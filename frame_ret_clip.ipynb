{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb513f38",
   "metadata": {},
   "source": [
    "Video retrieval by embedding single frames using CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "769c33eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Milvus server at port 19530\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from towhee import ops, pipe, register\n",
    "from towhee.operator import PyOperator\n",
    "from towhee import DataCollection\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from helpers import milvus_utils\n",
    "from helpers.extract_frames import extract_frame, extract_n_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33097668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "\n",
    "# Files\n",
    "MSRVTT_SAMPLES = \"./MSRVTT_1K.csv\"\n",
    "MSRVTT_SAMPLES_WITH_FRAMES = \"./MSRVTT_1K_frames.csv\"\n",
    "# file created using raw FIRE judgements, see clean_fire_judgements.ipynb\n",
    "FIRE_BENCHMARK_Q_JUDGEMENTS = \"./fire_benchmark_q_judgements.csv\" \n",
    "\n",
    "# Database Collections\n",
    "FRAME_RET_COLLECTION = \"msrvtt_multi_frame_ret_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62a84e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "video_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "video_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentence",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "dd9bd039-588f-4986-a7d6-5ec353b6159d",
       "rows": [
        [
         "0",
         "video7579",
         "./test_1k_compress/video7579.mp4",
         "a girl wearing red top and black trouser is putting a sweater on a dog"
        ],
        [
         "1",
         "video7725",
         "./test_1k_compress/video7725.mp4",
         "young people sit around the edges of a room clapping and raising their arms while others dance in the center during a party"
        ],
        [
         "2",
         "video9258",
         "./test_1k_compress/video9258.mp4",
         "a person is using a phone"
        ],
        [
         "3",
         "video7365",
         "./test_1k_compress/video7365.mp4",
         "cartoon people are eating at a restaurant"
        ],
        [
         "4",
         "video8068",
         "./test_1k_compress/video8068.mp4",
         "a woman on a couch talks to a a man"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_path</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video7579</td>\n",
       "      <td>./test_1k_compress/video7579.mp4</td>\n",
       "      <td>a girl wearing red top and black trouser is pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video7725</td>\n",
       "      <td>./test_1k_compress/video7725.mp4</td>\n",
       "      <td>young people sit around the edges of a room cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video9258</td>\n",
       "      <td>./test_1k_compress/video9258.mp4</td>\n",
       "      <td>a person is using a phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video7365</td>\n",
       "      <td>./test_1k_compress/video7365.mp4</td>\n",
       "      <td>cartoon people are eating at a restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video8068</td>\n",
       "      <td>./test_1k_compress/video8068.mp4</td>\n",
       "      <td>a woman on a couch talks to a a man</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    video_id                        video_path  \\\n",
       "0  video7579  ./test_1k_compress/video7579.mp4   \n",
       "1  video7725  ./test_1k_compress/video7725.mp4   \n",
       "2  video9258  ./test_1k_compress/video9258.mp4   \n",
       "3  video7365  ./test_1k_compress/video7365.mp4   \n",
       "4  video8068  ./test_1k_compress/video8068.mp4   \n",
       "\n",
       "                                            sentence  \n",
       "0  a girl wearing red top and black trouser is pu...  \n",
       "1  young people sit around the edges of a room cl...  \n",
       "2                          a person is using a phone  \n",
       "3          cartoon people are eating at a restaurant  \n",
       "4                a woman on a couch talks to a a man  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_samples_df = pd.read_csv(MSRVTT_SAMPLES)\n",
    "raw_samples_df[['video_id', 'video_path', 'sentence']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282b53af",
   "metadata": {},
   "source": [
    "Before we embed video frames, we need to extract and/or construct a single frame from each of the 1000 videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d171472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def extract_n_frames_2(video_path, output_folder, n=10):\n",
    "    \"\"\"\n",
    "    Extract n equally spaced frames from a video file and save them to a directory.\n",
    "    \n",
    "    Args:\n",
    "        video_path (str): Path to the input video file\n",
    "        output_folder (str): Path to the output directory to save frames\n",
    "        n (int): Number of equally spaced frames to extract (default: 10)\n",
    "    \"\"\"\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Open the video file\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get the total number of frames in the video\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Calculate the frame interval to get n equally spaced frames\n",
    "    if total_frames <= n:\n",
    "        # If video has fewer frames than requested, extract all frames\n",
    "        frame_indices = list(range(total_frames))\n",
    "    else:\n",
    "        # Calculate indices of equally spaced frames\n",
    "        frame_indices = [int(i * total_frames / n) for i in range(n)]\n",
    "    \n",
    "    # Get the video filename for naming the frames\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    \n",
    "    # Extract the frames at the calculated indices\n",
    "    for i, frame_index in enumerate(frame_indices):\n",
    "        # Set the video position to the desired frame\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "        \n",
    "        # Read the frame\n",
    "        ret, frame = video.read()\n",
    "        \n",
    "        # Break if frame reading failed\n",
    "        if not ret:\n",
    "            print(f\"Failed to read frame at index {frame_index}\")\n",
    "            continue\n",
    "        \n",
    "        # Generate the output filename\n",
    "        output_filename = f\"{video_name}_frame_{i+1:03d}_of_{n:03d}.jpg\"\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "        \n",
    "        # Save the frame as an image\n",
    "        cv2.imwrite(output_path, frame)\n",
    "    \n",
    "    # Release the video capture object\n",
    "    video.release()\n",
    "    \n",
    "    # Return the list of saved frame paths\n",
    "    frame_paths = [os.path.join(output_folder, f\"{video_name}_frame_{i+1:03d}_of_{n:03d}.jpg\") for i in range(len(frame_indices))]\n",
    "    return frame_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8657f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:22<00:00, 45.05it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unnamed: 0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "key",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "vid_key",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "video_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "video_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "frame_path_1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "frame_path_2",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "frame_path_3",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "frame_path_4",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "frame_id",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6bb1c884-27d7-4c66-b0d8-9c1bdd090c9b",
       "rows": [
        [
         "0",
         "521",
         "ret521",
         "msr7579",
         "video7579",
         "a girl wearing red top and black trouser is putting a sweater on a dog",
         "./test_1k_compress/video7579.mp4",
         "./test_1k_images_3/video7579_frame_001_of_004.jpg",
         "./test_1k_images_3/video7579_frame_002_of_004.jpg",
         "./test_1k_images_3/video7579_frame_003_of_004.jpg",
         "./test_1k_images_3/video7579_frame_004_of_004.jpg",
         "video7579"
        ],
        [
         "1",
         "737",
         "ret737",
         "msr7725",
         "video7725",
         "young people sit around the edges of a room clapping and raising their arms while others dance in the center during a party",
         "./test_1k_compress/video7725.mp4",
         "./test_1k_images_3/video7725_frame_001_of_004.jpg",
         "./test_1k_images_3/video7725_frame_002_of_004.jpg",
         "./test_1k_images_3/video7725_frame_003_of_004.jpg",
         "./test_1k_images_3/video7725_frame_004_of_004.jpg",
         "video7725"
        ],
        [
         "2",
         "740",
         "ret740",
         "msr9258",
         "video9258",
         "a person is using a phone",
         "./test_1k_compress/video9258.mp4",
         "./test_1k_images_3/video9258_frame_001_of_004.jpg",
         "./test_1k_images_3/video9258_frame_002_of_004.jpg",
         "./test_1k_images_3/video9258_frame_003_of_004.jpg",
         "./test_1k_images_3/video9258_frame_004_of_004.jpg",
         "video9258"
        ],
        [
         "3",
         "660",
         "ret660",
         "msr7365",
         "video7365",
         "cartoon people are eating at a restaurant",
         "./test_1k_compress/video7365.mp4",
         "./test_1k_images_3/video7365_frame_001_of_004.jpg",
         "./test_1k_images_3/video7365_frame_002_of_004.jpg",
         "./test_1k_images_3/video7365_frame_003_of_004.jpg",
         "./test_1k_images_3/video7365_frame_004_of_004.jpg",
         "video7365"
        ],
        [
         "4",
         "411",
         "ret411",
         "msr8068",
         "video8068",
         "a woman on a couch talks to a a man",
         "./test_1k_compress/video8068.mp4",
         "./test_1k_images_3/video8068_frame_001_of_004.jpg",
         "./test_1k_images_3/video8068_frame_002_of_004.jpg",
         "./test_1k_images_3/video8068_frame_003_of_004.jpg",
         "./test_1k_images_3/video8068_frame_004_of_004.jpg",
         "video8068"
        ],
        [
         "5",
         "678",
         "ret678",
         "msr7131",
         "video7131",
         "athletes are getting ready and start running for an event",
         "./test_1k_compress/video7131.mp4",
         "./test_1k_images_3/video7131_frame_001_of_004.jpg",
         "./test_1k_images_3/video7131_frame_002_of_004.jpg",
         "./test_1k_images_3/video7131_frame_003_of_004.jpg",
         "./test_1k_images_3/video7131_frame_004_of_004.jpg",
         "video7131"
        ],
        [
         "6",
         "626",
         "ret626",
         "msr7213",
         "video7213",
         "a woman is making lasagna",
         "./test_1k_compress/video7213.mp4",
         "./test_1k_images_3/video7213_frame_001_of_004.jpg",
         "./test_1k_images_3/video7213_frame_002_of_004.jpg",
         "./test_1k_images_3/video7213_frame_003_of_004.jpg",
         "./test_1k_images_3/video7213_frame_004_of_004.jpg",
         "video7213"
        ],
        [
         "7",
         "513",
         "ret513",
         "msr7575",
         "video7575",
         "a man speaking in a microphone",
         "./test_1k_compress/video7575.mp4",
         "./test_1k_images_3/video7575_frame_001_of_004.jpg",
         "./test_1k_images_3/video7575_frame_002_of_004.jpg",
         "./test_1k_images_3/video7575_frame_003_of_004.jpg",
         "./test_1k_images_3/video7575_frame_004_of_004.jpg",
         "video7575"
        ],
        [
         "8",
         "859",
         "ret859",
         "msr7978",
         "video7978",
         "a team with blue uniforms are playing badmitten with a team in white",
         "./test_1k_compress/video7978.mp4",
         "./test_1k_images_3/video7978_frame_001_of_004.jpg",
         "./test_1k_images_3/video7978_frame_002_of_004.jpg",
         "./test_1k_images_3/video7978_frame_003_of_004.jpg",
         "./test_1k_images_3/video7978_frame_004_of_004.jpg",
         "video7978"
        ],
        [
         "9",
         "136",
         "ret136",
         "msr8123",
         "video8123",
         "a woman is giving demo for baby trolley",
         "./test_1k_compress/video8123.mp4",
         "./test_1k_images_3/video8123_frame_001_of_004.jpg",
         "./test_1k_images_3/video8123_frame_002_of_004.jpg",
         "./test_1k_images_3/video8123_frame_003_of_004.jpg",
         "./test_1k_images_3/video8123_frame_004_of_004.jpg",
         "video8123"
        ],
        [
         "10",
         "811",
         "ret811",
         "msr9800",
         "video9800",
         "a car is in a wreck",
         "./test_1k_compress/video9800.mp4",
         "./test_1k_images_3/video9800_frame_001_of_004.jpg",
         "./test_1k_images_3/video9800_frame_002_of_004.jpg",
         "./test_1k_images_3/video9800_frame_003_of_004.jpg",
         "./test_1k_images_3/video9800_frame_004_of_004.jpg",
         "video9800"
        ],
        [
         "11",
         "76",
         "ret76",
         "msr9205",
         "video9205",
         "a woman interviewing about her part in a protest happening in brazil",
         "./test_1k_compress/video9205.mp4",
         "./test_1k_images_3/video9205_frame_001_of_004.jpg",
         "./test_1k_images_3/video9205_frame_002_of_004.jpg",
         "./test_1k_images_3/video9205_frame_003_of_004.jpg",
         "./test_1k_images_3/video9205_frame_004_of_004.jpg",
         "video9205"
        ],
        [
         "12",
         "636",
         "ret636",
         "msr7590",
         "video7590",
         "an emotional scene of two persons where they are crying on meeting",
         "./test_1k_compress/video7590.mp4",
         "./test_1k_images_3/video7590_frame_001_of_004.jpg",
         "./test_1k_images_3/video7590_frame_002_of_004.jpg",
         "./test_1k_images_3/video7590_frame_003_of_004.jpg",
         "./test_1k_images_3/video7590_frame_004_of_004.jpg",
         "video7590"
        ],
        [
         "13",
         "973",
         "ret973",
         "msr9017",
         "video9017",
         "the man is driving his motorbike fast and having problems on the race",
         "./test_1k_compress/video9017.mp4",
         "./test_1k_images_3/video9017_frame_001_of_004.jpg",
         "./test_1k_images_3/video9017_frame_002_of_004.jpg",
         "./test_1k_images_3/video9017_frame_003_of_004.jpg",
         "./test_1k_images_3/video9017_frame_004_of_004.jpg",
         "video9017"
        ],
        [
         "14",
         "938",
         "ret938",
         "msr9241",
         "video9241",
         "japanese people laughing and dancing",
         "./test_1k_compress/video9241.mp4",
         "./test_1k_images_3/video9241_frame_001_of_004.jpg",
         "./test_1k_images_3/video9241_frame_002_of_004.jpg",
         "./test_1k_images_3/video9241_frame_003_of_004.jpg",
         "./test_1k_images_3/video9241_frame_004_of_004.jpg",
         "video9241"
        ],
        [
         "15",
         "899",
         "ret899",
         "msr7158",
         "video7158",
         "fox news presidential debate recapping the gop debate with donald trump and ted cruz",
         "./test_1k_compress/video7158.mp4",
         "./test_1k_images_3/video7158_frame_001_of_004.jpg",
         "./test_1k_images_3/video7158_frame_002_of_004.jpg",
         "./test_1k_images_3/video7158_frame_003_of_004.jpg",
         "./test_1k_images_3/video7158_frame_004_of_004.jpg",
         "video7158"
        ],
        [
         "16",
         "280",
         "ret280",
         "msr9233",
         "video9233",
         "a man is giving a speech",
         "./test_1k_compress/video9233.mp4",
         "./test_1k_images_3/video9233_frame_001_of_004.jpg",
         "./test_1k_images_3/video9233_frame_002_of_004.jpg",
         "./test_1k_images_3/video9233_frame_003_of_004.jpg",
         "./test_1k_images_3/video9233_frame_004_of_004.jpg",
         "video9233"
        ],
        [
         "17",
         "883",
         "ret883",
         "msr8687",
         "video8687",
         "fast moving time is shown here",
         "./test_1k_compress/video8687.mp4",
         "./test_1k_images_3/video8687_frame_001_of_004.jpg",
         "./test_1k_images_3/video8687_frame_002_of_004.jpg",
         "./test_1k_images_3/video8687_frame_003_of_004.jpg",
         "./test_1k_images_3/video8687_frame_004_of_004.jpg",
         "video8687"
        ],
        [
         "18",
         "761",
         "ret761",
         "msr9337",
         "video9337",
         "some people are inside of a room",
         "./test_1k_compress/video9337.mp4",
         "./test_1k_images_3/video9337_frame_001_of_004.jpg",
         "./test_1k_images_3/video9337_frame_002_of_004.jpg",
         "./test_1k_images_3/video9337_frame_003_of_004.jpg",
         "./test_1k_images_3/video9337_frame_004_of_004.jpg",
         "video9337"
        ],
        [
         "19",
         "319",
         "ret319",
         "msr9620",
         "video9620",
         "outer space pictures that have parts of equipments in them with water droplets on it",
         "./test_1k_compress/video9620.mp4",
         "./test_1k_images_3/video9620_frame_001_of_004.jpg",
         "./test_1k_images_3/video9620_frame_002_of_004.jpg",
         "./test_1k_images_3/video9620_frame_003_of_004.jpg",
         "./test_1k_images_3/video9620_frame_004_of_004.jpg",
         "video9620"
        ],
        [
         "20",
         "549",
         "ret549",
         "msr7411",
         "video7411",
         "jolly good music troop delivering a program and the lady is in good spirit",
         "./test_1k_compress/video7411.mp4",
         "./test_1k_images_3/video7411_frame_001_of_004.jpg",
         "./test_1k_images_3/video7411_frame_002_of_004.jpg",
         "./test_1k_images_3/video7411_frame_003_of_004.jpg",
         "./test_1k_images_3/video7411_frame_004_of_004.jpg",
         "video7411"
        ],
        [
         "21",
         "174",
         "ret174",
         "msr8514",
         "video8514",
         "a person is putting the vegetable in to the water and boil it",
         "./test_1k_compress/video8514.mp4",
         "./test_1k_images_3/video8514_frame_001_of_004.jpg",
         "./test_1k_images_3/video8514_frame_002_of_004.jpg",
         "./test_1k_images_3/video8514_frame_003_of_004.jpg",
         "./test_1k_images_3/video8514_frame_004_of_004.jpg",
         "video8514"
        ],
        [
         "22",
         "371",
         "ret371",
         "msr8481",
         "video8481",
         "a woman is reporting on keds commercials",
         "./test_1k_compress/video8481.mp4",
         "./test_1k_images_3/video8481_frame_001_of_004.jpg",
         "./test_1k_images_3/video8481_frame_002_of_004.jpg",
         "./test_1k_images_3/video8481_frame_003_of_004.jpg",
         "./test_1k_images_3/video8481_frame_004_of_004.jpg",
         "video8481"
        ],
        [
         "23",
         "527",
         "ret527",
         "msr9224",
         "video9224",
         "someone is playing a game",
         "./test_1k_compress/video9224.mp4",
         "./test_1k_images_3/video9224_frame_001_of_004.jpg",
         "./test_1k_images_3/video9224_frame_002_of_004.jpg",
         "./test_1k_images_3/video9224_frame_003_of_004.jpg",
         "./test_1k_images_3/video9224_frame_004_of_004.jpg",
         "video9224"
        ],
        [
         "24",
         "210",
         "ret210",
         "msr8426",
         "video8426",
         "cabins on a sandy beach have walkways going up to their porches",
         "./test_1k_compress/video8426.mp4",
         "./test_1k_images_3/video8426_frame_001_of_004.jpg",
         "./test_1k_images_3/video8426_frame_002_of_004.jpg",
         "./test_1k_images_3/video8426_frame_003_of_004.jpg",
         "./test_1k_images_3/video8426_frame_004_of_004.jpg",
         "video8426"
        ],
        [
         "25",
         "235",
         "ret235",
         "msr9699",
         "video9699",
         "a man explains how to do a experiment",
         "./test_1k_compress/video9699.mp4",
         "./test_1k_images_3/video9699_frame_001_of_004.jpg",
         "./test_1k_images_3/video9699_frame_002_of_004.jpg",
         "./test_1k_images_3/video9699_frame_003_of_004.jpg",
         "./test_1k_images_3/video9699_frame_004_of_004.jpg",
         "video9699"
        ],
        [
         "26",
         "101",
         "ret101",
         "msr9882",
         "video9882",
         "a news reader is reading the news and asking question to some people",
         "./test_1k_compress/video9882.mp4",
         "./test_1k_images_3/video9882_frame_001_of_004.jpg",
         "./test_1k_images_3/video9882_frame_002_of_004.jpg",
         "./test_1k_images_3/video9882_frame_003_of_004.jpg",
         "./test_1k_images_3/video9882_frame_004_of_004.jpg",
         "video9882"
        ],
        [
         "27",
         "986",
         "ret986",
         "msr8300",
         "video8300",
         "a woman pours water into her pot of meat then tomato sauce and stirs it all around while talking",
         "./test_1k_compress/video8300.mp4",
         "./test_1k_images_3/video8300_frame_001_of_004.jpg",
         "./test_1k_images_3/video8300_frame_002_of_004.jpg",
         "./test_1k_images_3/video8300_frame_003_of_004.jpg",
         "./test_1k_images_3/video8300_frame_004_of_004.jpg",
         "video8300"
        ],
        [
         "28",
         "902",
         "ret902",
         "msr8863",
         "video8863",
         "an animated girl talks to a baby and plays with it",
         "./test_1k_compress/video8863.mp4",
         "./test_1k_images_3/video8863_frame_001_of_004.jpg",
         "./test_1k_images_3/video8863_frame_002_of_004.jpg",
         "./test_1k_images_3/video8863_frame_003_of_004.jpg",
         "./test_1k_images_3/video8863_frame_004_of_004.jpg",
         "video8863"
        ],
        [
         "29",
         "947",
         "ret947",
         "msr7147",
         "video7147",
         "a man cooks burgers and bacon on a grill",
         "./test_1k_compress/video7147.mp4",
         "./test_1k_images_3/video7147_frame_001_of_004.jpg",
         "./test_1k_images_3/video7147_frame_002_of_004.jpg",
         "./test_1k_images_3/video7147_frame_003_of_004.jpg",
         "./test_1k_images_3/video7147_frame_004_of_004.jpg",
         "video7147"
        ],
        [
         "30",
         "346",
         "ret346",
         "msr7744",
         "video7744",
         "a chef stirs up some ingredients inside of a pan",
         "./test_1k_compress/video7744.mp4",
         "./test_1k_images_3/video7744_frame_001_of_004.jpg",
         "./test_1k_images_3/video7744_frame_002_of_004.jpg",
         "./test_1k_images_3/video7744_frame_003_of_004.jpg",
         "./test_1k_images_3/video7744_frame_004_of_004.jpg",
         "video7744"
        ],
        [
         "31",
         "139",
         "ret139",
         "msr7839",
         "video7839",
         "this is a vine sports compilation",
         "./test_1k_compress/video7839.mp4",
         "./test_1k_images_3/video7839_frame_001_of_004.jpg",
         "./test_1k_images_3/video7839_frame_002_of_004.jpg",
         "./test_1k_images_3/video7839_frame_003_of_004.jpg",
         "./test_1k_images_3/video7839_frame_004_of_004.jpg",
         "video7839"
        ],
        [
         "32",
         "621",
         "ret621",
         "msr7214",
         "video7214",
         "race cars of different colors lined up on a dark track",
         "./test_1k_compress/video7214.mp4",
         "./test_1k_images_3/video7214_frame_001_of_004.jpg",
         "./test_1k_images_3/video7214_frame_002_of_004.jpg",
         "./test_1k_images_3/video7214_frame_003_of_004.jpg",
         "./test_1k_images_3/video7214_frame_004_of_004.jpg",
         "video7214"
        ],
        [
         "33",
         "499",
         "ret499",
         "msr7771",
         "video7771",
         "a golf player is trying to hit the ball into the pit",
         "./test_1k_compress/video7771.mp4",
         "./test_1k_images_3/video7771_frame_001_of_004.jpg",
         "./test_1k_images_3/video7771_frame_002_of_004.jpg",
         "./test_1k_images_3/video7771_frame_003_of_004.jpg",
         "./test_1k_images_3/video7771_frame_004_of_004.jpg",
         "video7771"
        ],
        [
         "34",
         "370",
         "ret370",
         "msr8486",
         "video8486",
         "a cartoon on a young guy cursing",
         "./test_1k_compress/video8486.mp4",
         "./test_1k_images_3/video8486_frame_001_of_004.jpg",
         "./test_1k_images_3/video8486_frame_002_of_004.jpg",
         "./test_1k_images_3/video8486_frame_003_of_004.jpg",
         "./test_1k_images_3/video8486_frame_004_of_004.jpg",
         "video8486"
        ],
        [
         "35",
         "198",
         "ret198",
         "msr9909",
         "video9909",
         "a crowd of people sitting next to each other as one man plays a video game",
         "./test_1k_compress/video9909.mp4",
         "./test_1k_images_3/video9909_frame_001_of_004.jpg",
         "./test_1k_images_3/video9909_frame_002_of_004.jpg",
         "./test_1k_images_3/video9909_frame_003_of_004.jpg",
         "./test_1k_images_3/video9909_frame_004_of_004.jpg",
         "video9909"
        ],
        [
         "36",
         "687",
         "ret687",
         "msr8922",
         "video8922",
         "an old man shakes hands with another man and then they hug each other",
         "./test_1k_compress/video8922.mp4",
         "./test_1k_images_3/video8922_frame_001_of_004.jpg",
         "./test_1k_images_3/video8922_frame_002_of_004.jpg",
         "./test_1k_images_3/video8922_frame_003_of_004.jpg",
         "./test_1k_images_3/video8922_frame_004_of_004.jpg",
         "video8922"
        ],
        [
         "37",
         "584",
         "ret584",
         "msr9814",
         "video9814",
         "a scene from spongebob squarepants where the townspeople are carrying torches and chasing a giant squidward",
         "./test_1k_compress/video9814.mp4",
         "./test_1k_images_3/video9814_frame_001_of_004.jpg",
         "./test_1k_images_3/video9814_frame_002_of_004.jpg",
         "./test_1k_images_3/video9814_frame_003_of_004.jpg",
         "./test_1k_images_3/video9814_frame_004_of_004.jpg",
         "video9814"
        ],
        [
         "38",
         "901",
         "ret901",
         "msr9368",
         "video9368",
         "someone demonstrates about the small motor uses to the video",
         "./test_1k_compress/video9368.mp4",
         "./test_1k_images_3/video9368_frame_001_of_004.jpg",
         "./test_1k_images_3/video9368_frame_002_of_004.jpg",
         "./test_1k_images_3/video9368_frame_003_of_004.jpg",
         "./test_1k_images_3/video9368_frame_004_of_004.jpg",
         "video9368"
        ],
        [
         "39",
         "59",
         "ret59",
         "msr8820",
         "video8820",
         "a person comes up in the hill on a orange motor bike and falls down",
         "./test_1k_compress/video8820.mp4",
         "./test_1k_images_3/video8820_frame_001_of_004.jpg",
         "./test_1k_images_3/video8820_frame_002_of_004.jpg",
         "./test_1k_images_3/video8820_frame_003_of_004.jpg",
         "./test_1k_images_3/video8820_frame_004_of_004.jpg",
         "video8820"
        ],
        [
         "40",
         "328",
         "ret328",
         "msr9452",
         "video9452",
         "an animated grey shark in the middle of a blue water simulation background rotating in a circle on the screen of a monitor",
         "./test_1k_compress/video9452.mp4",
         "./test_1k_images_3/video9452_frame_001_of_004.jpg",
         "./test_1k_images_3/video9452_frame_002_of_004.jpg",
         "./test_1k_images_3/video9452_frame_003_of_004.jpg",
         "./test_1k_images_3/video9452_frame_004_of_004.jpg",
         "video9452"
        ],
        [
         "41",
         "96",
         "ret96",
         "msr9344",
         "video9344",
         "gameplay footage of someone playing a game",
         "./test_1k_compress/video9344.mp4",
         "./test_1k_images_3/video9344_frame_001_of_004.jpg",
         "./test_1k_images_3/video9344_frame_002_of_004.jpg",
         "./test_1k_images_3/video9344_frame_003_of_004.jpg",
         "./test_1k_images_3/video9344_frame_004_of_004.jpg",
         "video9344"
        ],
        [
         "42",
         "312",
         "ret312",
         "msr9032",
         "video9032",
         "a hospital mortuary room and a doctor treat the special case",
         "./test_1k_compress/video9032.mp4",
         "./test_1k_images_3/video9032_frame_001_of_004.jpg",
         "./test_1k_images_3/video9032_frame_002_of_004.jpg",
         "./test_1k_images_3/video9032_frame_003_of_004.jpg",
         "./test_1k_images_3/video9032_frame_004_of_004.jpg",
         "video9032"
        ],
        [
         "43",
         "974",
         "ret974",
         "msr9016",
         "video9016",
         "all persons are wearing bikini dresses and playing in sea",
         "./test_1k_compress/video9016.mp4",
         "./test_1k_images_3/video9016_frame_001_of_004.jpg",
         "./test_1k_images_3/video9016_frame_002_of_004.jpg",
         "./test_1k_images_3/video9016_frame_003_of_004.jpg",
         "./test_1k_images_3/video9016_frame_004_of_004.jpg",
         "video9016"
        ],
        [
         "44",
         "299",
         "ret299",
         "msr9353",
         "video9353",
         "two women are outside and are discussing something in a foreign language",
         "./test_1k_compress/video9353.mp4",
         "./test_1k_images_3/video9353_frame_001_of_004.jpg",
         "./test_1k_images_3/video9353_frame_002_of_004.jpg",
         "./test_1k_images_3/video9353_frame_003_of_004.jpg",
         "./test_1k_images_3/video9353_frame_004_of_004.jpg",
         "video9353"
        ],
        [
         "45",
         "277",
         "ret277",
         "msr9405",
         "video9405",
         "red balloons float in the sky and have packages tied to them",
         "./test_1k_compress/video9405.mp4",
         "./test_1k_images_3/video9405_frame_001_of_004.jpg",
         "./test_1k_images_3/video9405_frame_002_of_004.jpg",
         "./test_1k_images_3/video9405_frame_003_of_004.jpg",
         "./test_1k_images_3/video9405_frame_004_of_004.jpg",
         "video9405"
        ],
        [
         "46",
         "924",
         "ret924",
         "msr7559",
         "video7559",
         "a man is trying some sushi",
         "./test_1k_compress/video7559.mp4",
         "./test_1k_images_3/video7559_frame_001_of_004.jpg",
         "./test_1k_images_3/video7559_frame_002_of_004.jpg",
         "./test_1k_images_3/video7559_frame_003_of_004.jpg",
         "./test_1k_images_3/video7559_frame_004_of_004.jpg",
         "video7559"
        ],
        [
         "47",
         "601",
         "ret601",
         "msr9063",
         "video9063",
         "people on stage performing",
         "./test_1k_compress/video9063.mp4",
         "./test_1k_images_3/video9063_frame_001_of_004.jpg",
         "./test_1k_images_3/video9063_frame_002_of_004.jpg",
         "./test_1k_images_3/video9063_frame_003_of_004.jpg",
         "./test_1k_images_3/video9063_frame_004_of_004.jpg",
         "video9063"
        ],
        [
         "48",
         "439",
         "ret439",
         "msr7352",
         "video7352",
         "a movie scene starring morgan freeman and men in armor running",
         "./test_1k_compress/video7352.mp4",
         "./test_1k_images_3/video7352_frame_001_of_004.jpg",
         "./test_1k_images_3/video7352_frame_002_of_004.jpg",
         "./test_1k_images_3/video7352_frame_003_of_004.jpg",
         "./test_1k_images_3/video7352_frame_004_of_004.jpg",
         "video7352"
        ],
        [
         "49",
         "837",
         "ret837",
         "msr8447",
         "video8447",
         "a woman singing on the voice",
         "./test_1k_compress/video8447.mp4",
         "./test_1k_images_3/video8447_frame_001_of_004.jpg",
         "./test_1k_images_3/video8447_frame_002_of_004.jpg",
         "./test_1k_images_3/video8447_frame_003_of_004.jpg",
         "./test_1k_images_3/video8447_frame_004_of_004.jpg",
         "video8447"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 1000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>key</th>\n",
       "      <th>vid_key</th>\n",
       "      <th>video_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_path</th>\n",
       "      <th>frame_path_1</th>\n",
       "      <th>frame_path_2</th>\n",
       "      <th>frame_path_3</th>\n",
       "      <th>frame_path_4</th>\n",
       "      <th>frame_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>521</td>\n",
       "      <td>ret521</td>\n",
       "      <td>msr7579</td>\n",
       "      <td>video7579</td>\n",
       "      <td>a girl wearing red top and black trouser is pu...</td>\n",
       "      <td>./test_1k_compress/video7579.mp4</td>\n",
       "      <td>./test_1k_images_3/video7579_frame_001_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video7579_frame_002_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video7579_frame_003_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video7579_frame_004_of_004.jpg</td>\n",
       "      <td>video7579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>737</td>\n",
       "      <td>ret737</td>\n",
       "      <td>msr7725</td>\n",
       "      <td>video7725</td>\n",
       "      <td>young people sit around the edges of a room cl...</td>\n",
       "      <td>./test_1k_compress/video7725.mp4</td>\n",
       "      <td>./test_1k_images_3/video7725_frame_001_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video7725_frame_002_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video7725_frame_003_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video7725_frame_004_of_004.jpg</td>\n",
       "      <td>video7725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>740</td>\n",
       "      <td>ret740</td>\n",
       "      <td>msr9258</td>\n",
       "      <td>video9258</td>\n",
       "      <td>a person is using a phone</td>\n",
       "      <td>./test_1k_compress/video9258.mp4</td>\n",
       "      <td>./test_1k_images_3/video9258_frame_001_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video9258_frame_002_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video9258_frame_003_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video9258_frame_004_of_004.jpg</td>\n",
       "      <td>video9258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>660</td>\n",
       "      <td>ret660</td>\n",
       "      <td>msr7365</td>\n",
       "      <td>video7365</td>\n",
       "      <td>cartoon people are eating at a restaurant</td>\n",
       "      <td>./test_1k_compress/video7365.mp4</td>\n",
       "      <td>./test_1k_images_3/video7365_frame_001_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video7365_frame_002_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video7365_frame_003_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video7365_frame_004_of_004.jpg</td>\n",
       "      <td>video7365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>411</td>\n",
       "      <td>ret411</td>\n",
       "      <td>msr8068</td>\n",
       "      <td>video8068</td>\n",
       "      <td>a woman on a couch talks to a a man</td>\n",
       "      <td>./test_1k_compress/video8068.mp4</td>\n",
       "      <td>./test_1k_images_3/video8068_frame_001_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video8068_frame_002_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video8068_frame_003_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video8068_frame_004_of_004.jpg</td>\n",
       "      <td>video8068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>106</td>\n",
       "      <td>ret106</td>\n",
       "      <td>msr7034</td>\n",
       "      <td>video7034</td>\n",
       "      <td>man in black shirt is holding a baby upside do...</td>\n",
       "      <td>./test_1k_compress/video7034.mp4</td>\n",
       "      <td>./test_1k_images_3/video7034_frame_001_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video7034_frame_002_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video7034_frame_003_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video7034_frame_004_of_004.jpg</td>\n",
       "      <td>video7034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>270</td>\n",
       "      <td>ret270</td>\n",
       "      <td>msr7568</td>\n",
       "      <td>video7568</td>\n",
       "      <td>the queen of england is seen walking with an e...</td>\n",
       "      <td>./test_1k_compress/video7568.mp4</td>\n",
       "      <td>./test_1k_images_3/video7568_frame_001_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video7568_frame_002_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video7568_frame_003_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video7568_frame_004_of_004.jpg</td>\n",
       "      <td>video7568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>860</td>\n",
       "      <td>ret860</td>\n",
       "      <td>msr7979</td>\n",
       "      <td>video7979</td>\n",
       "      <td>people talking about a fight</td>\n",
       "      <td>./test_1k_compress/video7979.mp4</td>\n",
       "      <td>./test_1k_images_3/video7979_frame_001_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video7979_frame_002_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video7979_frame_003_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video7979_frame_004_of_004.jpg</td>\n",
       "      <td>video7979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>435</td>\n",
       "      <td>ret435</td>\n",
       "      <td>msr7356</td>\n",
       "      <td>video7356</td>\n",
       "      <td>a vehicle with details on what comes with it b...</td>\n",
       "      <td>./test_1k_compress/video7356.mp4</td>\n",
       "      <td>./test_1k_images_3/video7356_frame_001_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video7356_frame_002_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video7356_frame_003_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video7356_frame_004_of_004.jpg</td>\n",
       "      <td>video7356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>102</td>\n",
       "      <td>ret102</td>\n",
       "      <td>msr8578</td>\n",
       "      <td>video8578</td>\n",
       "      <td>a man is commentating while playing minecraft</td>\n",
       "      <td>./test_1k_compress/video8578.mp4</td>\n",
       "      <td>./test_1k_images_3/video8578_frame_001_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video8578_frame_002_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video8578_frame_003_of_004.jpg</td>\n",
       "      <td>./test_1k_images_3/video8578_frame_004_of_004.jpg</td>\n",
       "      <td>video8578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0     key  vid_key   video_id  \\\n",
       "0           521  ret521  msr7579  video7579   \n",
       "1           737  ret737  msr7725  video7725   \n",
       "2           740  ret740  msr9258  video9258   \n",
       "3           660  ret660  msr7365  video7365   \n",
       "4           411  ret411  msr8068  video8068   \n",
       "..          ...     ...      ...        ...   \n",
       "995         106  ret106  msr7034  video7034   \n",
       "996         270  ret270  msr7568  video7568   \n",
       "997         860  ret860  msr7979  video7979   \n",
       "998         435  ret435  msr7356  video7356   \n",
       "999         102  ret102  msr8578  video8578   \n",
       "\n",
       "                                              sentence  \\\n",
       "0    a girl wearing red top and black trouser is pu...   \n",
       "1    young people sit around the edges of a room cl...   \n",
       "2                            a person is using a phone   \n",
       "3            cartoon people are eating at a restaurant   \n",
       "4                  a woman on a couch talks to a a man   \n",
       "..                                                 ...   \n",
       "995  man in black shirt is holding a baby upside do...   \n",
       "996  the queen of england is seen walking with an e...   \n",
       "997                       people talking about a fight   \n",
       "998  a vehicle with details on what comes with it b...   \n",
       "999      a man is commentating while playing minecraft   \n",
       "\n",
       "                           video_path  \\\n",
       "0    ./test_1k_compress/video7579.mp4   \n",
       "1    ./test_1k_compress/video7725.mp4   \n",
       "2    ./test_1k_compress/video9258.mp4   \n",
       "3    ./test_1k_compress/video7365.mp4   \n",
       "4    ./test_1k_compress/video8068.mp4   \n",
       "..                                ...   \n",
       "995  ./test_1k_compress/video7034.mp4   \n",
       "996  ./test_1k_compress/video7568.mp4   \n",
       "997  ./test_1k_compress/video7979.mp4   \n",
       "998  ./test_1k_compress/video7356.mp4   \n",
       "999  ./test_1k_compress/video8578.mp4   \n",
       "\n",
       "                                          frame_path_1  \\\n",
       "0    ./test_1k_images_3/video7579_frame_001_of_004.jpg   \n",
       "1    ./test_1k_images_3/video7725_frame_001_of_004.jpg   \n",
       "2    ./test_1k_images_3/video9258_frame_001_of_004.jpg   \n",
       "3    ./test_1k_images_3/video7365_frame_001_of_004.jpg   \n",
       "4    ./test_1k_images_3/video8068_frame_001_of_004.jpg   \n",
       "..                                                 ...   \n",
       "995  ./test_1k_images_3/video7034_frame_001_of_004.jpg   \n",
       "996  ./test_1k_images_3/video7568_frame_001_of_004.jpg   \n",
       "997  ./test_1k_images_3/video7979_frame_001_of_004.jpg   \n",
       "998  ./test_1k_images_3/video7356_frame_001_of_004.jpg   \n",
       "999  ./test_1k_images_3/video8578_frame_001_of_004.jpg   \n",
       "\n",
       "                                          frame_path_2  \\\n",
       "0    ./test_1k_images_3/video7579_frame_002_of_004.jpg   \n",
       "1    ./test_1k_images_3/video7725_frame_002_of_004.jpg   \n",
       "2    ./test_1k_images_3/video9258_frame_002_of_004.jpg   \n",
       "3    ./test_1k_images_3/video7365_frame_002_of_004.jpg   \n",
       "4    ./test_1k_images_3/video8068_frame_002_of_004.jpg   \n",
       "..                                                 ...   \n",
       "995  ./test_1k_images_3/video7034_frame_002_of_004.jpg   \n",
       "996  ./test_1k_images_3/video7568_frame_002_of_004.jpg   \n",
       "997  ./test_1k_images_3/video7979_frame_002_of_004.jpg   \n",
       "998  ./test_1k_images_3/video7356_frame_002_of_004.jpg   \n",
       "999  ./test_1k_images_3/video8578_frame_002_of_004.jpg   \n",
       "\n",
       "                                          frame_path_3  \\\n",
       "0    ./test_1k_images_3/video7579_frame_003_of_004.jpg   \n",
       "1    ./test_1k_images_3/video7725_frame_003_of_004.jpg   \n",
       "2    ./test_1k_images_3/video9258_frame_003_of_004.jpg   \n",
       "3    ./test_1k_images_3/video7365_frame_003_of_004.jpg   \n",
       "4    ./test_1k_images_3/video8068_frame_003_of_004.jpg   \n",
       "..                                                 ...   \n",
       "995  ./test_1k_images_3/video7034_frame_003_of_004.jpg   \n",
       "996  ./test_1k_images_3/video7568_frame_003_of_004.jpg   \n",
       "997  ./test_1k_images_3/video7979_frame_003_of_004.jpg   \n",
       "998  ./test_1k_images_3/video7356_frame_003_of_004.jpg   \n",
       "999  ./test_1k_images_3/video8578_frame_003_of_004.jpg   \n",
       "\n",
       "                                          frame_path_4   frame_id  \n",
       "0    ./test_1k_images_3/video7579_frame_004_of_004.jpg  video7579  \n",
       "1    ./test_1k_images_3/video7725_frame_004_of_004.jpg  video7725  \n",
       "2    ./test_1k_images_3/video9258_frame_004_of_004.jpg  video9258  \n",
       "3    ./test_1k_images_3/video7365_frame_004_of_004.jpg  video7365  \n",
       "4    ./test_1k_images_3/video8068_frame_004_of_004.jpg  video8068  \n",
       "..                                                 ...        ...  \n",
       "995  ./test_1k_images_3/video7034_frame_004_of_004.jpg  video7034  \n",
       "996  ./test_1k_images_3/video7568_frame_004_of_004.jpg  video7568  \n",
       "997  ./test_1k_images_3/video7979_frame_004_of_004.jpg  video7979  \n",
       "998  ./test_1k_images_3/video7356_frame_004_of_004.jpg  video7356  \n",
       "999  ./test_1k_images_3/video8578_frame_004_of_004.jpg  video8578  \n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for row in tqdm(raw_samples_df.iterrows(), total=len(raw_samples_df)):\n",
    "    video_path = row[1]['video_path']\n",
    "    images_dir = \"./test_1k_images_3\"\n",
    "    image_name = os.path.basename(video_path).split('.')[0]\n",
    "    image_path = os.path.join(images_dir, image_name) + \".jpg\"\n",
    "    # extract 4 frames per video\n",
    "    all_frame_paths = extract_n_frames_2(video_path, images_dir, 4)\n",
    "    f1, f2, f3, f4 = all_frame_paths\n",
    "    # extract_frame(video_path, image_path)\n",
    "    # add column with val to current row\n",
    "    raw_samples_df.at[row[0], 'frame_path_1'] = f1\n",
    "    raw_samples_df.at[row[0], 'frame_path_2'] = f2\n",
    "    raw_samples_df.at[row[0], 'frame_path_3'] = f3\n",
    "    raw_samples_df.at[row[0], 'frame_path_4'] = f4\n",
    "    \n",
    "    raw_samples_df.at[row[0], 'frame_id'] = image_name\n",
    "    \n",
    "# Now this should contain new columns with the frame_path and frame_id\n",
    "raw_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6820e1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We write the transformed samples data to a CSV file so it can be loaded into the load pipeline\n",
    "# raw_samples_df[['video_id', 'frame_path', 'frame_id', 'sentence']].to_csv(MSRVTT_SAMPLES_WITH_FRAMES, index=False)\n",
    "raw_samples_df[['video_id', 'frame_path_1', 'frame_path_2', 'frame_path_3', 'frame_path_4', 'frame_id', 'sentence']].to_csv(MSRVTT_SAMPLES_WITH_FRAMES, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7381872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Collection>:\n",
       "-------------\n",
       "<name>: msrvtt_multi_frame_ret_1\n",
       "<description>: video retrieval\n",
       "<schema>: {'auto_id': False, 'description': 'video retrieval', 'fields': [{'name': 'id', 'description': '', 'type': <DataType.INT64: 5>, 'is_primary': True, 'auto_id': False}, {'name': 'embedding', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 512}}]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the collection in Milvus to store image embeddings\n",
    "milvus_utils.create_milvus_collection(FRAME_RET_COLLECTION, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84a9beba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 23:40:15,842 - 8454604864 - clip.py-clip:100 - WARNING: Gpu not available, use cpu\n",
      "2025-04-16 23:40:15,873 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:40:15,944 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:40:16,005 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "2025-04-16 23:40:16,008 - 18983612416 - connectionpool.py-connectionpool:1049 - DEBUG: Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-16 23:40:16,099 - 18983612416 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16 HTTP/1.1\" 200 3499\n",
      "2025-04-16 23:40:16,277 - 18983612416 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/main HTTP/1.1\" 200 3099\n",
      "2025-04-16 23:40:16,293 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:40:16,326 - 18983612416 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/discussions?p=0 HTTP/1.1\" 200 6380\n",
      "2025-04-16 23:40:16,387 - 18983612416 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/refs%2Fpr%2F10 HTTP/1.1\" 200 4064\n",
      "2025-04-16 23:40:16,422 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:40:16,424 - 18983612416 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors.index.json HTTP/1.1\" 404 0\n",
      "2025-04-16 23:40:16,609 - 18983612416 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors HTTP/1.1\" 302 0\n",
      "2025-04-16 23:40:16,737 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:40:16,852 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "2025-04-16 23:40:16,886 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.json HTTP/1.1\" 404 0\n",
      "2025-04-16 23:40:16,954 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.jinja HTTP/1.1\" 404 0\n",
      "2025-04-16 23:40:17,054 - 8454604864 - clip.py-clip:100 - WARNING: Gpu not available, use cpu\n",
      "2025-04-16 23:40:17,083 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:40:17,115 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:40:17,371 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "2025-04-16 23:40:17,374 - 19602239488 - connectionpool.py-connectionpool:1049 - DEBUG: Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-16 23:40:17,450 - 19602239488 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16 HTTP/1.1\" 200 3499\n",
      "2025-04-16 23:40:17,471 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:40:17,519 - 19602239488 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/main HTTP/1.1\" 200 3099\n",
      "2025-04-16 23:40:17,553 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:40:17,569 - 19602239488 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/discussions?p=0 HTTP/1.1\" 200 6380\n",
      "2025-04-16 23:40:17,583 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:40:17,651 - 19602239488 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/refs%2Fpr%2F10 HTTP/1.1\" 200 4064\n",
      "2025-04-16 23:40:17,679 - 19602239488 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors.index.json HTTP/1.1\" 404 0\n",
      "2025-04-16 23:40:17,683 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "2025-04-16 23:40:17,787 - 19602239488 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors HTTP/1.1\" 302 0\n",
      "2025-04-16 23:40:17,788 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.json HTTP/1.1\" 404 0\n",
      "2025-04-16 23:40:17,821 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.jinja HTTP/1.1\" 404 0\n",
      "2025-04-16 23:40:17,929 - 8454604864 - clip.py-clip:100 - WARNING: Gpu not available, use cpu\n",
      "2025-04-16 23:40:17,957 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:40:17,994 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:40:18,028 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "2025-04-16 23:40:18,030 - 20221915136 - connectionpool.py-connectionpool:1049 - DEBUG: Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-16 23:40:18,335 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:40:18,368 - 20221915136 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16 HTTP/1.1\" 200 3499\n",
      "2025-04-16 23:40:18,442 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:40:18,467 - 20221915136 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/main HTTP/1.1\" 200 3099\n",
      "2025-04-16 23:40:18,470 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:40:18,535 - 20221915136 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/discussions?p=0 HTTP/1.1\" 200 6380\n",
      "2025-04-16 23:40:18,588 - 20221915136 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/refs%2Fpr%2F10 HTTP/1.1\" 200 4064\n",
      "2025-04-16 23:40:18,593 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "2025-04-16 23:40:18,618 - 20221915136 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors.index.json HTTP/1.1\" 404 0\n",
      "2025-04-16 23:40:18,624 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.json HTTP/1.1\" 404 0\n",
      "2025-04-16 23:40:18,648 - 20221915136 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors HTTP/1.1\" 302 0\n",
      "2025-04-16 23:40:18,655 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.jinja HTTP/1.1\" 404 0\n",
      "2025-04-16 23:40:18,745 - 8454604864 - clip.py-clip:100 - WARNING: Gpu not available, use cpu\n",
      "2025-04-16 23:40:18,858 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:40:18,888 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:40:18,920 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "2025-04-16 23:40:18,924 - 20839493632 - connectionpool.py-connectionpool:1049 - DEBUG: Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-16 23:40:19,016 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:40:19,057 - 20839493632 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16 HTTP/1.1\" 200 3499\n",
      "2025-04-16 23:40:19,086 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:40:19,103 - 20839493632 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/main HTTP/1.1\" 200 3099\n",
      "2025-04-16 23:40:19,130 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:40:19,226 - 20839493632 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/discussions?p=0 HTTP/1.1\" 200 6380\n",
      "2025-04-16 23:40:19,256 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "2025-04-16 23:40:19,360 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.json HTTP/1.1\" 404 0\n",
      "2025-04-16 23:40:19,360 - 20839493632 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/refs%2Fpr%2F10 HTTP/1.1\" 200 4064\n",
      "2025-04-16 23:40:19,398 - 20839493632 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors.index.json HTTP/1.1\" 404 0\n",
      "2025-04-16 23:40:19,428 - 20839493632 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors HTTP/1.1\" 302 0\n",
      "2025-04-16 23:40:19,458 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.jinja HTTP/1.1\" 404 0\n"
     ]
    }
   ],
   "source": [
    "def read_frame_loader_csv(csv_path, encoding='utf-8-sig'):\n",
    "    with open(csv_path, 'r', encoding=encoding) as f:\n",
    "        data = csv.DictReader(f)\n",
    "        for line in data:\n",
    "            raw_id = line['frame_id']\n",
    "            cleaned_id = raw_id[len('video'):]\n",
    "            yield int(cleaned_id), line['frame_path_1'], line['frame_path_2'], line['frame_path_3'], line['frame_path_4']\n",
    "\n",
    "frame_loader_pipeline = (\n",
    "    pipe.input('csv_file')\n",
    "    .flat_map('csv_file', ('frame_id', 'f_path_1', 'f_path_2','f_path_3', 'f_path_4'), read_frame_loader_csv)\n",
    "    .map('f_path_1', 'img1', ops.image_decode.cv2('rgb'))\n",
    "    .map('f_path_2', 'img2', ops.image_decode.cv2('rgb'))\n",
    "    .map('f_path_3', 'img3', ops.image_decode.cv2('rgb'))\n",
    "    .map('f_path_4', 'img4', ops.image_decode.cv2('rgb'))\n",
    "    .map('img1', 'vec1', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='image', device='mps'))\n",
    "    .map('img2', 'vec2', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='image', device='mps'))\n",
    "    .map('img3', 'vec3', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='image', device='mps'))\n",
    "    .map('img4', 'vec4', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='image', device='mps'))\n",
    "    .map(('vec1', 'vec2', 'vec3', 'vec4'), 'vec', lambda v1, v2, v3, v4: np.mean([v1, v2, v3, v4], axis=0))\n",
    "    .map('vec', 'vec', lambda x: x / np.linalg.norm(x))\n",
    "    .map(('frame_id', 'vec'), (), ops.ann_insert.milvus_client(collection_name=FRAME_RET_COLLECTION))\n",
    "    .output()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d352597e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 23:40:21,793 - 20839493632 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2025-04-16 23:40:21,793 - 21464379392 - node.py-node:167 - INFO: Begin to run Node-read_frame_loader_csv-0\n",
      "2025-04-16 23:40:21,793 - 21481205760 - node.py-node:167 - INFO: Begin to run Node-image-decode/cv2-1\n",
      "2025-04-16 23:40:21,794 - 21498032128 - node.py-node:167 - INFO: Begin to run Node-image-decode/cv2-2\n",
      "2025-04-16 23:40:21,794 - 21514858496 - node.py-node:167 - INFO: Begin to run Node-image-decode/cv2-3\n",
      "2025-04-16 23:40:21,794 - 21531684864 - node.py-node:167 - INFO: Begin to run Node-image-decode/cv2-4\n",
      "2025-04-16 23:40:21,795 - 20839493632 - node.py-node:167 - INFO: Begin to run Node-image-text-embedding/clip-5\n",
      "2025-04-16 23:40:21,795 - 21565337600 - node.py-node:167 - INFO: Begin to run Node-image-text-embedding/clip-6\n",
      "2025-04-16 23:40:21,796 - 21582163968 - node.py-node:167 - INFO: Begin to run Node-image-text-embedding/clip-7\n",
      "2025-04-16 23:40:21,796 - 21548511232 - node.py-node:167 - INFO: Begin to run Node-image-text-embedding/clip-8\n",
      "2025-04-16 23:40:21,796 - 21598990336 - node.py-node:167 - INFO: Begin to run Node-lambda-9\n",
      "2025-04-16 23:40:21,797 - 21615816704 - node.py-node:167 - INFO: Begin to run Node-lambda-10\n",
      "2025-04-16 23:40:21,797 - 21632643072 - node.py-node:167 - INFO: Begin to run Node-ann-insert/milvus-client-11\n",
      "2025-04-16 23:40:21,798 - 21649469440 - node.py-node:167 - INFO: Begin to run Node-_output\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<towhee.runtime.data_queue.DataQueue at 0x39ed33ac0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_loader_pipeline(MSRVTT_SAMPLES_WITH_FRAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "641f13e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 23:43:48,678 - 8454604864 - clip.py-clip:100 - WARNING: Gpu not available, use cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 23:43:48,760 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:43:48,845 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:43:48,878 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "2025-04-16 23:43:48,881 - 18807287808 - connectionpool.py-connectionpool:1049 - DEBUG: Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-16 23:43:48,971 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:43:48,994 - 18807287808 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16 HTTP/1.1\" 200 3499\n",
      "2025-04-16 23:43:49,102 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:43:49,118 - 18807287808 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/main HTTP/1.1\" 200 3099\n",
      "2025-04-16 23:43:49,141 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 23:43:49,213 - 18807287808 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/discussions?p=0 HTTP/1.1\" 200 6380\n",
      "2025-04-16 23:43:49,248 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "2025-04-16 23:43:49,265 - 18807287808 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/refs%2Fpr%2F10 HTTP/1.1\" 200 4064\n",
      "2025-04-16 23:43:49,279 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.json HTTP/1.1\" 404 0\n",
      "2025-04-16 23:43:49,311 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.jinja HTTP/1.1\" 404 0\n",
      "2025-04-16 23:43:49,405 - 18807287808 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors.index.json HTTP/1.1\" 404 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 23:43:49,679 - 18807287808 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors HTTP/1.1\" 302 0\n"
     ]
    }
   ],
   "source": [
    "def read_frame_search_csv(csv_file):\n",
    "    with open(csv_file, 'r', encoding='utf-8-sig') as f:\n",
    "        data = csv.DictReader(f)\n",
    "        for line in data:\n",
    "            yield line['frame_id'], line['sentence']\n",
    "            \n",
    "frame_search_pipeline = (\n",
    "    pipe.input('csv_file')\n",
    "    .flat_map('csv_file', ('rel_frame_id', 'query'), read_frame_search_csv)\n",
    "    .map('query', 'vec', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='text', device='mps'))\n",
    "    .map('vec', 'vec', lambda x: x / np.linalg.norm(x))\n",
    "    .map('vec', 'top10_raw_res', ops.ann_search.milvus_client(collection_name=FRAME_RET_COLLECTION, limit=10))\n",
    "    # .map('vec', 'top10_raw_res', \n",
    "    #      ops.ann_search.milvus_client(collection_name=VIDEO_RET_COLLECTION, limit=10))\n",
    "    .map('top10_raw_res', ('top1', 'top5', 'top10'), lambda x: (x[:1], x[:5], x[:10]))\n",
    "    .output('rel_frame_id', 'query', 'top1', 'top5', 'top10')\n",
    "    # .output('vec')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df641753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 23:43:52,744 - 18807287808 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2025-04-16 23:43:52,768 - 18842988544 - node.py-node:167 - INFO: Begin to run Node-read_frame_search_csv-0\n",
      "2025-04-16 23:43:52,779 - 18859814912 - node.py-node:167 - INFO: Begin to run Node-image-text-embedding/clip-1\n",
      "2025-04-16 23:43:52,781 - 18876641280 - node.py-node:167 - INFO: Begin to run Node-lambda-2\n",
      "2025-04-16 23:43:52,783 - 18893467648 - node.py-node:167 - INFO: Begin to run Node-ann-search/milvus-client-3\n",
      "2025-04-16 23:43:52,838 - 18910294016 - node.py-node:167 - INFO: Begin to run Node-lambda-4\n",
      "2025-04-16 23:43:52,838 - 18807287808 - node.py-node:167 - INFO: Begin to run Node-_output\n"
     ]
    }
   ],
   "source": [
    "ret_dc = DataCollection(frame_search_pipeline(MSRVTT_SAMPLES_WITH_FRAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dab70054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border-collapse: collapse;\"><tr><th style=\"text-align: center; font-size: 130%; border: none;\">rel_frame_id</th> <th style=\"text-align: center; font-size: 130%; border: none;\">query</th> <th style=\"text-align: center; font-size: 130%; border: none;\">top1</th> <th style=\"text-align: center; font-size: 130%; border: none;\">top5</th> <th style=\"text-align: center; font-size: 130%; border: none;\">top10</th></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video7579</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">a girl wearing red top and black trouser is putting a sweater on a dog</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7579, 1.3646539449691772]] len=1</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7579, 1.3646539449691772],[9451, 1.4305797815322876],[9603, 1.4387223720550537],[9405, 1.4451756477355957],...] len=5</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7579, 1.3646539449691772],[9451, 1.4305797815322876],[9603, 1.4387223720550537],[9405, 1.4451756477355957],...] len=10</td></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video7725</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">young people sit around the edges of a room clapping and raising their arms while others dance in the center during a party</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[8441, 1.4233133792877197]] len=1</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[8441, 1.4233133792877197],[7444, 1.4263453483581543],[7725, 1.4346461296081543],[8339, 1.4430490732192993],...] len=5</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[8441, 1.4233133792877197],[7444, 1.4263453483581543],[7725, 1.4346461296081543],[8339, 1.4430490732192993],...] len=10</td></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video9258</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">a person is using a phone</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9257, 1.4228744506835938]] len=1</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9257, 1.4228744506835938],[9697, 1.4255503416061401],[9829, 1.4330558776855469],[9258, 1.4334453344345093],...] len=5</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9257, 1.4228744506835938],[9697, 1.4255503416061401],[9829, 1.4330558776855469],[9258, 1.4334453344345093],...] len=10</td></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video7365</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">cartoon people are eating at a restaurant</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9777, 1.3961538076400757]] len=1</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9777, 1.3961538076400757],[7365, 1.4227542877197266],[9537, 1.4308252334594727],[7741, 1.4411455392837524],...] len=5</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9777, 1.3961538076400757],[7365, 1.4227542877197266],[9537, 1.4308252334594727],[7741, 1.4411455392837524],...] len=10</td></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video8068</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">a woman on a couch talks to a a man</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7724, 1.3794373273849487]] len=1</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7724, 1.3794373273849487],[7234, 1.4042013883590698],[7341, 1.4079279899597168],[9347, 1.408487319946289],...] len=5</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7724, 1.3794373273849487],[7234, 1.4042013883590698],[7341, 1.4079279899597168],[9347, 1.408487319946289],...] len=10</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ret_dc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b7c4181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO remove this, import from helpers and rerun the whole notebook\n",
    "\n",
    "def twohee_data_col_to_df(twohee_data_collection):\n",
    "    res_list = twohee_data_collection.to_list()\n",
    "    res_obj_list = []\n",
    "    for r in res_list:\n",
    "        res_obj = vars(r)\n",
    "        res_obj_list.append(res_obj)\n",
    "    res_df = pd.DataFrame(res_obj_list)\n",
    "    \n",
    "    # Add ground truth column\n",
    "    if 'rel_video_id' in res_df.columns:\n",
    "        res_df['ground_truth'] = res_df['rel_video_id'].apply(\n",
    "            lambda x: int(x[len('video'):]))\n",
    "    if 'rel_frame_id' in res_df.columns:\n",
    "        res_df['ground_truth'] = res_df['rel_frame_id'].apply(\n",
    "            lambda x: int(x[len('video'):]))\n",
    "    else:\n",
    "        raise ValueError(\"No rel_video_id or rel_frame_id found in the DataCollection\")\n",
    "    return res_df.copy()\n",
    "\n",
    "\n",
    "def average_precision(ground_truth, predictions):\n",
    "    \"\"\"\n",
    "    Calculate the Average Precision (AP) for a single query.\n",
    "\n",
    "    Args:\n",
    "        ground_truth (int): The ground truth video ID.\n",
    "        predictions (list): List of predicted video IDs.\n",
    "\n",
    "    Returns:\n",
    "        float: The Average Precision (AP) score for the query.\n",
    "    \"\"\"\n",
    "    hits = 0\n",
    "    sum_precision = 0\n",
    "    for i, pred in enumerate(predictions):\n",
    "        if pred == ground_truth:\n",
    "            hits += 1\n",
    "            sum_precision += hits / (i + 1)\n",
    "    return sum_precision / hits if hits > 0 else 0\n",
    "\n",
    "\n",
    "def calculate_mean_average_precision(df):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Average Precision (MAP) for the given dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing columns 'query', 'ground_truth', 'top1', 'top5', 'top10'.\n",
    "\n",
    "    Returns:\n",
    "        float: The Mean Average Precision (MAP) score.\n",
    "    \"\"\"\n",
    "    # Calculate AP for each query\n",
    "    ap_scores = []\n",
    "    for _, row in df.iterrows():\n",
    "        ground_truth = row['ground_truth']\n",
    "        predictions_with_scores = row['top10']\n",
    "        predictions = [pred[0] for pred in predictions_with_scores]\n",
    "        ap_scores.append(average_precision(ground_truth, predictions))\n",
    "\n",
    "    # Calculate MAP\n",
    "    mean_ap = sum(ap_scores) / len(ap_scores) if ap_scores else 0\n",
    "    return mean_ap\n",
    "\n",
    "\n",
    "def calculate_recall(df):\n",
    "    \"\"\"\n",
    "    Calculate recall@1, recall@5, and recall@10 for the given dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing columns 'query', 'ground_truth', 'top1', 'top5', 'top10'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing recall@1, recall@5, and recall@10.\n",
    "    \"\"\"\n",
    "    recall_at_1 = 0\n",
    "    recall_at_5 = 0\n",
    "    recall_at_10 = 0\n",
    "    total_queries = len(df)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        ground_truth = row['ground_truth']\n",
    "        if ground_truth in [pred[0] for pred in row['top1']]:\n",
    "            recall_at_1 += 1\n",
    "        if ground_truth in [pred[0] for pred in row['top5']]:\n",
    "            recall_at_5 += 1\n",
    "        if ground_truth in [pred[0] for pred in row['top10']]:\n",
    "            recall_at_10 += 1\n",
    "\n",
    "    return {\n",
    "        'recall@1': recall_at_1 / total_queries,\n",
    "        'recall@5': recall_at_5 / total_queries,\n",
    "        'recall@10': recall_at_10 / total_queries\n",
    "    }\n",
    "\n",
    "\n",
    "def ndcg_score(ground_truth, predictions, k=10):\n",
    "    \"\"\"\n",
    "    Calculate the Normalized Discounted Cumulative Gain (NDCG) for a single query.\n",
    "\n",
    "    Args:\n",
    "        ground_truth (int): The ground truth video ID.\n",
    "        predictions (list): List of predicted video IDs with scores [(id, score), ...].\n",
    "        k (int): The number of top predictions to consider.\n",
    "\n",
    "    Returns:\n",
    "        float: The NDCG score for the query.\n",
    "    \"\"\"\n",
    "    def dcg(relevance_scores):\n",
    "        return sum(rel / np.log2(idx + 2) for idx, rel in enumerate(relevance_scores))\n",
    "\n",
    "    # Relevance scores: 1 if the prediction matches the ground truth, else 0\n",
    "    relevance_scores = [1 if pred[0] ==\n",
    "                        ground_truth else 0 for pred in predictions[:k]]\n",
    "\n",
    "    # Calculate DCG and IDCG\n",
    "    actual_dcg = dcg(relevance_scores)\n",
    "    ideal_dcg = dcg(sorted(relevance_scores, reverse=True))\n",
    "\n",
    "    # Return NDCG\n",
    "    return actual_dcg / ideal_dcg if ideal_dcg > 0 else 0\n",
    "\n",
    "# call this function to get the NDCG score for each query\n",
    "\n",
    "\n",
    "def calculate_ndcg(df, k=10):\n",
    "    \"\"\"\n",
    "    Calculate NDCG for the given dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing columns 'query', 'ground_truth', 'top1', 'top5', 'top10'.\n",
    "        k (int): The number of top predictions to consider.\n",
    "\n",
    "    Returns:\n",
    "        float: The mean NDCG score.\n",
    "    \"\"\"\n",
    "    ndcg_scores = []\n",
    "    for _, row in df.iterrows():\n",
    "        ground_truth = row['ground_truth']\n",
    "        predictions_with_scores = row['top10']\n",
    "        ndcg_scores.append(ndcg_score(\n",
    "            ground_truth, predictions_with_scores, k))\n",
    "\n",
    "    return sum(ndcg_scores) / len(ndcg_scores) if ndcg_scores else 0\n",
    "\n",
    "\n",
    "def get_all_eval_scores(df):\n",
    "    \"\"\"Return a dataframe with all evaluation scores: Recall@1, Recall@5, Recall@10, MAP, NDCG@1, NDCG@5, NDCG@10\"\"\"\n",
    "    recall_scores = calculate_recall(df)\n",
    "    map_score = calculate_mean_average_precision(df)\n",
    "    ndcg_score_1 = calculate_ndcg(df, k=1)\n",
    "    ndcg_score_5 = calculate_ndcg(df, k=5)\n",
    "    ndcg_score_10 = calculate_ndcg(df, k=10)\n",
    "\n",
    "    eval_scores = {\n",
    "        'recall@1': recall_scores['recall@1'],\n",
    "        'recall@5': recall_scores['recall@5'],\n",
    "        'recall@10': recall_scores['recall@10'],\n",
    "        'map': map_score,\n",
    "        'ndcg@1': ndcg_score_1,\n",
    "        'ndcg@5': ndcg_score_5,\n",
    "        'ndcg@10': ndcg_score_10\n",
    "    }\n",
    "\n",
    "    return eval_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b8a22f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rel_frame_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "query",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "top1",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "top5",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "top10",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ground_truth",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8fe3e283-01bf-4fd5-8c6b-5946f6ad847e",
       "rows": [
        [
         "0",
         "video7579",
         "a girl wearing red top and black trouser is putting a sweater on a dog",
         "[[7579, 1.3646539449691772]]",
         "[[7579, 1.3646539449691772], [9451, 1.4305797815322876], [9603, 1.4387223720550537], [9405, 1.4451756477355957], [9034, 1.4529653787612915]]",
         "[[7579, 1.3646539449691772], [9451, 1.4305797815322876], [9603, 1.4387223720550537], [9405, 1.4451756477355957], [9034, 1.4529653787612915], [7361, 1.453911304473877], [7730, 1.4621329307556152], [9969, 1.4691641330718994], [8507, 1.4756416082382202], [9778, 1.4776570796966553]]",
         "7579"
        ],
        [
         "1",
         "video7725",
         "young people sit around the edges of a room clapping and raising their arms while others dance in the center during a party",
         "[[8441, 1.4233133792877197]]",
         "[[8441, 1.4233133792877197], [7444, 1.4263453483581543], [7725, 1.4346461296081543], [8339, 1.4430490732192993], [8556, 1.4516046047210693]]",
         "[[8441, 1.4233133792877197], [7444, 1.4263453483581543], [7725, 1.4346461296081543], [8339, 1.4430490732192993], [8556, 1.4516046047210693], [9222, 1.4689582586288452], [7756, 1.469283938407898], [7141, 1.4699264764785767], [9063, 1.4703967571258545], [8014, 1.476288080215454]]",
         "7725"
        ],
        [
         "2",
         "video9258",
         "a person is using a phone",
         "[[9257, 1.4228744506835938]]",
         "[[9257, 1.4228744506835938], [9697, 1.4255503416061401], [9829, 1.4330558776855469], [9258, 1.4334453344345093], [8945, 1.4339852333068848]]",
         "[[9257, 1.4228744506835938], [9697, 1.4255503416061401], [9829, 1.4330558776855469], [9258, 1.4334453344345093], [8945, 1.4339852333068848], [7728, 1.4411003589630127], [7418, 1.445277452468872], [9404, 1.4467036724090576], [7687, 1.4467148780822754], [8311, 1.4506480693817139]]",
         "9258"
        ],
        [
         "3",
         "video7365",
         "cartoon people are eating at a restaurant",
         "[[9777, 1.3961538076400757]]",
         "[[9777, 1.3961538076400757], [7365, 1.4227542877197266], [9537, 1.4308252334594727], [7741, 1.4411455392837524], [8129, 1.4499781131744385]]",
         "[[9777, 1.3961538076400757], [7365, 1.4227542877197266], [9537, 1.4308252334594727], [7741, 1.4411455392837524], [8129, 1.4499781131744385], [8781, 1.453294277191162], [8911, 1.4561069011688232], [7977, 1.4608396291732788], [7835, 1.4636974334716797], [9814, 1.4656175374984741]]",
         "7365"
        ],
        [
         "4",
         "video8068",
         "a woman on a couch talks to a a man",
         "[[7724, 1.3794373273849487]]",
         "[[7724, 1.3794373273849487], [7234, 1.4042013883590698], [7341, 1.4079279899597168], [9347, 1.408487319946289], [7685, 1.4095332622528076]]",
         "[[7724, 1.3794373273849487], [7234, 1.4042013883590698], [7341, 1.4079279899597168], [9347, 1.408487319946289], [7685, 1.4095332622528076], [8783, 1.4151232242584229], [8068, 1.4156534671783447], [9793, 1.4178009033203125], [9023, 1.4215595722198486], [9517, 1.4226722717285156]]",
         "8068"
        ],
        [
         "5",
         "video7131",
         "athletes are getting ready and start running for an event",
         "[[8264, 1.4217565059661865]]",
         "[[8264, 1.4217565059661865], [7131, 1.4312196969985962], [8451, 1.46365487575531], [8817, 1.4688547849655151], [8322, 1.4826016426086426]]",
         "[[8264, 1.4217565059661865], [7131, 1.4312196969985962], [8451, 1.46365487575531], [8817, 1.4688547849655151], [8322, 1.4826016426086426], [9233, 1.4857631921768188], [7788, 1.4939593076705933], [7776, 1.4943857192993164], [8339, 1.5016645193099976], [8125, 1.5039379596710205]]",
         "7131"
        ],
        [
         "6",
         "video7213",
         "a woman is making lasagna",
         "[[7213, 1.3492412567138672]]",
         "[[7213, 1.3492412567138672], [7154, 1.3614212274551392], [7966, 1.3791182041168213], [8910, 1.3819410800933838], [7744, 1.3917193412780762]]",
         "[[7213, 1.3492412567138672], [7154, 1.3614212274551392], [7966, 1.3791182041168213], [8910, 1.3819410800933838], [7744, 1.3917193412780762], [8686, 1.3992156982421875], [9693, 1.4010158777236938], [7799, 1.4047950506210327], [8247, 1.4062485694885254], [7360, 1.4067637920379639]]",
         "7213"
        ],
        [
         "7",
         "video7575",
         "a man speaking in a microphone",
         "[[7828, 1.3630192279815674]]",
         "[[7828, 1.3630192279815674], [9203, 1.3866963386535645], [7491, 1.398766279220581], [9885, 1.400754451751709], [9690, 1.4053953886032104]]",
         "[[7828, 1.3630192279815674], [9203, 1.3866963386535645], [7491, 1.398766279220581], [9885, 1.400754451751709], [9690, 1.4053953886032104], [7575, 1.4088170528411865], [9474, 1.412929892539978], [8269, 1.4135000705718994], [7110, 1.4165470600128174], [9404, 1.422919511795044]]",
         "7575"
        ],
        [
         "8",
         "video7978",
         "a team with blue uniforms are playing badmitten with a team in white",
         "[[9647, 1.4360268115997314]]",
         "[[9647, 1.4360268115997314], [7788, 1.4455500841140747], [9013, 1.4638700485229492], [8817, 1.4669160842895508], [7021, 1.4825704097747803]]",
         "[[9647, 1.4360268115997314], [7788, 1.4455500841140747], [9013, 1.4638700485229492], [8817, 1.4669160842895508], [7021, 1.4825704097747803], [7500, 1.4826980829238892], [7153, 1.4840039014816284], [7839, 1.4861631393432617], [8652, 1.4862654209136963], [7723, 1.4881591796875]]",
         "7978"
        ],
        [
         "9",
         "video8123",
         "a woman is giving demo for baby trolley",
         "[[9755, 1.3558000326156616]]",
         "[[9755, 1.3558000326156616], [8123, 1.3574180603027344], [7230, 1.3631043434143066], [8258, 1.3656103610992432], [8018, 1.3822846412658691]]",
         "[[9755, 1.3558000326156616], [8123, 1.3574180603027344], [7230, 1.3631043434143066], [8258, 1.3656103610992432], [8018, 1.3822846412658691], [7827, 1.3919546604156494], [7217, 1.4005019664764404], [8899, 1.4017436504364014], [9405, 1.4302101135253906], [7364, 1.4536162614822388]]",
         "8123"
        ],
        [
         "10",
         "video9800",
         "a car is in a wreck",
         "[[9622, 1.346225619316101]]",
         "[[9622, 1.346225619316101], [7765, 1.395709753036499], [7965, 1.414044976234436], [7354, 1.4173258543014526], [8973, 1.4228099584579468]]",
         "[[9622, 1.346225619316101], [7765, 1.395709753036499], [7965, 1.414044976234436], [7354, 1.4173258543014526], [8973, 1.4228099584579468], [8934, 1.4256608486175537], [9800, 1.4275267124176025], [9511, 1.430391788482666], [9535, 1.4329254627227783], [8089, 1.4343602657318115]]",
         "9800"
        ],
        [
         "11",
         "video9205",
         "a woman interviewing about her part in a protest happening in brazil",
         "[[9205, 1.3994241952896118]]",
         "[[9205, 1.3994241952896118], [7364, 1.4493741989135742], [7341, 1.4549899101257324], [7680, 1.4634183645248413], [7822, 1.4660718441009521]]",
         "[[9205, 1.3994241952896118], [7364, 1.4493741989135742], [7341, 1.4549899101257324], [7680, 1.4634183645248413], [7822, 1.4660718441009521], [8311, 1.4668958187103271], [8333, 1.473061203956604], [9028, 1.4779269695281982], [7580, 1.4790550470352173], [8254, 1.479229211807251]]",
         "9205"
        ],
        [
         "12",
         "video7590",
         "an emotional scene of two persons where they are crying on meeting",
         "[[7590, 1.411278486251831]]",
         "[[7590, 1.411278486251831], [8974, 1.4274256229400635], [7619, 1.4276301860809326], [8879, 1.4311299324035645], [8349, 1.4333910942077637]]",
         "[[7590, 1.411278486251831], [8974, 1.4274256229400635], [7619, 1.4276301860809326], [8879, 1.4311299324035645], [8349, 1.4333910942077637], [9521, 1.4361556768417358], [9688, 1.4404585361480713], [8330, 1.4405243396759033], [7163, 1.4430930614471436], [9326, 1.4448920488357544]]",
         "7590"
        ],
        [
         "13",
         "video9017",
         "the man is driving his motorbike fast and having problems on the race",
         "[[9511, 1.382845401763916]]",
         "[[9511, 1.382845401763916], [8934, 1.3879225254058838], [7616, 1.3931431770324707], [9806, 1.395315408706665], [7214, 1.3959099054336548]]",
         "[[9511, 1.382845401763916], [8934, 1.3879225254058838], [7616, 1.3931431770324707], [9806, 1.395315408706665], [7214, 1.3959099054336548], [8657, 1.4006755352020264], [7765, 1.4047787189483643], [8089, 1.4049257040023804], [7544, 1.4069876670837402], [9017, 1.4071133136749268]]",
         "9017"
        ],
        [
         "14",
         "video9241",
         "japanese people laughing and dancing",
         "[[9131, 1.332502841949463]]",
         "[[9131, 1.332502841949463], [8349, 1.4050121307373047], [9682, 1.4088870286941528], [8118, 1.4093393087387085], [8129, 1.4157278537750244]]",
         "[[9131, 1.332502841949463], [8349, 1.4050121307373047], [9682, 1.4088870286941528], [8118, 1.4093393087387085], [8129, 1.4157278537750244], [8306, 1.4251346588134766], [8606, 1.4295445680618286], [8831, 1.4298814535140991], [8241, 1.4312283992767334], [8899, 1.432578444480896]]",
         "9241"
        ],
        [
         "15",
         "video7158",
         "fox news presidential debate recapping the gop debate with donald trump and ted cruz",
         "[[7158, 1.2899657487869263]]",
         "[[7158, 1.2899657487869263], [8464, 1.344756841659546], [7731, 1.3777096271514893], [9223, 1.395728588104248], [7234, 1.4169496297836304]]",
         "[[7158, 1.2899657487869263], [8464, 1.344756841659546], [7731, 1.3777096271514893], [9223, 1.395728588104248], [7234, 1.4169496297836304], [8789, 1.425482988357544], [7754, 1.4308781623840332], [7231, 1.4572131633758545], [7371, 1.47568678855896], [8824, 1.4758988618850708]]",
         "7158"
        ],
        [
         "16",
         "video9233",
         "a man is giving a speech",
         "[[7828, 1.3921784162521362]]",
         "[[7828, 1.3921784162521362], [9233, 1.3949718475341797], [9404, 1.397292971611023], [8346, 1.4003169536590576], [9203, 1.4131850004196167]]",
         "[[7828, 1.3921784162521362], [9233, 1.3949718475341797], [9404, 1.397292971611023], [8346, 1.4003169536590576], [9203, 1.4131850004196167], [9350, 1.4132790565490723], [8445, 1.4210104942321777], [7619, 1.422214150428772], [7110, 1.4237220287322998], [9829, 1.423805832862854]]",
         "9233"
        ],
        [
         "17",
         "video8687",
         "fast moving time is shown here",
         "[[8909, 1.4122499227523804]]",
         "[[8909, 1.4122499227523804], [8681, 1.4189213514328003], [8817, 1.4198246002197266], [8243, 1.42534601688385], [9511, 1.4262641668319702]]",
         "[[8909, 1.4122499227523804], [8681, 1.4189213514328003], [8817, 1.4198246002197266], [8243, 1.42534601688385], [9511, 1.4262641668319702], [9259, 1.4269914627075195], [8819, 1.428597092628479], [8934, 1.4290789365768433], [9305, 1.4299869537353516], [8687, 1.4308273792266846]]",
         "8687"
        ],
        [
         "18",
         "video9337",
         "some people are inside of a room",
         "[[9324, 1.411644697189331]]",
         "[[9324, 1.411644697189331], [8076, 1.4178072214126587], [9307, 1.4332964420318604], [8815, 1.437543272972107], [7149, 1.4389643669128418]]",
         "[[9324, 1.411644697189331], [8076, 1.4178072214126587], [9307, 1.4332964420318604], [8815, 1.437543272972107], [7149, 1.4389643669128418], [8486, 1.442048192024231], [7593, 1.442634105682373], [9878, 1.4426393508911133], [8340, 1.4432803392410278], [9237, 1.4444708824157715]]",
         "9337"
        ],
        [
         "19",
         "video9620",
         "outer space pictures that have parts of equipments in them with water droplets on it",
         "[[9620, 1.381562352180481]]",
         "[[9620, 1.381562352180481], [8674, 1.430824637413025], [7431, 1.4494998455047607], [9609, 1.4531407356262207], [7562, 1.4596211910247803]]",
         "[[9620, 1.381562352180481], [8674, 1.430824637413025], [7431, 1.4494998455047607], [9609, 1.4531407356262207], [7562, 1.4596211910247803], [7732, 1.466639757156372], [7178, 1.478424072265625], [7027, 1.4794209003448486], [8069, 1.482252836227417], [8071, 1.4877612590789795]]",
         "9620"
        ],
        [
         "20",
         "video7411",
         "jolly good music troop delivering a program and the lady is in good spirit",
         "[[9352, 1.497209072113037]]",
         "[[9352, 1.497209072113037], [8919, 1.497537612915039], [9357, 1.5123125314712524], [9908, 1.520127296447754], [7843, 1.5266269445419312]]",
         "[[9352, 1.497209072113037], [8919, 1.497537612915039], [9357, 1.5123125314712524], [9908, 1.520127296447754], [7843, 1.5266269445419312], [7827, 1.5275499820709229], [9745, 1.5337165594100952], [9131, 1.5353548526763916], [7772, 1.5403954982757568], [8317, 1.5410293340682983]]",
         "7411"
        ],
        [
         "21",
         "video8514",
         "a person is putting the vegetable in to the water and boil it",
         "[[8514, 1.3275465965270996]]",
         "[[8514, 1.3275465965270996], [9625, 1.3613979816436768], [9335, 1.364518404006958], [9639, 1.3754700422286987], [8300, 1.385040283203125]]",
         "[[8514, 1.3275465965270996], [9625, 1.3613979816436768], [9335, 1.364518404006958], [9639, 1.3754700422286987], [8300, 1.385040283203125], [9693, 1.3914488554000854], [7213, 1.3923559188842773], [7554, 1.3932116031646729], [7911, 1.3934228420257568], [7154, 1.3939614295959473]]",
         "8514"
        ],
        [
         "22",
         "video8481",
         "a woman is reporting on keds commercials",
         "[[8481, 1.3228449821472168]]",
         "[[8481, 1.3228449821472168], [8494, 1.4082932472229004], [8826, 1.43733811378479], [7724, 1.4405484199523926], [9600, 1.4420950412750244]]",
         "[[8481, 1.3228449821472168], [8494, 1.4082932472229004], [8826, 1.43733811378479], [7724, 1.4405484199523926], [9600, 1.4420950412750244], [7231, 1.4474940299987793], [8254, 1.4498069286346436], [9503, 1.4536309242248535], [9575, 1.4541362524032593], [9347, 1.456803321838379]]",
         "8481"
        ],
        [
         "23",
         "video9224",
         "someone is playing a game",
         "[[7780, 1.4332605600357056]]",
         "[[7780, 1.4332605600357056], [9829, 1.4345611333847046], [8811, 1.4429991245269775], [7354, 1.4488399028778076], [7166, 1.458106279373169]]",
         "[[7780, 1.4332605600357056], [9829, 1.4345611333847046], [8811, 1.4429991245269775], [7354, 1.4488399028778076], [7166, 1.458106279373169], [8488, 1.4636316299438477], [8075, 1.4652705192565918], [8979, 1.4663074016571045], [8323, 1.4663101434707642], [8267, 1.4663292169570923]]",
         "9224"
        ],
        [
         "24",
         "video8426",
         "cabins on a sandy beach have walkways going up to their porches",
         "[[8426, 1.3408877849578857]]",
         "[[8426, 1.3408877849578857], [9359, 1.4784421920776367], [9332, 1.4839214086532593], [9244, 1.4926514625549316], [9253, 1.4957153797149658]]",
         "[[8426, 1.3408877849578857], [9359, 1.4784421920776367], [9332, 1.4839214086532593], [9244, 1.4926514625549316], [9253, 1.4957153797149658], [9338, 1.499864101409912], [8895, 1.5012892484664917], [7174, 1.507659912109375], [7155, 1.5088838338851929], [9031, 1.510891079902649]]",
         "8426"
        ],
        [
         "25",
         "video9699",
         "a man explains how to do a experiment",
         "[[9699, 1.3425610065460205]]",
         "[[9699, 1.3425610065460205], [8483, 1.3647879362106323], [8834, 1.3700191974639893], [9335, 1.3748912811279297], [8067, 1.3763622045516968]]",
         "[[9699, 1.3425610065460205], [8483, 1.3647879362106323], [8834, 1.3700191974639893], [9335, 1.3748912811279297], [8067, 1.3763622045516968], [7966, 1.37884521484375], [7546, 1.378852128982544], [8774, 1.378951072692871], [9249, 1.3817291259765625], [7110, 1.3823152780532837]]",
         "9699"
        ],
        [
         "26",
         "video9882",
         "a news reader is reading the news and asking question to some people",
         "[[9205, 1.3645951747894287]]",
         "[[9205, 1.3645951747894287], [9204, 1.3694454431533813], [8333, 1.370316743850708], [8311, 1.376706838607788], [8822, 1.385411262512207]]",
         "[[9205, 1.3645951747894287], [9204, 1.3694454431533813], [8333, 1.370316743850708], [8311, 1.376706838607788], [8822, 1.385411262512207], [7469, 1.3891382217407227], [7790, 1.394501805305481], [8022, 1.4051092863082886], [9223, 1.4052284955978394], [7967, 1.4072967767715454]]",
         "9882"
        ],
        [
         "27",
         "video8300",
         "a woman pours water into her pot of meat then tomato sauce and stirs it all around while talking",
         "[[8300, 1.3149280548095703]]",
         "[[8300, 1.3149280548095703], [7744, 1.3330907821655273], [8910, 1.3388526439666748], [8772, 1.3468986749649048], [9335, 1.3575448989868164]]",
         "[[8300, 1.3149280548095703], [7744, 1.3330907821655273], [8910, 1.3388526439666748], [8772, 1.3468986749649048], [9335, 1.3575448989868164], [9689, 1.3750653266906738], [8654, 1.376861810684204], [9693, 1.3778352737426758], [9022, 1.3887939453125], [7565, 1.389824390411377]]",
         "8300"
        ],
        [
         "28",
         "video8863",
         "an animated girl talks to a baby and plays with it",
         "[[8676, 1.3744807243347168]]",
         "[[8676, 1.3744807243347168], [9777, 1.378342866897583], [8863, 1.381762981414795], [8123, 1.386659026145935], [7020, 1.391669511795044]]",
         "[[8676, 1.3744807243347168], [9777, 1.378342866897583], [8863, 1.381762981414795], [8123, 1.386659026145935], [7020, 1.391669511795044], [7179, 1.3950459957122803], [7230, 1.4038763046264648], [8478, 1.4058849811553955], [9256, 1.4078724384307861], [9231, 1.4088190793991089]]",
         "8863"
        ],
        [
         "29",
         "video7147",
         "a man cooks burgers and bacon on a grill",
         "[[7147, 1.3049933910369873]]",
         "[[7147, 1.3049933910369873], [9333, 1.317720651626587], [7154, 1.386624813079834], [8834, 1.3919003009796143], [9335, 1.3975580930709839]]",
         "[[7147, 1.3049933910369873], [9333, 1.317720651626587], [7154, 1.386624813079834], [8834, 1.3919003009796143], [9335, 1.3975580930709839], [9694, 1.4024529457092285], [7820, 1.4073829650878906], [8300, 1.4224793910980225], [7966, 1.4248799085617065], [7799, 1.432102918624878]]",
         "7147"
        ],
        [
         "30",
         "video7744",
         "a chef stirs up some ingredients inside of a pan",
         "[[9335, 1.2784157991409302]]",
         "[[9335, 1.2784157991409302], [7966, 1.3027151823043823], [8514, 1.3229398727416992], [7799, 1.332653522491455], [9693, 1.33266019821167]]",
         "[[9335, 1.2784157991409302], [7966, 1.3027151823043823], [8514, 1.3229398727416992], [7799, 1.332653522491455], [9693, 1.33266019821167], [7744, 1.3424474000930786], [7554, 1.3443849086761475], [8300, 1.3481532335281372], [9625, 1.348660945892334], [8483, 1.3493216037750244]]",
         "7744"
        ],
        [
         "31",
         "video7839",
         "this is a vine sports compilation",
         "[[8979, 1.2923836708068848]]",
         "[[8979, 1.2923836708068848], [9029, 1.3030606508255005], [8253, 1.3152722120285034], [7787, 1.321333408355713], [8913, 1.3216372728347778]]",
         "[[8979, 1.2923836708068848], [9029, 1.3030606508255005], [8253, 1.3152722120285034], [7787, 1.321333408355713], [8913, 1.3216372728347778], [9605, 1.3303425312042236], [7358, 1.336706280708313], [7839, 1.3372600078582764], [7112, 1.3378232717514038], [9018, 1.3385226726531982]]",
         "7839"
        ],
        [
         "32",
         "video7214",
         "race cars of different colors lined up on a dark track",
         "[[8689, 1.4301421642303467]]",
         "[[8689, 1.4301421642303467], [7464, 1.44502592086792], [7214, 1.4482390880584717], [9691, 1.45964515209198], [9832, 1.460724115371704]]",
         "[[8689, 1.4301421642303467], [7464, 1.44502592086792], [7214, 1.4482390880584717], [9691, 1.45964515209198], [9832, 1.460724115371704], [8473, 1.4699145555496216], [9328, 1.473738431930542], [7616, 1.480024814605713], [8817, 1.4810773134231567], [9535, 1.483282446861267]]",
         "7214"
        ],
        [
         "33",
         "video7771",
         "a golf player is trying to hit the ball into the pit",
         "[[7771, 1.3148136138916016]]",
         "[[7771, 1.3148136138916016], [7021, 1.4089388847351074], [8125, 1.4340282678604126], [7699, 1.449831247329712], [8049, 1.4503422975540161]]",
         "[[7771, 1.3148136138916016], [7021, 1.4089388847351074], [8125, 1.4340282678604126], [7699, 1.449831247329712], [8049, 1.4503422975540161], [7788, 1.451645016670227], [8816, 1.4560141563415527], [7357, 1.4574912786483765], [9832, 1.4600048065185547], [8665, 1.46107017993927]]",
         "7771"
        ],
        [
         "34",
         "video8486",
         "a cartoon on a young guy cursing",
         "[[8486, 1.3734201192855835]]",
         "[[8486, 1.3734201192855835], [9777, 1.3988442420959473], [7160, 1.4214977025985718], [7741, 1.4233741760253906], [7977, 1.4264628887176514]]",
         "[[8486, 1.3734201192855835], [9777, 1.3988442420959473], [7160, 1.4214977025985718], [7741, 1.4233741760253906], [7977, 1.4264628887176514], [7912, 1.426673173904419], [7172, 1.434866189956665], [8673, 1.436368703842163], [8911, 1.439018964767456], [9206, 1.4419771432876587]]",
         "8486"
        ],
        [
         "35",
         "video9909",
         "a crowd of people sitting next to each other as one man plays a video game",
         "[[9909, 1.38607919216156]]",
         "[[9909, 1.38607919216156], [8689, 1.3902208805084229], [8472, 1.3963571786880493], [8313, 1.4294995069503784], [9350, 1.4405078887939453]]",
         "[[9909, 1.38607919216156], [8689, 1.3902208805084229], [8472, 1.3963571786880493], [8313, 1.4294995069503784], [9350, 1.4405078887939453], [7685, 1.442232370376587], [8459, 1.442596435546875], [8116, 1.443664312362671], [7141, 1.4456746578216553], [9224, 1.4465584754943848]]",
         "9909"
        ],
        [
         "36",
         "video8922",
         "an old man shakes hands with another man and then they hug each other",
         "[[7200, 1.4053401947021484]]",
         "[[7200, 1.4053401947021484], [7362, 1.4301306009292603], [8922, 1.4339680671691895], [8652, 1.4426453113555908], [7590, 1.444905400276184]]",
         "[[7200, 1.4053401947021484], [7362, 1.4301306009292603], [8922, 1.4339680671691895], [8652, 1.4426453113555908], [7590, 1.444905400276184], [8016, 1.4477195739746094], [7110, 1.4506148099899292], [8899, 1.4520611763000488], [9520, 1.4536347389221191], [7158, 1.457543134689331]]",
         "8922"
        ],
        [
         "37",
         "video9814",
         "a scene from spongebob squarepants where the townspeople are carrying torches and chasing a giant squidward",
         "[[9814, 1.3468403816223145]]",
         "[[9814, 1.3468403816223145], [7835, 1.3818392753601074], [8916, 1.386263370513916], [8128, 1.388279676437378], [7235, 1.3908449411392212]]",
         "[[9814, 1.3468403816223145], [7835, 1.3818392753601074], [8916, 1.386263370513916], [8128, 1.388279676437378], [7235, 1.3908449411392212], [7111, 1.3982203006744385], [8673, 1.4017025232315063], [7029, 1.4092907905578613], [7218, 1.4172954559326172], [8817, 1.4200598001480103]]",
         "9814"
        ],
        [
         "38",
         "video9368",
         "someone demonstrates about the small motor uses to the video",
         "[[9696, 1.3573471307754517]]",
         "[[9696, 1.3573471307754517], [8626, 1.3599284887313843], [7688, 1.3626848459243774], [8622, 1.3759047985076904], [7369, 1.3856606483459473]]",
         "[[9696, 1.3573471307754517], [8626, 1.3599284887313843], [7688, 1.3626848459243774], [8622, 1.3759047985076904], [7369, 1.3856606483459473], [9368, 1.386144995689392], [7363, 1.3871097564697266], [9755, 1.392714262008667], [9508, 1.392979383468628], [7765, 1.3933231830596924]]",
         "9368"
        ],
        [
         "39",
         "video8820",
         "a person comes up in the hill on a orange motor bike and falls down",
         "[[9511, 1.3748786449432373]]",
         "[[9511, 1.3748786449432373], [7616, 1.4077422618865967], [8125, 1.4101386070251465], [8820, 1.4138493537902832], [9800, 1.4170931577682495]]",
         "[[9511, 1.3748786449432373], [7616, 1.4077422618865967], [8125, 1.4101386070251465], [8820, 1.4138493537902832], [9800, 1.4170931577682495], [9323, 1.4194867610931396], [8934, 1.420248031616211], [9622, 1.4210127592086792], [7649, 1.4301064014434814], [9773, 1.4420807361602783]]",
         "8820"
        ],
        [
         "40",
         "video9452",
         "an animated grey shark in the middle of a blue water simulation background rotating in a circle on the screen of a monitor",
         "[[9452, 1.2844328880310059]]",
         "[[9452, 1.2844328880310059], [8909, 1.3409173488616943], [8328, 1.3796908855438232], [8111, 1.4062411785125732], [7061, 1.4116237163543701]]",
         "[[9452, 1.2844328880310059], [8909, 1.3409173488616943], [8328, 1.3796908855438232], [8111, 1.4062411785125732], [7061, 1.4116237163543701], [7027, 1.4218125343322754], [8010, 1.428774118423462], [7900, 1.4330235719680786], [9620, 1.43983793258667], [9236, 1.4408626556396484]]",
         "9452"
        ],
        [
         "41",
         "video9344",
         "gameplay footage of someone playing a game",
         "[[9452, 1.34981107711792]]",
         "[[9452, 1.34981107711792], [7780, 1.3512439727783203], [9795, 1.3526318073272705], [8313, 1.356750249862671], [9336, 1.3576136827468872]]",
         "[[9452, 1.34981107711792], [7780, 1.3512439727783203], [9795, 1.3526318073272705], [8313, 1.356750249862671], [9336, 1.3576136827468872], [7919, 1.361295223236084], [9224, 1.364799976348877], [8027, 1.3649219274520874], [9035, 1.365583062171936], [8116, 1.3665223121643066]]",
         "9344"
        ],
        [
         "42",
         "video9032",
         "a hospital mortuary room and a doctor treat the special case",
         "[[9032, 1.3952785730361938]]",
         "[[9032, 1.3952785730361938], [8664, 1.405979871749878], [8325, 1.4181400537490845], [7963, 1.4261212348937988], [8129, 1.4289873838424683]]",
         "[[9032, 1.3952785730361938], [8664, 1.405979871749878], [8325, 1.4181400537490845], [7963, 1.4261212348937988], [8129, 1.4289873838424683], [7632, 1.4465961456298828], [8620, 1.4473921060562134], [7829, 1.449157476425171], [9579, 1.4504411220550537], [8606, 1.4525201320648193]]",
         "9032"
        ],
        [
         "43",
         "video9016",
         "all persons are wearing bikini dresses and playing in sea",
         "[[7117, 1.390992522239685]]",
         "[[7117, 1.390992522239685], [7025, 1.414297342300415], [9359, 1.416670322418213], [9338, 1.4312551021575928], [8999, 1.435294270515442]]",
         "[[7117, 1.390992522239685], [7025, 1.414297342300415], [9359, 1.416670322418213], [9338, 1.4312551021575928], [8999, 1.435294270515442], [7681, 1.4355136156082153], [8928, 1.4419418573379517], [9342, 1.4519363641738892], [8241, 1.460404634475708], [9201, 1.4604963064193726]]",
         "9016"
        ],
        [
         "44",
         "video9353",
         "two women are outside and are discussing something in a foreign language",
         "[[7724, 1.3936067819595337]]",
         "[[7724, 1.3936067819595337], [9871, 1.426619052886963], [8306, 1.4373626708984375], [9341, 1.439741849899292], [7116, 1.4449423551559448]]",
         "[[7724, 1.3936067819595337], [9871, 1.426619052886963], [8306, 1.4373626708984375], [9341, 1.439741849899292], [7116, 1.4449423551559448], [8895, 1.4493556022644043], [9039, 1.4539618492126465], [7149, 1.4551422595977783], [8016, 1.4596999883651733], [9353, 1.4614659547805786]]",
         "9353"
        ],
        [
         "45",
         "video9405",
         "red balloons float in the sky and have packages tied to them",
         "[[9405, 1.3394527435302734]]",
         "[[9405, 1.3394527435302734], [9680, 1.4422450065612793], [7061, 1.4756726026535034], [9246, 1.479779601097107], [9030, 1.479856014251709]]",
         "[[9405, 1.3394527435302734], [9680, 1.4422450065612793], [7061, 1.4756726026535034], [9246, 1.479779601097107], [9030, 1.479856014251709], [9807, 1.4804942607879639], [8945, 1.4857208728790283], [8260, 1.4858016967773438], [8339, 1.487975835800171], [8075, 1.4904497861862183]]",
         "9405"
        ],
        [
         "46",
         "video7559",
         "a man is trying some sushi",
         "[[7559, 1.4002225399017334]]",
         "[[7559, 1.4002225399017334], [8129, 1.4282807111740112], [8686, 1.4294345378875732], [9687, 1.431078314781189], [9537, 1.4322091341018677]]",
         "[[7559, 1.4002225399017334], [8129, 1.4282807111740112], [8686, 1.4294345378875732], [9687, 1.431078314781189], [9537, 1.4322091341018677], [7799, 1.4418543577194214], [7966, 1.4450618028640747], [8300, 1.4493285417556763], [9309, 1.4529409408569336], [9693, 1.4561989307403564]]",
         "7559"
        ],
        [
         "47",
         "video9063",
         "people on stage performing",
         "[[9063, 1.407305121421814]]",
         "[[9063, 1.407305121421814], [7558, 1.4194921255111694], [7156, 1.42177152633667], [8324, 1.4297935962677002], [8445, 1.4370970726013184]]",
         "[[9063, 1.407305121421814], [7558, 1.4194921255111694], [7156, 1.42177152633667], [8324, 1.4297935962677002], [8445, 1.4370970726013184], [9834, 1.4380996227264404], [8441, 1.4423902034759521], [7772, 1.445433497428894], [8466, 1.4503775835037231], [9304, 1.4561539888381958]]",
         "9063"
        ],
        [
         "48",
         "video7352",
         "a movie scene starring morgan freeman and men in armor running",
         "[[8475, 1.374740719795227]]",
         "[[8475, 1.374740719795227], [8122, 1.4032244682312012], [8061, 1.4098279476165771], [9742, 1.4124112129211426], [8948, 1.4155124425888062]]",
         "[[8475, 1.374740719795227], [8122, 1.4032244682312012], [8061, 1.4098279476165771], [9742, 1.4124112129211426], [8948, 1.4155124425888062], [9230, 1.4156315326690674], [7466, 1.4255940914154053], [8808, 1.426265001296997], [7352, 1.4311718940734863], [8266, 1.4354852437973022]]",
         "7352"
        ],
        [
         "49",
         "video8447",
         "a woman singing on the voice",
         "[[7569, 1.3199124336242676]]",
         "[[7569, 1.3199124336242676], [8265, 1.3233084678649902], [9222, 1.328627109527588], [9778, 1.3314499855041504], [9518, 1.3363654613494873]]",
         "[[7569, 1.3199124336242676], [8265, 1.3233084678649902], [9222, 1.328627109527588], [9778, 1.3314499855041504], [9518, 1.3363654613494873], [8818, 1.3368275165557861], [8810, 1.3381586074829102], [8447, 1.3449121713638306], [9304, 1.349623203277588], [9351, 1.3508051633834839]]",
         "8447"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 1000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rel_frame_id</th>\n",
       "      <th>query</th>\n",
       "      <th>top1</th>\n",
       "      <th>top5</th>\n",
       "      <th>top10</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video7579</td>\n",
       "      <td>a girl wearing red top and black trouser is pu...</td>\n",
       "      <td>[[7579, 1.3646539449691772]]</td>\n",
       "      <td>[[7579, 1.3646539449691772], [9451, 1.43057978...</td>\n",
       "      <td>[[7579, 1.3646539449691772], [9451, 1.43057978...</td>\n",
       "      <td>7579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video7725</td>\n",
       "      <td>young people sit around the edges of a room cl...</td>\n",
       "      <td>[[8441, 1.4233133792877197]]</td>\n",
       "      <td>[[8441, 1.4233133792877197], [7444, 1.42634534...</td>\n",
       "      <td>[[8441, 1.4233133792877197], [7444, 1.42634534...</td>\n",
       "      <td>7725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video9258</td>\n",
       "      <td>a person is using a phone</td>\n",
       "      <td>[[9257, 1.4228744506835938]]</td>\n",
       "      <td>[[9257, 1.4228744506835938], [9697, 1.42555034...</td>\n",
       "      <td>[[9257, 1.4228744506835938], [9697, 1.42555034...</td>\n",
       "      <td>9258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video7365</td>\n",
       "      <td>cartoon people are eating at a restaurant</td>\n",
       "      <td>[[9777, 1.3961538076400757]]</td>\n",
       "      <td>[[9777, 1.3961538076400757], [7365, 1.42275428...</td>\n",
       "      <td>[[9777, 1.3961538076400757], [7365, 1.42275428...</td>\n",
       "      <td>7365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video8068</td>\n",
       "      <td>a woman on a couch talks to a a man</td>\n",
       "      <td>[[7724, 1.3794373273849487]]</td>\n",
       "      <td>[[7724, 1.3794373273849487], [7234, 1.40420138...</td>\n",
       "      <td>[[7724, 1.3794373273849487], [7234, 1.40420138...</td>\n",
       "      <td>8068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>video7034</td>\n",
       "      <td>man in black shirt is holding a baby upside do...</td>\n",
       "      <td>[[9885, 1.4678269624710083]]</td>\n",
       "      <td>[[9885, 1.4678269624710083], [9320, 1.47455167...</td>\n",
       "      <td>[[9885, 1.4678269624710083], [9320, 1.47455167...</td>\n",
       "      <td>7034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>video7568</td>\n",
       "      <td>the queen of england is seen walking with an e...</td>\n",
       "      <td>[[7568, 1.2751219272613525]]</td>\n",
       "      <td>[[7568, 1.2751219272613525], [7116, 1.45783209...</td>\n",
       "      <td>[[7568, 1.2751219272613525], [7116, 1.45783209...</td>\n",
       "      <td>7568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>video7979</td>\n",
       "      <td>people talking about a fight</td>\n",
       "      <td>[[7211, 1.4365811347961426]]</td>\n",
       "      <td>[[7211, 1.4365811347961426], [7501, 1.43993902...</td>\n",
       "      <td>[[7211, 1.4365811347961426], [7501, 1.43993902...</td>\n",
       "      <td>7979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>video7356</td>\n",
       "      <td>a vehicle with details on what comes with it b...</td>\n",
       "      <td>[[7356, 1.3352746963500977]]</td>\n",
       "      <td>[[7356, 1.3352746963500977], [8819, 1.39669334...</td>\n",
       "      <td>[[7356, 1.3352746963500977], [8819, 1.39669334...</td>\n",
       "      <td>7356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>video8578</td>\n",
       "      <td>a man is commentating while playing minecraft</td>\n",
       "      <td>[[8077, 1.35731041431427]]</td>\n",
       "      <td>[[8077, 1.35731041431427], [8931, 1.3581938743...</td>\n",
       "      <td>[[8077, 1.35731041431427], [8931, 1.3581938743...</td>\n",
       "      <td>8578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    rel_frame_id                                              query  \\\n",
       "0      video7579  a girl wearing red top and black trouser is pu...   \n",
       "1      video7725  young people sit around the edges of a room cl...   \n",
       "2      video9258                          a person is using a phone   \n",
       "3      video7365          cartoon people are eating at a restaurant   \n",
       "4      video8068                a woman on a couch talks to a a man   \n",
       "..           ...                                                ...   \n",
       "995    video7034  man in black shirt is holding a baby upside do...   \n",
       "996    video7568  the queen of england is seen walking with an e...   \n",
       "997    video7979                       people talking about a fight   \n",
       "998    video7356  a vehicle with details on what comes with it b...   \n",
       "999    video8578      a man is commentating while playing minecraft   \n",
       "\n",
       "                             top1  \\\n",
       "0    [[7579, 1.3646539449691772]]   \n",
       "1    [[8441, 1.4233133792877197]]   \n",
       "2    [[9257, 1.4228744506835938]]   \n",
       "3    [[9777, 1.3961538076400757]]   \n",
       "4    [[7724, 1.3794373273849487]]   \n",
       "..                            ...   \n",
       "995  [[9885, 1.4678269624710083]]   \n",
       "996  [[7568, 1.2751219272613525]]   \n",
       "997  [[7211, 1.4365811347961426]]   \n",
       "998  [[7356, 1.3352746963500977]]   \n",
       "999    [[8077, 1.35731041431427]]   \n",
       "\n",
       "                                                  top5  \\\n",
       "0    [[7579, 1.3646539449691772], [9451, 1.43057978...   \n",
       "1    [[8441, 1.4233133792877197], [7444, 1.42634534...   \n",
       "2    [[9257, 1.4228744506835938], [9697, 1.42555034...   \n",
       "3    [[9777, 1.3961538076400757], [7365, 1.42275428...   \n",
       "4    [[7724, 1.3794373273849487], [7234, 1.40420138...   \n",
       "..                                                 ...   \n",
       "995  [[9885, 1.4678269624710083], [9320, 1.47455167...   \n",
       "996  [[7568, 1.2751219272613525], [7116, 1.45783209...   \n",
       "997  [[7211, 1.4365811347961426], [7501, 1.43993902...   \n",
       "998  [[7356, 1.3352746963500977], [8819, 1.39669334...   \n",
       "999  [[8077, 1.35731041431427], [8931, 1.3581938743...   \n",
       "\n",
       "                                                 top10  ground_truth  \n",
       "0    [[7579, 1.3646539449691772], [9451, 1.43057978...          7579  \n",
       "1    [[8441, 1.4233133792877197], [7444, 1.42634534...          7725  \n",
       "2    [[9257, 1.4228744506835938], [9697, 1.42555034...          9258  \n",
       "3    [[9777, 1.3961538076400757], [7365, 1.42275428...          7365  \n",
       "4    [[7724, 1.3794373273849487], [7234, 1.40420138...          8068  \n",
       "..                                                 ...           ...  \n",
       "995  [[9885, 1.4678269624710083], [9320, 1.47455167...          7034  \n",
       "996  [[7568, 1.2751219272613525], [7116, 1.45783209...          7568  \n",
       "997  [[7211, 1.4365811347961426], [7501, 1.43993902...          7979  \n",
       "998  [[7356, 1.3352746963500977], [8819, 1.39669334...          7356  \n",
       "999  [[8077, 1.35731041431427], [8931, 1.3581938743...          8578  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twohee_data_col_to_df(ret_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79ecce3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall@1': 0.311,\n",
       " 'recall@5': 0.537,\n",
       " 'recall@10': 0.651,\n",
       " 'map': 0.4118039682539681,\n",
       " 'ndcg@1': 0.311,\n",
       " 'ndcg@5': 0.4313712173413061,\n",
       " 'ndcg@10': 0.46854068360509477}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_eval_scores(twohee_data_col_to_df(ret_dc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b69532",
   "metadata": {},
   "source": [
    "# Try evaluation against queries from FIRE benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9ea2e1",
   "metadata": {},
   "source": [
    "We are working with a sample of MSR-VTT and our evaluation pipeline supports only one relevant query per video, hence we need to filter the full FIRE benchmark to only include videos we have sampled and ones with a single relevant result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31086197",
   "metadata": {},
   "source": [
    "FIRE_BENCHMARK_Q_JUDGEMENTS is created in the notebook `./clean_fire_judgements.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3c6413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 17:45:31,779 - 8454604864 - clip.py-clip:100 - WARNING: Gpu not available, use cpu\n",
      "2025-04-16 17:45:31,823 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 17:45:31,928 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 17:45:31,979 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "2025-04-16 17:45:32,042 - 17460719616 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16 HTTP/1.1\" 200 3499\n",
      "2025-04-16 17:45:32,094 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 17:45:32,188 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 17:45:32,236 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-16 17:45:32,315 - 17460719616 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/main HTTP/1.1\" 200 3099\n",
      "2025-04-16 17:45:32,358 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "2025-04-16 17:45:32,398 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.json HTTP/1.1\" 404 0\n",
      "2025-04-16 17:45:32,406 - 17460719616 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/discussions?p=0 HTTP/1.1\" 200 6380\n",
      "2025-04-16 17:45:32,439 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.jinja HTTP/1.1\" 404 0\n",
      "2025-04-16 17:45:32,539 - 17460719616 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/refs%2Fpr%2F10 HTTP/1.1\" 200 4064\n",
      "2025-04-16 17:45:32,586 - 17477545984 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2025-04-16 17:45:32,587 - 17494372352 - node.py-node:167 - INFO: Begin to run Node-read_frame_search_fire_csv-0\n",
      "2025-04-16 17:45:32,587 - 17511198720 - node.py-node:167 - INFO: Begin to run Node-image-text-embedding/clip-1\n",
      "2025-04-16 17:45:32,587 - 17528025088 - node.py-node:167 - INFO: Begin to run Node-lambda-2\n",
      "2025-04-16 17:45:32,587 - 17544851456 - node.py-node:167 - INFO: Begin to run Node-ann-search/milvus-client-3\n",
      "2025-04-16 17:45:32,587 - 17477545984 - node.py-node:167 - INFO: Begin to run Node-lambda-4\n",
      "2025-04-16 17:45:32,587 - 17561677824 - node.py-node:167 - INFO: Begin to run Node-_output\n",
      "2025-04-16 17:45:32,603 - 17460719616 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors.index.json HTTP/1.1\" 404 0\n",
      "2025-04-16 17:45:32,645 - 17460719616 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors HTTP/1.1\" 302 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border-collapse: collapse;\"><tr><th style=\"text-align: center; font-size: 130%; border: none;\">rel_frame_id</th> <th style=\"text-align: center; font-size: 130%; border: none;\">query</th> <th style=\"text-align: center; font-size: 130%; border: none;\">top1</th> <th style=\"text-align: center; font-size: 130%; border: none;\">top5</th> <th style=\"text-align: center; font-size: 130%; border: none;\">top10</th></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video8469</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">two parrots in a bird cage one white chick and on green adult</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[8469, 1.4449390172958374]] len=1</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[8469, 1.4449390172958374],[7849, 1.4497870206832886],[7822, 1.4854648113250732]] len=3</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[8469, 1.4449390172958374],[7849, 1.4497870206832886],[7822, 1.4854648113250732]] len=3</td></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video9687</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">a man chopping lobster and taking off the shell</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7820, 1.40888512134552]] len=1</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7820, 1.40888512134552],[9742, 1.4197094440460205],[9687, 1.4254179000854492]] len=3</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7820, 1.40888512134552],[9742, 1.4197094440460205],[9687, 1.4254179000854492]] len=3</td></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video7698</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">two women are walking in a parking lot</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7558, 1.4385546445846558]] len=1</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7558, 1.4385546445846558],[9039, 1.4457066059112549],[7698, 1.4519243240356445]] len=3</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7558, 1.4385546445846558],[9039, 1.4457066059112549],[7698, 1.4519243240356445]] len=3</td></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video9503</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">a woman is talking about how jeans with patches or rips is trendy</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9503, 1.4195761680603027]] len=1</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9503, 1.4195761680603027],[8825, 1.4488005638122559],[9039, 1.4948625564575195]] len=3</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9503, 1.4195761680603027],[8825, 1.4488005638122559],[9039, 1.4948625564575195]] len=3</td></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video8903</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">a naked child runs through a field</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9031, 1.3999378681182861]] len=1</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9031, 1.3999378681182861],[9805, 1.4242286682128906],[8125, 1.4620842933654785]] len=3</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9031, 1.3999378681182861],[9805, 1.4242286682128906],[8125, 1.4620842933654785]] len=3</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run query pipeline using FIRE\n",
    "\n",
    "\n",
    "# CSV parser function and pipeline recreated since the FIRE csv uses `video_id` instead of `frame_id`\n",
    "def read_frame_search_fire_csv(csv_file):\n",
    "    with open(csv_file, 'r', encoding='utf-8-sig') as f:\n",
    "        data = csv.DictReader(f)\n",
    "        for line in data:\n",
    "            yield line['video_id'], line['sentence']\n",
    "            \n",
    "frame_search_fire_pipeline = (\n",
    "    pipe.input('csv_file')\n",
    "    .flat_map('csv_file', ('rel_frame_id', 'query'), read_frame_search_fire_csv)\n",
    "    .map('query', 'vec', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='text', device='mps'))\n",
    "    .map('vec', 'vec', lambda x: x / np.linalg.norm(x))\n",
    "    .map('vec', 'top10_raw_res', ops.ann_search.milvus_client(collection_name=FRAME_RET_COLLECTION, limit=10))\n",
    "    .map('top10_raw_res', ('top1', 'top5', 'top10'), lambda x: (x[:1], x[:5], x[:10]))\n",
    "    .output('rel_frame_id', 'query', 'top1', 'top5', 'top10')\n",
    ")\n",
    "            \n",
    "fire_query_results = DataCollection(frame_search_fire_pipeline(FIRE_BENCHMARK_Q_JUDGEMENTS))\n",
    "fire_query_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d379d6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall@1': 0.3853503184713376,\n",
       " 'recall@5': 0.5222929936305732,\n",
       " 'recall@10': 0.5222929936305732,\n",
       " 'map': 0.4437367303609342,\n",
       " 'ndcg@1': 0.3853503184713376,\n",
       " 'ndcg@5': 0.46382902575068446,\n",
       " 'ndcg@10': 0.46382902575068446}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_eval_scores(twohee_data_col_to_df(fire_query_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info-ret-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
