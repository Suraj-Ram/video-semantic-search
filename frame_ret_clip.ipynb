{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb513f38",
   "metadata": {},
   "source": [
    "Video retrieval by embedding single frames using CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "769c33eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Milvus server at port 19530\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from towhee import ops, pipe, register\n",
    "from towhee.operator import PyOperator\n",
    "from towhee import DataCollection\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from helpers import milvus_utils\n",
    "from helpers.extract_frames import extract_frame, extract_n_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "33097668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "\n",
    "# Files\n",
    "MSRVTT_SAMPLES = \"./MSRVTT_1K.csv\"\n",
    "MSRVTT_SAMPLES_WITH_FRAMES = \"./MSRVTT_1K_frames.csv\"\n",
    "# file created using raw FIRE judgements, see clean_fire_judgements.ipynb\n",
    "FIRE_BENCHMARK_Q_JUDGEMENTS = \"./fire_benchmark_q_judgements.csv\" \n",
    "\n",
    "# Database Collections\n",
    "FRAME_RET_COLLECTION = \"msrvtt_multi_frame_ret_8b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62a84e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "video_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "video_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentence",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "dd9bd039-588f-4986-a7d6-5ec353b6159d",
       "rows": [
        [
         "0",
         "video7579",
         "./test_1k_compress/video7579.mp4",
         "a girl wearing red top and black trouser is putting a sweater on a dog"
        ],
        [
         "1",
         "video7725",
         "./test_1k_compress/video7725.mp4",
         "young people sit around the edges of a room clapping and raising their arms while others dance in the center during a party"
        ],
        [
         "2",
         "video9258",
         "./test_1k_compress/video9258.mp4",
         "a person is using a phone"
        ],
        [
         "3",
         "video7365",
         "./test_1k_compress/video7365.mp4",
         "cartoon people are eating at a restaurant"
        ],
        [
         "4",
         "video8068",
         "./test_1k_compress/video8068.mp4",
         "a woman on a couch talks to a a man"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_path</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video7579</td>\n",
       "      <td>./test_1k_compress/video7579.mp4</td>\n",
       "      <td>a girl wearing red top and black trouser is pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video7725</td>\n",
       "      <td>./test_1k_compress/video7725.mp4</td>\n",
       "      <td>young people sit around the edges of a room cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video9258</td>\n",
       "      <td>./test_1k_compress/video9258.mp4</td>\n",
       "      <td>a person is using a phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video7365</td>\n",
       "      <td>./test_1k_compress/video7365.mp4</td>\n",
       "      <td>cartoon people are eating at a restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video8068</td>\n",
       "      <td>./test_1k_compress/video8068.mp4</td>\n",
       "      <td>a woman on a couch talks to a a man</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    video_id                        video_path  \\\n",
       "0  video7579  ./test_1k_compress/video7579.mp4   \n",
       "1  video7725  ./test_1k_compress/video7725.mp4   \n",
       "2  video9258  ./test_1k_compress/video9258.mp4   \n",
       "3  video7365  ./test_1k_compress/video7365.mp4   \n",
       "4  video8068  ./test_1k_compress/video8068.mp4   \n",
       "\n",
       "                                            sentence  \n",
       "0  a girl wearing red top and black trouser is pu...  \n",
       "1  young people sit around the edges of a room cl...  \n",
       "2                          a person is using a phone  \n",
       "3          cartoon people are eating at a restaurant  \n",
       "4                a woman on a couch talks to a a man  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_samples_df = pd.read_csv(MSRVTT_SAMPLES)\n",
    "raw_samples_df[['video_id', 'video_path', 'sentence']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282b53af",
   "metadata": {},
   "source": [
    "Before we embed video frames, we need to extract and/or construct a single frame from each of the 1000 videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d171472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def extract_n_frames_2(video_path, output_folder, n=10):\n",
    "    \"\"\"\n",
    "    Extract n equally spaced frames from a video file and save them to a directory.\n",
    "    \n",
    "    Args:\n",
    "        video_path (str): Path to the input video file\n",
    "        output_folder (str): Path to the output directory to save frames\n",
    "        n (int): Number of equally spaced frames to extract (default: 10)\n",
    "    \"\"\"\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Open the video file\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get the total number of frames in the video\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Calculate the frame interval to get n equally spaced frames\n",
    "    if total_frames <= n:\n",
    "        # If video has fewer frames than requested, extract all frames\n",
    "        frame_indices = list(range(total_frames))\n",
    "    else:\n",
    "        # Calculate indices of equally spaced frames\n",
    "        frame_indices = [int(i * total_frames / n) for i in range(n)]\n",
    "    \n",
    "    # Get the video filename for naming the frames\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    \n",
    "    # Extract the frames at the calculated indices\n",
    "    for i, frame_index in enumerate(frame_indices):\n",
    "        # Set the video position to the desired frame\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "        \n",
    "        # Read the frame\n",
    "        ret, frame = video.read()\n",
    "        \n",
    "        # Break if frame reading failed\n",
    "        if not ret:\n",
    "            print(f\"Failed to read frame at index {frame_index}\")\n",
    "            continue\n",
    "        \n",
    "        # Generate the output filename\n",
    "        output_filename = f\"{video_name}_frame_{i+1:03d}_of_{n:03d}.jpg\"\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "        \n",
    "        # Save the frame as an image\n",
    "        cv2.imwrite(output_path, frame)\n",
    "    \n",
    "    # Release the video capture object\n",
    "    video.release()\n",
    "    \n",
    "    # Return the list of saved frame paths\n",
    "    frame_paths = [os.path.join(output_folder, f\"{video_name}_frame_{i+1:03d}_of_{n:03d}.jpg\") for i in range(len(frame_indices))]\n",
    "    return frame_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8657f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 8 per video...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:42<00:00, 23.54it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unnamed: 0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "key",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "vid_key",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "video_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "video_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "frame_path_1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "frame_path_2",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "frame_path_3",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "frame_path_4",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "frame_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "frame_path_5",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "frame_path_6",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "frame_path_7",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "frame_path_8",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e4ee5ec5-bbba-4dfe-b668-ad50c775e2c8",
       "rows": [
        [
         "0",
         "521",
         "ret521",
         "msr7579",
         "video7579",
         "a girl wearing red top and black trouser is putting a sweater on a dog",
         "./test_1k_compress/video7579.mp4",
         "./test_1k_images_8/video7579_frame_001_of_008.jpg",
         "./test_1k_images_8/video7579_frame_002_of_008.jpg",
         "./test_1k_images_8/video7579_frame_003_of_008.jpg",
         "./test_1k_images_8/video7579_frame_004_of_008.jpg",
         "video7579",
         "./test_1k_images_8/video7579_frame_005_of_008.jpg",
         "./test_1k_images_8/video7579_frame_006_of_008.jpg",
         "./test_1k_images_8/video7579_frame_007_of_008.jpg",
         "./test_1k_images_8/video7579_frame_008_of_008.jpg"
        ],
        [
         "1",
         "737",
         "ret737",
         "msr7725",
         "video7725",
         "young people sit around the edges of a room clapping and raising their arms while others dance in the center during a party",
         "./test_1k_compress/video7725.mp4",
         "./test_1k_images_8/video7725_frame_001_of_008.jpg",
         "./test_1k_images_8/video7725_frame_002_of_008.jpg",
         "./test_1k_images_8/video7725_frame_003_of_008.jpg",
         "./test_1k_images_8/video7725_frame_004_of_008.jpg",
         "video7725",
         "./test_1k_images_8/video7725_frame_005_of_008.jpg",
         "./test_1k_images_8/video7725_frame_006_of_008.jpg",
         "./test_1k_images_8/video7725_frame_007_of_008.jpg",
         "./test_1k_images_8/video7725_frame_008_of_008.jpg"
        ],
        [
         "2",
         "740",
         "ret740",
         "msr9258",
         "video9258",
         "a person is using a phone",
         "./test_1k_compress/video9258.mp4",
         "./test_1k_images_8/video9258_frame_001_of_008.jpg",
         "./test_1k_images_8/video9258_frame_002_of_008.jpg",
         "./test_1k_images_8/video9258_frame_003_of_008.jpg",
         "./test_1k_images_8/video9258_frame_004_of_008.jpg",
         "video9258",
         "./test_1k_images_8/video9258_frame_005_of_008.jpg",
         "./test_1k_images_8/video9258_frame_006_of_008.jpg",
         "./test_1k_images_8/video9258_frame_007_of_008.jpg",
         "./test_1k_images_8/video9258_frame_008_of_008.jpg"
        ],
        [
         "3",
         "660",
         "ret660",
         "msr7365",
         "video7365",
         "cartoon people are eating at a restaurant",
         "./test_1k_compress/video7365.mp4",
         "./test_1k_images_8/video7365_frame_001_of_008.jpg",
         "./test_1k_images_8/video7365_frame_002_of_008.jpg",
         "./test_1k_images_8/video7365_frame_003_of_008.jpg",
         "./test_1k_images_8/video7365_frame_004_of_008.jpg",
         "video7365",
         "./test_1k_images_8/video7365_frame_005_of_008.jpg",
         "./test_1k_images_8/video7365_frame_006_of_008.jpg",
         "./test_1k_images_8/video7365_frame_007_of_008.jpg",
         "./test_1k_images_8/video7365_frame_008_of_008.jpg"
        ],
        [
         "4",
         "411",
         "ret411",
         "msr8068",
         "video8068",
         "a woman on a couch talks to a a man",
         "./test_1k_compress/video8068.mp4",
         "./test_1k_images_8/video8068_frame_001_of_008.jpg",
         "./test_1k_images_8/video8068_frame_002_of_008.jpg",
         "./test_1k_images_8/video8068_frame_003_of_008.jpg",
         "./test_1k_images_8/video8068_frame_004_of_008.jpg",
         "video8068",
         "./test_1k_images_8/video8068_frame_005_of_008.jpg",
         "./test_1k_images_8/video8068_frame_006_of_008.jpg",
         "./test_1k_images_8/video8068_frame_007_of_008.jpg",
         "./test_1k_images_8/video8068_frame_008_of_008.jpg"
        ],
        [
         "5",
         "678",
         "ret678",
         "msr7131",
         "video7131",
         "athletes are getting ready and start running for an event",
         "./test_1k_compress/video7131.mp4",
         "./test_1k_images_8/video7131_frame_001_of_008.jpg",
         "./test_1k_images_8/video7131_frame_002_of_008.jpg",
         "./test_1k_images_8/video7131_frame_003_of_008.jpg",
         "./test_1k_images_8/video7131_frame_004_of_008.jpg",
         "video7131",
         "./test_1k_images_8/video7131_frame_005_of_008.jpg",
         "./test_1k_images_8/video7131_frame_006_of_008.jpg",
         "./test_1k_images_8/video7131_frame_007_of_008.jpg",
         "./test_1k_images_8/video7131_frame_008_of_008.jpg"
        ],
        [
         "6",
         "626",
         "ret626",
         "msr7213",
         "video7213",
         "a woman is making lasagna",
         "./test_1k_compress/video7213.mp4",
         "./test_1k_images_8/video7213_frame_001_of_008.jpg",
         "./test_1k_images_8/video7213_frame_002_of_008.jpg",
         "./test_1k_images_8/video7213_frame_003_of_008.jpg",
         "./test_1k_images_8/video7213_frame_004_of_008.jpg",
         "video7213",
         "./test_1k_images_8/video7213_frame_005_of_008.jpg",
         "./test_1k_images_8/video7213_frame_006_of_008.jpg",
         "./test_1k_images_8/video7213_frame_007_of_008.jpg",
         "./test_1k_images_8/video7213_frame_008_of_008.jpg"
        ],
        [
         "7",
         "513",
         "ret513",
         "msr7575",
         "video7575",
         "a man speaking in a microphone",
         "./test_1k_compress/video7575.mp4",
         "./test_1k_images_8/video7575_frame_001_of_008.jpg",
         "./test_1k_images_8/video7575_frame_002_of_008.jpg",
         "./test_1k_images_8/video7575_frame_003_of_008.jpg",
         "./test_1k_images_8/video7575_frame_004_of_008.jpg",
         "video7575",
         "./test_1k_images_8/video7575_frame_005_of_008.jpg",
         "./test_1k_images_8/video7575_frame_006_of_008.jpg",
         "./test_1k_images_8/video7575_frame_007_of_008.jpg",
         "./test_1k_images_8/video7575_frame_008_of_008.jpg"
        ],
        [
         "8",
         "859",
         "ret859",
         "msr7978",
         "video7978",
         "a team with blue uniforms are playing badmitten with a team in white",
         "./test_1k_compress/video7978.mp4",
         "./test_1k_images_8/video7978_frame_001_of_008.jpg",
         "./test_1k_images_8/video7978_frame_002_of_008.jpg",
         "./test_1k_images_8/video7978_frame_003_of_008.jpg",
         "./test_1k_images_8/video7978_frame_004_of_008.jpg",
         "video7978",
         "./test_1k_images_8/video7978_frame_005_of_008.jpg",
         "./test_1k_images_8/video7978_frame_006_of_008.jpg",
         "./test_1k_images_8/video7978_frame_007_of_008.jpg",
         "./test_1k_images_8/video7978_frame_008_of_008.jpg"
        ],
        [
         "9",
         "136",
         "ret136",
         "msr8123",
         "video8123",
         "a woman is giving demo for baby trolley",
         "./test_1k_compress/video8123.mp4",
         "./test_1k_images_8/video8123_frame_001_of_008.jpg",
         "./test_1k_images_8/video8123_frame_002_of_008.jpg",
         "./test_1k_images_8/video8123_frame_003_of_008.jpg",
         "./test_1k_images_8/video8123_frame_004_of_008.jpg",
         "video8123",
         "./test_1k_images_8/video8123_frame_005_of_008.jpg",
         "./test_1k_images_8/video8123_frame_006_of_008.jpg",
         "./test_1k_images_8/video8123_frame_007_of_008.jpg",
         "./test_1k_images_8/video8123_frame_008_of_008.jpg"
        ],
        [
         "10",
         "811",
         "ret811",
         "msr9800",
         "video9800",
         "a car is in a wreck",
         "./test_1k_compress/video9800.mp4",
         "./test_1k_images_8/video9800_frame_001_of_008.jpg",
         "./test_1k_images_8/video9800_frame_002_of_008.jpg",
         "./test_1k_images_8/video9800_frame_003_of_008.jpg",
         "./test_1k_images_8/video9800_frame_004_of_008.jpg",
         "video9800",
         "./test_1k_images_8/video9800_frame_005_of_008.jpg",
         "./test_1k_images_8/video9800_frame_006_of_008.jpg",
         "./test_1k_images_8/video9800_frame_007_of_008.jpg",
         "./test_1k_images_8/video9800_frame_008_of_008.jpg"
        ],
        [
         "11",
         "76",
         "ret76",
         "msr9205",
         "video9205",
         "a woman interviewing about her part in a protest happening in brazil",
         "./test_1k_compress/video9205.mp4",
         "./test_1k_images_8/video9205_frame_001_of_008.jpg",
         "./test_1k_images_8/video9205_frame_002_of_008.jpg",
         "./test_1k_images_8/video9205_frame_003_of_008.jpg",
         "./test_1k_images_8/video9205_frame_004_of_008.jpg",
         "video9205",
         "./test_1k_images_8/video9205_frame_005_of_008.jpg",
         "./test_1k_images_8/video9205_frame_006_of_008.jpg",
         "./test_1k_images_8/video9205_frame_007_of_008.jpg",
         "./test_1k_images_8/video9205_frame_008_of_008.jpg"
        ],
        [
         "12",
         "636",
         "ret636",
         "msr7590",
         "video7590",
         "an emotional scene of two persons where they are crying on meeting",
         "./test_1k_compress/video7590.mp4",
         "./test_1k_images_8/video7590_frame_001_of_008.jpg",
         "./test_1k_images_8/video7590_frame_002_of_008.jpg",
         "./test_1k_images_8/video7590_frame_003_of_008.jpg",
         "./test_1k_images_8/video7590_frame_004_of_008.jpg",
         "video7590",
         "./test_1k_images_8/video7590_frame_005_of_008.jpg",
         "./test_1k_images_8/video7590_frame_006_of_008.jpg",
         "./test_1k_images_8/video7590_frame_007_of_008.jpg",
         "./test_1k_images_8/video7590_frame_008_of_008.jpg"
        ],
        [
         "13",
         "973",
         "ret973",
         "msr9017",
         "video9017",
         "the man is driving his motorbike fast and having problems on the race",
         "./test_1k_compress/video9017.mp4",
         "./test_1k_images_8/video9017_frame_001_of_008.jpg",
         "./test_1k_images_8/video9017_frame_002_of_008.jpg",
         "./test_1k_images_8/video9017_frame_003_of_008.jpg",
         "./test_1k_images_8/video9017_frame_004_of_008.jpg",
         "video9017",
         "./test_1k_images_8/video9017_frame_005_of_008.jpg",
         "./test_1k_images_8/video9017_frame_006_of_008.jpg",
         "./test_1k_images_8/video9017_frame_007_of_008.jpg",
         "./test_1k_images_8/video9017_frame_008_of_008.jpg"
        ],
        [
         "14",
         "938",
         "ret938",
         "msr9241",
         "video9241",
         "japanese people laughing and dancing",
         "./test_1k_compress/video9241.mp4",
         "./test_1k_images_8/video9241_frame_001_of_008.jpg",
         "./test_1k_images_8/video9241_frame_002_of_008.jpg",
         "./test_1k_images_8/video9241_frame_003_of_008.jpg",
         "./test_1k_images_8/video9241_frame_004_of_008.jpg",
         "video9241",
         "./test_1k_images_8/video9241_frame_005_of_008.jpg",
         "./test_1k_images_8/video9241_frame_006_of_008.jpg",
         "./test_1k_images_8/video9241_frame_007_of_008.jpg",
         "./test_1k_images_8/video9241_frame_008_of_008.jpg"
        ],
        [
         "15",
         "899",
         "ret899",
         "msr7158",
         "video7158",
         "fox news presidential debate recapping the gop debate with donald trump and ted cruz",
         "./test_1k_compress/video7158.mp4",
         "./test_1k_images_8/video7158_frame_001_of_008.jpg",
         "./test_1k_images_8/video7158_frame_002_of_008.jpg",
         "./test_1k_images_8/video7158_frame_003_of_008.jpg",
         "./test_1k_images_8/video7158_frame_004_of_008.jpg",
         "video7158",
         "./test_1k_images_8/video7158_frame_005_of_008.jpg",
         "./test_1k_images_8/video7158_frame_006_of_008.jpg",
         "./test_1k_images_8/video7158_frame_007_of_008.jpg",
         "./test_1k_images_8/video7158_frame_008_of_008.jpg"
        ],
        [
         "16",
         "280",
         "ret280",
         "msr9233",
         "video9233",
         "a man is giving a speech",
         "./test_1k_compress/video9233.mp4",
         "./test_1k_images_8/video9233_frame_001_of_008.jpg",
         "./test_1k_images_8/video9233_frame_002_of_008.jpg",
         "./test_1k_images_8/video9233_frame_003_of_008.jpg",
         "./test_1k_images_8/video9233_frame_004_of_008.jpg",
         "video9233",
         "./test_1k_images_8/video9233_frame_005_of_008.jpg",
         "./test_1k_images_8/video9233_frame_006_of_008.jpg",
         "./test_1k_images_8/video9233_frame_007_of_008.jpg",
         "./test_1k_images_8/video9233_frame_008_of_008.jpg"
        ],
        [
         "17",
         "883",
         "ret883",
         "msr8687",
         "video8687",
         "fast moving time is shown here",
         "./test_1k_compress/video8687.mp4",
         "./test_1k_images_8/video8687_frame_001_of_008.jpg",
         "./test_1k_images_8/video8687_frame_002_of_008.jpg",
         "./test_1k_images_8/video8687_frame_003_of_008.jpg",
         "./test_1k_images_8/video8687_frame_004_of_008.jpg",
         "video8687",
         "./test_1k_images_8/video8687_frame_005_of_008.jpg",
         "./test_1k_images_8/video8687_frame_006_of_008.jpg",
         "./test_1k_images_8/video8687_frame_007_of_008.jpg",
         "./test_1k_images_8/video8687_frame_008_of_008.jpg"
        ],
        [
         "18",
         "761",
         "ret761",
         "msr9337",
         "video9337",
         "some people are inside of a room",
         "./test_1k_compress/video9337.mp4",
         "./test_1k_images_8/video9337_frame_001_of_008.jpg",
         "./test_1k_images_8/video9337_frame_002_of_008.jpg",
         "./test_1k_images_8/video9337_frame_003_of_008.jpg",
         "./test_1k_images_8/video9337_frame_004_of_008.jpg",
         "video9337",
         "./test_1k_images_8/video9337_frame_005_of_008.jpg",
         "./test_1k_images_8/video9337_frame_006_of_008.jpg",
         "./test_1k_images_8/video9337_frame_007_of_008.jpg",
         "./test_1k_images_8/video9337_frame_008_of_008.jpg"
        ],
        [
         "19",
         "319",
         "ret319",
         "msr9620",
         "video9620",
         "outer space pictures that have parts of equipments in them with water droplets on it",
         "./test_1k_compress/video9620.mp4",
         "./test_1k_images_8/video9620_frame_001_of_008.jpg",
         "./test_1k_images_8/video9620_frame_002_of_008.jpg",
         "./test_1k_images_8/video9620_frame_003_of_008.jpg",
         "./test_1k_images_8/video9620_frame_004_of_008.jpg",
         "video9620",
         "./test_1k_images_8/video9620_frame_005_of_008.jpg",
         "./test_1k_images_8/video9620_frame_006_of_008.jpg",
         "./test_1k_images_8/video9620_frame_007_of_008.jpg",
         "./test_1k_images_8/video9620_frame_008_of_008.jpg"
        ],
        [
         "20",
         "549",
         "ret549",
         "msr7411",
         "video7411",
         "jolly good music troop delivering a program and the lady is in good spirit",
         "./test_1k_compress/video7411.mp4",
         "./test_1k_images_8/video7411_frame_001_of_008.jpg",
         "./test_1k_images_8/video7411_frame_002_of_008.jpg",
         "./test_1k_images_8/video7411_frame_003_of_008.jpg",
         "./test_1k_images_8/video7411_frame_004_of_008.jpg",
         "video7411",
         "./test_1k_images_8/video7411_frame_005_of_008.jpg",
         "./test_1k_images_8/video7411_frame_006_of_008.jpg",
         "./test_1k_images_8/video7411_frame_007_of_008.jpg",
         "./test_1k_images_8/video7411_frame_008_of_008.jpg"
        ],
        [
         "21",
         "174",
         "ret174",
         "msr8514",
         "video8514",
         "a person is putting the vegetable in to the water and boil it",
         "./test_1k_compress/video8514.mp4",
         "./test_1k_images_8/video8514_frame_001_of_008.jpg",
         "./test_1k_images_8/video8514_frame_002_of_008.jpg",
         "./test_1k_images_8/video8514_frame_003_of_008.jpg",
         "./test_1k_images_8/video8514_frame_004_of_008.jpg",
         "video8514",
         "./test_1k_images_8/video8514_frame_005_of_008.jpg",
         "./test_1k_images_8/video8514_frame_006_of_008.jpg",
         "./test_1k_images_8/video8514_frame_007_of_008.jpg",
         "./test_1k_images_8/video8514_frame_008_of_008.jpg"
        ],
        [
         "22",
         "371",
         "ret371",
         "msr8481",
         "video8481",
         "a woman is reporting on keds commercials",
         "./test_1k_compress/video8481.mp4",
         "./test_1k_images_8/video8481_frame_001_of_008.jpg",
         "./test_1k_images_8/video8481_frame_002_of_008.jpg",
         "./test_1k_images_8/video8481_frame_003_of_008.jpg",
         "./test_1k_images_8/video8481_frame_004_of_008.jpg",
         "video8481",
         "./test_1k_images_8/video8481_frame_005_of_008.jpg",
         "./test_1k_images_8/video8481_frame_006_of_008.jpg",
         "./test_1k_images_8/video8481_frame_007_of_008.jpg",
         "./test_1k_images_8/video8481_frame_008_of_008.jpg"
        ],
        [
         "23",
         "527",
         "ret527",
         "msr9224",
         "video9224",
         "someone is playing a game",
         "./test_1k_compress/video9224.mp4",
         "./test_1k_images_8/video9224_frame_001_of_008.jpg",
         "./test_1k_images_8/video9224_frame_002_of_008.jpg",
         "./test_1k_images_8/video9224_frame_003_of_008.jpg",
         "./test_1k_images_8/video9224_frame_004_of_008.jpg",
         "video9224",
         "./test_1k_images_8/video9224_frame_005_of_008.jpg",
         "./test_1k_images_8/video9224_frame_006_of_008.jpg",
         "./test_1k_images_8/video9224_frame_007_of_008.jpg",
         "./test_1k_images_8/video9224_frame_008_of_008.jpg"
        ],
        [
         "24",
         "210",
         "ret210",
         "msr8426",
         "video8426",
         "cabins on a sandy beach have walkways going up to their porches",
         "./test_1k_compress/video8426.mp4",
         "./test_1k_images_8/video8426_frame_001_of_008.jpg",
         "./test_1k_images_8/video8426_frame_002_of_008.jpg",
         "./test_1k_images_8/video8426_frame_003_of_008.jpg",
         "./test_1k_images_8/video8426_frame_004_of_008.jpg",
         "video8426",
         "./test_1k_images_8/video8426_frame_005_of_008.jpg",
         "./test_1k_images_8/video8426_frame_006_of_008.jpg",
         "./test_1k_images_8/video8426_frame_007_of_008.jpg",
         "./test_1k_images_8/video8426_frame_008_of_008.jpg"
        ],
        [
         "25",
         "235",
         "ret235",
         "msr9699",
         "video9699",
         "a man explains how to do a experiment",
         "./test_1k_compress/video9699.mp4",
         "./test_1k_images_8/video9699_frame_001_of_008.jpg",
         "./test_1k_images_8/video9699_frame_002_of_008.jpg",
         "./test_1k_images_8/video9699_frame_003_of_008.jpg",
         "./test_1k_images_8/video9699_frame_004_of_008.jpg",
         "video9699",
         "./test_1k_images_8/video9699_frame_005_of_008.jpg",
         "./test_1k_images_8/video9699_frame_006_of_008.jpg",
         "./test_1k_images_8/video9699_frame_007_of_008.jpg",
         "./test_1k_images_8/video9699_frame_008_of_008.jpg"
        ],
        [
         "26",
         "101",
         "ret101",
         "msr9882",
         "video9882",
         "a news reader is reading the news and asking question to some people",
         "./test_1k_compress/video9882.mp4",
         "./test_1k_images_8/video9882_frame_001_of_008.jpg",
         "./test_1k_images_8/video9882_frame_002_of_008.jpg",
         "./test_1k_images_8/video9882_frame_003_of_008.jpg",
         "./test_1k_images_8/video9882_frame_004_of_008.jpg",
         "video9882",
         "./test_1k_images_8/video9882_frame_005_of_008.jpg",
         "./test_1k_images_8/video9882_frame_006_of_008.jpg",
         "./test_1k_images_8/video9882_frame_007_of_008.jpg",
         "./test_1k_images_8/video9882_frame_008_of_008.jpg"
        ],
        [
         "27",
         "986",
         "ret986",
         "msr8300",
         "video8300",
         "a woman pours water into her pot of meat then tomato sauce and stirs it all around while talking",
         "./test_1k_compress/video8300.mp4",
         "./test_1k_images_8/video8300_frame_001_of_008.jpg",
         "./test_1k_images_8/video8300_frame_002_of_008.jpg",
         "./test_1k_images_8/video8300_frame_003_of_008.jpg",
         "./test_1k_images_8/video8300_frame_004_of_008.jpg",
         "video8300",
         "./test_1k_images_8/video8300_frame_005_of_008.jpg",
         "./test_1k_images_8/video8300_frame_006_of_008.jpg",
         "./test_1k_images_8/video8300_frame_007_of_008.jpg",
         "./test_1k_images_8/video8300_frame_008_of_008.jpg"
        ],
        [
         "28",
         "902",
         "ret902",
         "msr8863",
         "video8863",
         "an animated girl talks to a baby and plays with it",
         "./test_1k_compress/video8863.mp4",
         "./test_1k_images_8/video8863_frame_001_of_008.jpg",
         "./test_1k_images_8/video8863_frame_002_of_008.jpg",
         "./test_1k_images_8/video8863_frame_003_of_008.jpg",
         "./test_1k_images_8/video8863_frame_004_of_008.jpg",
         "video8863",
         "./test_1k_images_8/video8863_frame_005_of_008.jpg",
         "./test_1k_images_8/video8863_frame_006_of_008.jpg",
         "./test_1k_images_8/video8863_frame_007_of_008.jpg",
         "./test_1k_images_8/video8863_frame_008_of_008.jpg"
        ],
        [
         "29",
         "947",
         "ret947",
         "msr7147",
         "video7147",
         "a man cooks burgers and bacon on a grill",
         "./test_1k_compress/video7147.mp4",
         "./test_1k_images_8/video7147_frame_001_of_008.jpg",
         "./test_1k_images_8/video7147_frame_002_of_008.jpg",
         "./test_1k_images_8/video7147_frame_003_of_008.jpg",
         "./test_1k_images_8/video7147_frame_004_of_008.jpg",
         "video7147",
         "./test_1k_images_8/video7147_frame_005_of_008.jpg",
         "./test_1k_images_8/video7147_frame_006_of_008.jpg",
         "./test_1k_images_8/video7147_frame_007_of_008.jpg",
         "./test_1k_images_8/video7147_frame_008_of_008.jpg"
        ],
        [
         "30",
         "346",
         "ret346",
         "msr7744",
         "video7744",
         "a chef stirs up some ingredients inside of a pan",
         "./test_1k_compress/video7744.mp4",
         "./test_1k_images_8/video7744_frame_001_of_008.jpg",
         "./test_1k_images_8/video7744_frame_002_of_008.jpg",
         "./test_1k_images_8/video7744_frame_003_of_008.jpg",
         "./test_1k_images_8/video7744_frame_004_of_008.jpg",
         "video7744",
         "./test_1k_images_8/video7744_frame_005_of_008.jpg",
         "./test_1k_images_8/video7744_frame_006_of_008.jpg",
         "./test_1k_images_8/video7744_frame_007_of_008.jpg",
         "./test_1k_images_8/video7744_frame_008_of_008.jpg"
        ],
        [
         "31",
         "139",
         "ret139",
         "msr7839",
         "video7839",
         "this is a vine sports compilation",
         "./test_1k_compress/video7839.mp4",
         "./test_1k_images_8/video7839_frame_001_of_008.jpg",
         "./test_1k_images_8/video7839_frame_002_of_008.jpg",
         "./test_1k_images_8/video7839_frame_003_of_008.jpg",
         "./test_1k_images_8/video7839_frame_004_of_008.jpg",
         "video7839",
         "./test_1k_images_8/video7839_frame_005_of_008.jpg",
         "./test_1k_images_8/video7839_frame_006_of_008.jpg",
         "./test_1k_images_8/video7839_frame_007_of_008.jpg",
         "./test_1k_images_8/video7839_frame_008_of_008.jpg"
        ],
        [
         "32",
         "621",
         "ret621",
         "msr7214",
         "video7214",
         "race cars of different colors lined up on a dark track",
         "./test_1k_compress/video7214.mp4",
         "./test_1k_images_8/video7214_frame_001_of_008.jpg",
         "./test_1k_images_8/video7214_frame_002_of_008.jpg",
         "./test_1k_images_8/video7214_frame_003_of_008.jpg",
         "./test_1k_images_8/video7214_frame_004_of_008.jpg",
         "video7214",
         "./test_1k_images_8/video7214_frame_005_of_008.jpg",
         "./test_1k_images_8/video7214_frame_006_of_008.jpg",
         "./test_1k_images_8/video7214_frame_007_of_008.jpg",
         "./test_1k_images_8/video7214_frame_008_of_008.jpg"
        ],
        [
         "33",
         "499",
         "ret499",
         "msr7771",
         "video7771",
         "a golf player is trying to hit the ball into the pit",
         "./test_1k_compress/video7771.mp4",
         "./test_1k_images_8/video7771_frame_001_of_008.jpg",
         "./test_1k_images_8/video7771_frame_002_of_008.jpg",
         "./test_1k_images_8/video7771_frame_003_of_008.jpg",
         "./test_1k_images_8/video7771_frame_004_of_008.jpg",
         "video7771",
         "./test_1k_images_8/video7771_frame_005_of_008.jpg",
         "./test_1k_images_8/video7771_frame_006_of_008.jpg",
         "./test_1k_images_8/video7771_frame_007_of_008.jpg",
         "./test_1k_images_8/video7771_frame_008_of_008.jpg"
        ],
        [
         "34",
         "370",
         "ret370",
         "msr8486",
         "video8486",
         "a cartoon on a young guy cursing",
         "./test_1k_compress/video8486.mp4",
         "./test_1k_images_8/video8486_frame_001_of_008.jpg",
         "./test_1k_images_8/video8486_frame_002_of_008.jpg",
         "./test_1k_images_8/video8486_frame_003_of_008.jpg",
         "./test_1k_images_8/video8486_frame_004_of_008.jpg",
         "video8486",
         "./test_1k_images_8/video8486_frame_005_of_008.jpg",
         "./test_1k_images_8/video8486_frame_006_of_008.jpg",
         "./test_1k_images_8/video8486_frame_007_of_008.jpg",
         "./test_1k_images_8/video8486_frame_008_of_008.jpg"
        ],
        [
         "35",
         "198",
         "ret198",
         "msr9909",
         "video9909",
         "a crowd of people sitting next to each other as one man plays a video game",
         "./test_1k_compress/video9909.mp4",
         "./test_1k_images_8/video9909_frame_001_of_008.jpg",
         "./test_1k_images_8/video9909_frame_002_of_008.jpg",
         "./test_1k_images_8/video9909_frame_003_of_008.jpg",
         "./test_1k_images_8/video9909_frame_004_of_008.jpg",
         "video9909",
         "./test_1k_images_8/video9909_frame_005_of_008.jpg",
         "./test_1k_images_8/video9909_frame_006_of_008.jpg",
         "./test_1k_images_8/video9909_frame_007_of_008.jpg",
         "./test_1k_images_8/video9909_frame_008_of_008.jpg"
        ],
        [
         "36",
         "687",
         "ret687",
         "msr8922",
         "video8922",
         "an old man shakes hands with another man and then they hug each other",
         "./test_1k_compress/video8922.mp4",
         "./test_1k_images_8/video8922_frame_001_of_008.jpg",
         "./test_1k_images_8/video8922_frame_002_of_008.jpg",
         "./test_1k_images_8/video8922_frame_003_of_008.jpg",
         "./test_1k_images_8/video8922_frame_004_of_008.jpg",
         "video8922",
         "./test_1k_images_8/video8922_frame_005_of_008.jpg",
         "./test_1k_images_8/video8922_frame_006_of_008.jpg",
         "./test_1k_images_8/video8922_frame_007_of_008.jpg",
         "./test_1k_images_8/video8922_frame_008_of_008.jpg"
        ],
        [
         "37",
         "584",
         "ret584",
         "msr9814",
         "video9814",
         "a scene from spongebob squarepants where the townspeople are carrying torches and chasing a giant squidward",
         "./test_1k_compress/video9814.mp4",
         "./test_1k_images_8/video9814_frame_001_of_008.jpg",
         "./test_1k_images_8/video9814_frame_002_of_008.jpg",
         "./test_1k_images_8/video9814_frame_003_of_008.jpg",
         "./test_1k_images_8/video9814_frame_004_of_008.jpg",
         "video9814",
         "./test_1k_images_8/video9814_frame_005_of_008.jpg",
         "./test_1k_images_8/video9814_frame_006_of_008.jpg",
         "./test_1k_images_8/video9814_frame_007_of_008.jpg",
         "./test_1k_images_8/video9814_frame_008_of_008.jpg"
        ],
        [
         "38",
         "901",
         "ret901",
         "msr9368",
         "video9368",
         "someone demonstrates about the small motor uses to the video",
         "./test_1k_compress/video9368.mp4",
         "./test_1k_images_8/video9368_frame_001_of_008.jpg",
         "./test_1k_images_8/video9368_frame_002_of_008.jpg",
         "./test_1k_images_8/video9368_frame_003_of_008.jpg",
         "./test_1k_images_8/video9368_frame_004_of_008.jpg",
         "video9368",
         "./test_1k_images_8/video9368_frame_005_of_008.jpg",
         "./test_1k_images_8/video9368_frame_006_of_008.jpg",
         "./test_1k_images_8/video9368_frame_007_of_008.jpg",
         "./test_1k_images_8/video9368_frame_008_of_008.jpg"
        ],
        [
         "39",
         "59",
         "ret59",
         "msr8820",
         "video8820",
         "a person comes up in the hill on a orange motor bike and falls down",
         "./test_1k_compress/video8820.mp4",
         "./test_1k_images_8/video8820_frame_001_of_008.jpg",
         "./test_1k_images_8/video8820_frame_002_of_008.jpg",
         "./test_1k_images_8/video8820_frame_003_of_008.jpg",
         "./test_1k_images_8/video8820_frame_004_of_008.jpg",
         "video8820",
         "./test_1k_images_8/video8820_frame_005_of_008.jpg",
         "./test_1k_images_8/video8820_frame_006_of_008.jpg",
         "./test_1k_images_8/video8820_frame_007_of_008.jpg",
         "./test_1k_images_8/video8820_frame_008_of_008.jpg"
        ],
        [
         "40",
         "328",
         "ret328",
         "msr9452",
         "video9452",
         "an animated grey shark in the middle of a blue water simulation background rotating in a circle on the screen of a monitor",
         "./test_1k_compress/video9452.mp4",
         "./test_1k_images_8/video9452_frame_001_of_008.jpg",
         "./test_1k_images_8/video9452_frame_002_of_008.jpg",
         "./test_1k_images_8/video9452_frame_003_of_008.jpg",
         "./test_1k_images_8/video9452_frame_004_of_008.jpg",
         "video9452",
         "./test_1k_images_8/video9452_frame_005_of_008.jpg",
         "./test_1k_images_8/video9452_frame_006_of_008.jpg",
         "./test_1k_images_8/video9452_frame_007_of_008.jpg",
         "./test_1k_images_8/video9452_frame_008_of_008.jpg"
        ],
        [
         "41",
         "96",
         "ret96",
         "msr9344",
         "video9344",
         "gameplay footage of someone playing a game",
         "./test_1k_compress/video9344.mp4",
         "./test_1k_images_8/video9344_frame_001_of_008.jpg",
         "./test_1k_images_8/video9344_frame_002_of_008.jpg",
         "./test_1k_images_8/video9344_frame_003_of_008.jpg",
         "./test_1k_images_8/video9344_frame_004_of_008.jpg",
         "video9344",
         "./test_1k_images_8/video9344_frame_005_of_008.jpg",
         "./test_1k_images_8/video9344_frame_006_of_008.jpg",
         "./test_1k_images_8/video9344_frame_007_of_008.jpg",
         "./test_1k_images_8/video9344_frame_008_of_008.jpg"
        ],
        [
         "42",
         "312",
         "ret312",
         "msr9032",
         "video9032",
         "a hospital mortuary room and a doctor treat the special case",
         "./test_1k_compress/video9032.mp4",
         "./test_1k_images_8/video9032_frame_001_of_008.jpg",
         "./test_1k_images_8/video9032_frame_002_of_008.jpg",
         "./test_1k_images_8/video9032_frame_003_of_008.jpg",
         "./test_1k_images_8/video9032_frame_004_of_008.jpg",
         "video9032",
         "./test_1k_images_8/video9032_frame_005_of_008.jpg",
         "./test_1k_images_8/video9032_frame_006_of_008.jpg",
         "./test_1k_images_8/video9032_frame_007_of_008.jpg",
         "./test_1k_images_8/video9032_frame_008_of_008.jpg"
        ],
        [
         "43",
         "974",
         "ret974",
         "msr9016",
         "video9016",
         "all persons are wearing bikini dresses and playing in sea",
         "./test_1k_compress/video9016.mp4",
         "./test_1k_images_8/video9016_frame_001_of_008.jpg",
         "./test_1k_images_8/video9016_frame_002_of_008.jpg",
         "./test_1k_images_8/video9016_frame_003_of_008.jpg",
         "./test_1k_images_8/video9016_frame_004_of_008.jpg",
         "video9016",
         "./test_1k_images_8/video9016_frame_005_of_008.jpg",
         "./test_1k_images_8/video9016_frame_006_of_008.jpg",
         "./test_1k_images_8/video9016_frame_007_of_008.jpg",
         "./test_1k_images_8/video9016_frame_008_of_008.jpg"
        ],
        [
         "44",
         "299",
         "ret299",
         "msr9353",
         "video9353",
         "two women are outside and are discussing something in a foreign language",
         "./test_1k_compress/video9353.mp4",
         "./test_1k_images_8/video9353_frame_001_of_008.jpg",
         "./test_1k_images_8/video9353_frame_002_of_008.jpg",
         "./test_1k_images_8/video9353_frame_003_of_008.jpg",
         "./test_1k_images_8/video9353_frame_004_of_008.jpg",
         "video9353",
         "./test_1k_images_8/video9353_frame_005_of_008.jpg",
         "./test_1k_images_8/video9353_frame_006_of_008.jpg",
         "./test_1k_images_8/video9353_frame_007_of_008.jpg",
         "./test_1k_images_8/video9353_frame_008_of_008.jpg"
        ],
        [
         "45",
         "277",
         "ret277",
         "msr9405",
         "video9405",
         "red balloons float in the sky and have packages tied to them",
         "./test_1k_compress/video9405.mp4",
         "./test_1k_images_8/video9405_frame_001_of_008.jpg",
         "./test_1k_images_8/video9405_frame_002_of_008.jpg",
         "./test_1k_images_8/video9405_frame_003_of_008.jpg",
         "./test_1k_images_8/video9405_frame_004_of_008.jpg",
         "video9405",
         "./test_1k_images_8/video9405_frame_005_of_008.jpg",
         "./test_1k_images_8/video9405_frame_006_of_008.jpg",
         "./test_1k_images_8/video9405_frame_007_of_008.jpg",
         "./test_1k_images_8/video9405_frame_008_of_008.jpg"
        ],
        [
         "46",
         "924",
         "ret924",
         "msr7559",
         "video7559",
         "a man is trying some sushi",
         "./test_1k_compress/video7559.mp4",
         "./test_1k_images_8/video7559_frame_001_of_008.jpg",
         "./test_1k_images_8/video7559_frame_002_of_008.jpg",
         "./test_1k_images_8/video7559_frame_003_of_008.jpg",
         "./test_1k_images_8/video7559_frame_004_of_008.jpg",
         "video7559",
         "./test_1k_images_8/video7559_frame_005_of_008.jpg",
         "./test_1k_images_8/video7559_frame_006_of_008.jpg",
         "./test_1k_images_8/video7559_frame_007_of_008.jpg",
         "./test_1k_images_8/video7559_frame_008_of_008.jpg"
        ],
        [
         "47",
         "601",
         "ret601",
         "msr9063",
         "video9063",
         "people on stage performing",
         "./test_1k_compress/video9063.mp4",
         "./test_1k_images_8/video9063_frame_001_of_008.jpg",
         "./test_1k_images_8/video9063_frame_002_of_008.jpg",
         "./test_1k_images_8/video9063_frame_003_of_008.jpg",
         "./test_1k_images_8/video9063_frame_004_of_008.jpg",
         "video9063",
         "./test_1k_images_8/video9063_frame_005_of_008.jpg",
         "./test_1k_images_8/video9063_frame_006_of_008.jpg",
         "./test_1k_images_8/video9063_frame_007_of_008.jpg",
         "./test_1k_images_8/video9063_frame_008_of_008.jpg"
        ],
        [
         "48",
         "439",
         "ret439",
         "msr7352",
         "video7352",
         "a movie scene starring morgan freeman and men in armor running",
         "./test_1k_compress/video7352.mp4",
         "./test_1k_images_8/video7352_frame_001_of_008.jpg",
         "./test_1k_images_8/video7352_frame_002_of_008.jpg",
         "./test_1k_images_8/video7352_frame_003_of_008.jpg",
         "./test_1k_images_8/video7352_frame_004_of_008.jpg",
         "video7352",
         "./test_1k_images_8/video7352_frame_005_of_008.jpg",
         "./test_1k_images_8/video7352_frame_006_of_008.jpg",
         "./test_1k_images_8/video7352_frame_007_of_008.jpg",
         "./test_1k_images_8/video7352_frame_008_of_008.jpg"
        ],
        [
         "49",
         "837",
         "ret837",
         "msr8447",
         "video8447",
         "a woman singing on the voice",
         "./test_1k_compress/video8447.mp4",
         "./test_1k_images_8/video8447_frame_001_of_008.jpg",
         "./test_1k_images_8/video8447_frame_002_of_008.jpg",
         "./test_1k_images_8/video8447_frame_003_of_008.jpg",
         "./test_1k_images_8/video8447_frame_004_of_008.jpg",
         "video8447",
         "./test_1k_images_8/video8447_frame_005_of_008.jpg",
         "./test_1k_images_8/video8447_frame_006_of_008.jpg",
         "./test_1k_images_8/video8447_frame_007_of_008.jpg",
         "./test_1k_images_8/video8447_frame_008_of_008.jpg"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 1000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>key</th>\n",
       "      <th>vid_key</th>\n",
       "      <th>video_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_path</th>\n",
       "      <th>frame_path_1</th>\n",
       "      <th>frame_path_2</th>\n",
       "      <th>frame_path_3</th>\n",
       "      <th>frame_path_4</th>\n",
       "      <th>frame_id</th>\n",
       "      <th>frame_path_5</th>\n",
       "      <th>frame_path_6</th>\n",
       "      <th>frame_path_7</th>\n",
       "      <th>frame_path_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>521</td>\n",
       "      <td>ret521</td>\n",
       "      <td>msr7579</td>\n",
       "      <td>video7579</td>\n",
       "      <td>a girl wearing red top and black trouser is pu...</td>\n",
       "      <td>./test_1k_compress/video7579.mp4</td>\n",
       "      <td>./test_1k_images_8/video7579_frame_001_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7579_frame_002_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7579_frame_003_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7579_frame_004_of_008.jpg</td>\n",
       "      <td>video7579</td>\n",
       "      <td>./test_1k_images_8/video7579_frame_005_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7579_frame_006_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7579_frame_007_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7579_frame_008_of_008.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>737</td>\n",
       "      <td>ret737</td>\n",
       "      <td>msr7725</td>\n",
       "      <td>video7725</td>\n",
       "      <td>young people sit around the edges of a room cl...</td>\n",
       "      <td>./test_1k_compress/video7725.mp4</td>\n",
       "      <td>./test_1k_images_8/video7725_frame_001_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7725_frame_002_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7725_frame_003_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7725_frame_004_of_008.jpg</td>\n",
       "      <td>video7725</td>\n",
       "      <td>./test_1k_images_8/video7725_frame_005_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7725_frame_006_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7725_frame_007_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7725_frame_008_of_008.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>740</td>\n",
       "      <td>ret740</td>\n",
       "      <td>msr9258</td>\n",
       "      <td>video9258</td>\n",
       "      <td>a person is using a phone</td>\n",
       "      <td>./test_1k_compress/video9258.mp4</td>\n",
       "      <td>./test_1k_images_8/video9258_frame_001_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video9258_frame_002_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video9258_frame_003_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video9258_frame_004_of_008.jpg</td>\n",
       "      <td>video9258</td>\n",
       "      <td>./test_1k_images_8/video9258_frame_005_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video9258_frame_006_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video9258_frame_007_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video9258_frame_008_of_008.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>660</td>\n",
       "      <td>ret660</td>\n",
       "      <td>msr7365</td>\n",
       "      <td>video7365</td>\n",
       "      <td>cartoon people are eating at a restaurant</td>\n",
       "      <td>./test_1k_compress/video7365.mp4</td>\n",
       "      <td>./test_1k_images_8/video7365_frame_001_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7365_frame_002_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7365_frame_003_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7365_frame_004_of_008.jpg</td>\n",
       "      <td>video7365</td>\n",
       "      <td>./test_1k_images_8/video7365_frame_005_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7365_frame_006_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7365_frame_007_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7365_frame_008_of_008.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>411</td>\n",
       "      <td>ret411</td>\n",
       "      <td>msr8068</td>\n",
       "      <td>video8068</td>\n",
       "      <td>a woman on a couch talks to a a man</td>\n",
       "      <td>./test_1k_compress/video8068.mp4</td>\n",
       "      <td>./test_1k_images_8/video8068_frame_001_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video8068_frame_002_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video8068_frame_003_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video8068_frame_004_of_008.jpg</td>\n",
       "      <td>video8068</td>\n",
       "      <td>./test_1k_images_8/video8068_frame_005_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video8068_frame_006_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video8068_frame_007_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video8068_frame_008_of_008.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>106</td>\n",
       "      <td>ret106</td>\n",
       "      <td>msr7034</td>\n",
       "      <td>video7034</td>\n",
       "      <td>man in black shirt is holding a baby upside do...</td>\n",
       "      <td>./test_1k_compress/video7034.mp4</td>\n",
       "      <td>./test_1k_images_8/video7034_frame_001_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7034_frame_002_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7034_frame_003_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7034_frame_004_of_008.jpg</td>\n",
       "      <td>video7034</td>\n",
       "      <td>./test_1k_images_8/video7034_frame_005_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7034_frame_006_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7034_frame_007_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7034_frame_008_of_008.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>270</td>\n",
       "      <td>ret270</td>\n",
       "      <td>msr7568</td>\n",
       "      <td>video7568</td>\n",
       "      <td>the queen of england is seen walking with an e...</td>\n",
       "      <td>./test_1k_compress/video7568.mp4</td>\n",
       "      <td>./test_1k_images_8/video7568_frame_001_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7568_frame_002_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7568_frame_003_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7568_frame_004_of_008.jpg</td>\n",
       "      <td>video7568</td>\n",
       "      <td>./test_1k_images_8/video7568_frame_005_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7568_frame_006_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7568_frame_007_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7568_frame_008_of_008.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>860</td>\n",
       "      <td>ret860</td>\n",
       "      <td>msr7979</td>\n",
       "      <td>video7979</td>\n",
       "      <td>people talking about a fight</td>\n",
       "      <td>./test_1k_compress/video7979.mp4</td>\n",
       "      <td>./test_1k_images_8/video7979_frame_001_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7979_frame_002_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7979_frame_003_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7979_frame_004_of_008.jpg</td>\n",
       "      <td>video7979</td>\n",
       "      <td>./test_1k_images_8/video7979_frame_005_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7979_frame_006_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7979_frame_007_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7979_frame_008_of_008.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>435</td>\n",
       "      <td>ret435</td>\n",
       "      <td>msr7356</td>\n",
       "      <td>video7356</td>\n",
       "      <td>a vehicle with details on what comes with it b...</td>\n",
       "      <td>./test_1k_compress/video7356.mp4</td>\n",
       "      <td>./test_1k_images_8/video7356_frame_001_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7356_frame_002_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7356_frame_003_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7356_frame_004_of_008.jpg</td>\n",
       "      <td>video7356</td>\n",
       "      <td>./test_1k_images_8/video7356_frame_005_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7356_frame_006_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7356_frame_007_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video7356_frame_008_of_008.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>102</td>\n",
       "      <td>ret102</td>\n",
       "      <td>msr8578</td>\n",
       "      <td>video8578</td>\n",
       "      <td>a man is commentating while playing minecraft</td>\n",
       "      <td>./test_1k_compress/video8578.mp4</td>\n",
       "      <td>./test_1k_images_8/video8578_frame_001_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video8578_frame_002_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video8578_frame_003_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video8578_frame_004_of_008.jpg</td>\n",
       "      <td>video8578</td>\n",
       "      <td>./test_1k_images_8/video8578_frame_005_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video8578_frame_006_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video8578_frame_007_of_008.jpg</td>\n",
       "      <td>./test_1k_images_8/video8578_frame_008_of_008.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0     key  vid_key   video_id  \\\n",
       "0           521  ret521  msr7579  video7579   \n",
       "1           737  ret737  msr7725  video7725   \n",
       "2           740  ret740  msr9258  video9258   \n",
       "3           660  ret660  msr7365  video7365   \n",
       "4           411  ret411  msr8068  video8068   \n",
       "..          ...     ...      ...        ...   \n",
       "995         106  ret106  msr7034  video7034   \n",
       "996         270  ret270  msr7568  video7568   \n",
       "997         860  ret860  msr7979  video7979   \n",
       "998         435  ret435  msr7356  video7356   \n",
       "999         102  ret102  msr8578  video8578   \n",
       "\n",
       "                                              sentence  \\\n",
       "0    a girl wearing red top and black trouser is pu...   \n",
       "1    young people sit around the edges of a room cl...   \n",
       "2                            a person is using a phone   \n",
       "3            cartoon people are eating at a restaurant   \n",
       "4                  a woman on a couch talks to a a man   \n",
       "..                                                 ...   \n",
       "995  man in black shirt is holding a baby upside do...   \n",
       "996  the queen of england is seen walking with an e...   \n",
       "997                       people talking about a fight   \n",
       "998  a vehicle with details on what comes with it b...   \n",
       "999      a man is commentating while playing minecraft   \n",
       "\n",
       "                           video_path  \\\n",
       "0    ./test_1k_compress/video7579.mp4   \n",
       "1    ./test_1k_compress/video7725.mp4   \n",
       "2    ./test_1k_compress/video9258.mp4   \n",
       "3    ./test_1k_compress/video7365.mp4   \n",
       "4    ./test_1k_compress/video8068.mp4   \n",
       "..                                ...   \n",
       "995  ./test_1k_compress/video7034.mp4   \n",
       "996  ./test_1k_compress/video7568.mp4   \n",
       "997  ./test_1k_compress/video7979.mp4   \n",
       "998  ./test_1k_compress/video7356.mp4   \n",
       "999  ./test_1k_compress/video8578.mp4   \n",
       "\n",
       "                                          frame_path_1  \\\n",
       "0    ./test_1k_images_8/video7579_frame_001_of_008.jpg   \n",
       "1    ./test_1k_images_8/video7725_frame_001_of_008.jpg   \n",
       "2    ./test_1k_images_8/video9258_frame_001_of_008.jpg   \n",
       "3    ./test_1k_images_8/video7365_frame_001_of_008.jpg   \n",
       "4    ./test_1k_images_8/video8068_frame_001_of_008.jpg   \n",
       "..                                                 ...   \n",
       "995  ./test_1k_images_8/video7034_frame_001_of_008.jpg   \n",
       "996  ./test_1k_images_8/video7568_frame_001_of_008.jpg   \n",
       "997  ./test_1k_images_8/video7979_frame_001_of_008.jpg   \n",
       "998  ./test_1k_images_8/video7356_frame_001_of_008.jpg   \n",
       "999  ./test_1k_images_8/video8578_frame_001_of_008.jpg   \n",
       "\n",
       "                                          frame_path_2  \\\n",
       "0    ./test_1k_images_8/video7579_frame_002_of_008.jpg   \n",
       "1    ./test_1k_images_8/video7725_frame_002_of_008.jpg   \n",
       "2    ./test_1k_images_8/video9258_frame_002_of_008.jpg   \n",
       "3    ./test_1k_images_8/video7365_frame_002_of_008.jpg   \n",
       "4    ./test_1k_images_8/video8068_frame_002_of_008.jpg   \n",
       "..                                                 ...   \n",
       "995  ./test_1k_images_8/video7034_frame_002_of_008.jpg   \n",
       "996  ./test_1k_images_8/video7568_frame_002_of_008.jpg   \n",
       "997  ./test_1k_images_8/video7979_frame_002_of_008.jpg   \n",
       "998  ./test_1k_images_8/video7356_frame_002_of_008.jpg   \n",
       "999  ./test_1k_images_8/video8578_frame_002_of_008.jpg   \n",
       "\n",
       "                                          frame_path_3  \\\n",
       "0    ./test_1k_images_8/video7579_frame_003_of_008.jpg   \n",
       "1    ./test_1k_images_8/video7725_frame_003_of_008.jpg   \n",
       "2    ./test_1k_images_8/video9258_frame_003_of_008.jpg   \n",
       "3    ./test_1k_images_8/video7365_frame_003_of_008.jpg   \n",
       "4    ./test_1k_images_8/video8068_frame_003_of_008.jpg   \n",
       "..                                                 ...   \n",
       "995  ./test_1k_images_8/video7034_frame_003_of_008.jpg   \n",
       "996  ./test_1k_images_8/video7568_frame_003_of_008.jpg   \n",
       "997  ./test_1k_images_8/video7979_frame_003_of_008.jpg   \n",
       "998  ./test_1k_images_8/video7356_frame_003_of_008.jpg   \n",
       "999  ./test_1k_images_8/video8578_frame_003_of_008.jpg   \n",
       "\n",
       "                                          frame_path_4   frame_id  \\\n",
       "0    ./test_1k_images_8/video7579_frame_004_of_008.jpg  video7579   \n",
       "1    ./test_1k_images_8/video7725_frame_004_of_008.jpg  video7725   \n",
       "2    ./test_1k_images_8/video9258_frame_004_of_008.jpg  video9258   \n",
       "3    ./test_1k_images_8/video7365_frame_004_of_008.jpg  video7365   \n",
       "4    ./test_1k_images_8/video8068_frame_004_of_008.jpg  video8068   \n",
       "..                                                 ...        ...   \n",
       "995  ./test_1k_images_8/video7034_frame_004_of_008.jpg  video7034   \n",
       "996  ./test_1k_images_8/video7568_frame_004_of_008.jpg  video7568   \n",
       "997  ./test_1k_images_8/video7979_frame_004_of_008.jpg  video7979   \n",
       "998  ./test_1k_images_8/video7356_frame_004_of_008.jpg  video7356   \n",
       "999  ./test_1k_images_8/video8578_frame_004_of_008.jpg  video8578   \n",
       "\n",
       "                                          frame_path_5  \\\n",
       "0    ./test_1k_images_8/video7579_frame_005_of_008.jpg   \n",
       "1    ./test_1k_images_8/video7725_frame_005_of_008.jpg   \n",
       "2    ./test_1k_images_8/video9258_frame_005_of_008.jpg   \n",
       "3    ./test_1k_images_8/video7365_frame_005_of_008.jpg   \n",
       "4    ./test_1k_images_8/video8068_frame_005_of_008.jpg   \n",
       "..                                                 ...   \n",
       "995  ./test_1k_images_8/video7034_frame_005_of_008.jpg   \n",
       "996  ./test_1k_images_8/video7568_frame_005_of_008.jpg   \n",
       "997  ./test_1k_images_8/video7979_frame_005_of_008.jpg   \n",
       "998  ./test_1k_images_8/video7356_frame_005_of_008.jpg   \n",
       "999  ./test_1k_images_8/video8578_frame_005_of_008.jpg   \n",
       "\n",
       "                                          frame_path_6  \\\n",
       "0    ./test_1k_images_8/video7579_frame_006_of_008.jpg   \n",
       "1    ./test_1k_images_8/video7725_frame_006_of_008.jpg   \n",
       "2    ./test_1k_images_8/video9258_frame_006_of_008.jpg   \n",
       "3    ./test_1k_images_8/video7365_frame_006_of_008.jpg   \n",
       "4    ./test_1k_images_8/video8068_frame_006_of_008.jpg   \n",
       "..                                                 ...   \n",
       "995  ./test_1k_images_8/video7034_frame_006_of_008.jpg   \n",
       "996  ./test_1k_images_8/video7568_frame_006_of_008.jpg   \n",
       "997  ./test_1k_images_8/video7979_frame_006_of_008.jpg   \n",
       "998  ./test_1k_images_8/video7356_frame_006_of_008.jpg   \n",
       "999  ./test_1k_images_8/video8578_frame_006_of_008.jpg   \n",
       "\n",
       "                                          frame_path_7  \\\n",
       "0    ./test_1k_images_8/video7579_frame_007_of_008.jpg   \n",
       "1    ./test_1k_images_8/video7725_frame_007_of_008.jpg   \n",
       "2    ./test_1k_images_8/video9258_frame_007_of_008.jpg   \n",
       "3    ./test_1k_images_8/video7365_frame_007_of_008.jpg   \n",
       "4    ./test_1k_images_8/video8068_frame_007_of_008.jpg   \n",
       "..                                                 ...   \n",
       "995  ./test_1k_images_8/video7034_frame_007_of_008.jpg   \n",
       "996  ./test_1k_images_8/video7568_frame_007_of_008.jpg   \n",
       "997  ./test_1k_images_8/video7979_frame_007_of_008.jpg   \n",
       "998  ./test_1k_images_8/video7356_frame_007_of_008.jpg   \n",
       "999  ./test_1k_images_8/video8578_frame_007_of_008.jpg   \n",
       "\n",
       "                                          frame_path_8  \n",
       "0    ./test_1k_images_8/video7579_frame_008_of_008.jpg  \n",
       "1    ./test_1k_images_8/video7725_frame_008_of_008.jpg  \n",
       "2    ./test_1k_images_8/video9258_frame_008_of_008.jpg  \n",
       "3    ./test_1k_images_8/video7365_frame_008_of_008.jpg  \n",
       "4    ./test_1k_images_8/video8068_frame_008_of_008.jpg  \n",
       "..                                                 ...  \n",
       "995  ./test_1k_images_8/video7034_frame_008_of_008.jpg  \n",
       "996  ./test_1k_images_8/video7568_frame_008_of_008.jpg  \n",
       "997  ./test_1k_images_8/video7979_frame_008_of_008.jpg  \n",
       "998  ./test_1k_images_8/video7356_frame_008_of_008.jpg  \n",
       "999  ./test_1k_images_8/video8578_frame_008_of_008.jpg  \n",
       "\n",
       "[1000 rows x 15 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_FRAMES = 8\n",
    "print(f\"Creating {NUM_FRAMES} per video...\")\n",
    "for row in tqdm(raw_samples_df.iterrows(), total=len(raw_samples_df)):\n",
    "    video_path = row[1]['video_path']\n",
    "    images_dir = \"./test_1k_images_8\"\n",
    "    image_name = os.path.basename(video_path).split('.')[0]\n",
    "    image_path = os.path.join(images_dir, image_name) + \".jpg\"\n",
    "    \n",
    "    all_frame_paths = extract_n_frames_2(video_path, images_dir, NUM_FRAMES)\n",
    "    for num_f in range(NUM_FRAMES):\n",
    "        raw_samples_df.at[row[0], f'frame_path_{num_f+1}'] = all_frame_paths[num_f]\n",
    "        \n",
    "    raw_samples_df.at[row[0], 'frame_id'] = image_name\n",
    "    \n",
    "# Now this should contain new columns with the frame_path and frame_id\n",
    "raw_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6820e1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frame_path_1', 'frame_path_2', 'frame_path_3', 'frame_path_4', 'frame_path_5', 'frame_path_6', 'frame_path_7', 'frame_path_8', 'video_id', 'frame_id', 'sentence']\n"
     ]
    }
   ],
   "source": [
    "# We write the transformed samples data to a CSV file so it can be loaded into the load pipeline\n",
    "# raw_samples_df[['video_id', 'frame_path', 'frame_id', 'sentence']].to_csv(MSRVTT_SAMPLES_WITH_FRAMES, index=False)\n",
    "def frame_path_cols(num_frames):\n",
    "    cols = []\n",
    "    for i in range(num_frames):\n",
    "        cols.append(f'frame_path_{i+1}')\n",
    "    return cols\n",
    "columns = frame_path_cols(NUM_FRAMES) + ['video_id', 'frame_id', 'sentence']\n",
    "print(columns)\n",
    "raw_samples_df[columns].to_csv(MSRVTT_SAMPLES_WITH_FRAMES, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b7381872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Collection>:\n",
       "-------------\n",
       "<name>: msrvtt_multi_frame_ret_8b\n",
       "<description>: video retrieval\n",
       "<schema>: {'auto_id': False, 'description': 'video retrieval', 'fields': [{'name': 'id', 'description': '', 'type': <DataType.INT64: 5>, 'is_primary': True, 'auto_id': False}, {'name': 'embedding', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 512}}]}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the collection in Milvus to store image embeddings\n",
    "milvus_utils.create_milvus_collection(FRAME_RET_COLLECTION, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a9beba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 11:41:06,686 - 8454604864 - clip.py-clip:100 - WARNING: Gpu not available, use cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 11:41:06,721 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:06,752 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:06,790 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:06,798 - 18874396672 - connectionpool.py-connectionpool:1049 - DEBUG: Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-17 11:41:06,864 - 18874396672 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16 HTTP/1.1\" 200 3499\n",
      "2025-04-17 11:41:06,914 - 18874396672 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/main HTTP/1.1\" 200 3099\n",
      "2025-04-17 11:41:06,939 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:06,965 - 18874396672 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/discussions?p=0 HTTP/1.1\" 200 6380\n",
      "2025-04-17 11:41:07,027 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:07,035 - 18874396672 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/refs%2Fpr%2F10 HTTP/1.1\" 200 4064\n",
      "2025-04-17 11:41:07,058 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:07,137 - 18874396672 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors.index.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:07,171 - 18874396672 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors HTTP/1.1\" 302 0\n",
      "2025-04-17 11:41:07,177 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:07,224 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:07,254 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.jinja HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:07,383 - 8454604864 - clip.py-clip:100 - WARNING: Gpu not available, use cpu\n",
      "2025-04-17 11:41:07,437 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:07,489 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:07,530 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:07,571 - 18874396672 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16 HTTP/1.1\" 200 3499\n",
      "2025-04-17 11:41:07,632 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:07,653 - 18874396672 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/main HTTP/1.1\" 200 3099\n",
      "2025-04-17 11:41:07,896 - 18874396672 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/discussions?p=0 HTTP/1.1\" 200 6380\n",
      "2025-04-17 11:41:08,084 - 18874396672 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/refs%2Fpr%2F10 HTTP/1.1\" 200 4064\n",
      "2025-04-17 11:41:08,127 - 18874396672 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors.index.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:08,158 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:08,158 - 18874396672 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors HTTP/1.1\" 302 0\n",
      "2025-04-17 11:41:08,191 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:08,305 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:08,342 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:08,375 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.jinja HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:08,472 - 8454604864 - clip.py-clip:100 - WARNING: Gpu not available, use cpu\n",
      "2025-04-17 11:41:08,507 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:08,538 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:08,575 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:08,613 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16 HTTP/1.1\" 200 3499\n",
      "2025-04-17 11:41:08,664 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/main HTTP/1.1\" 200 3099\n",
      "2025-04-17 11:41:08,673 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:08,716 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/discussions?p=0 HTTP/1.1\" 200 6380\n",
      "2025-04-17 11:41:08,750 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:08,766 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/refs%2Fpr%2F10 HTTP/1.1\" 200 4064\n",
      "2025-04-17 11:41:08,779 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:08,849 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors.index.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:08,881 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:08,881 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors HTTP/1.1\" 302 0\n",
      "2025-04-17 11:41:08,912 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:08,945 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.jinja HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:09,041 - 8454604864 - clip.py-clip:100 - WARNING: Gpu not available, use cpu\n",
      "2025-04-17 11:41:09,070 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:09,099 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:09,135 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:09,170 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16 HTTP/1.1\" 200 3499\n",
      "2025-04-17 11:41:09,227 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/main HTTP/1.1\" 200 3099\n",
      "2025-04-17 11:41:09,228 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:09,275 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/discussions?p=0 HTTP/1.1\" 200 6380\n",
      "2025-04-17 11:41:09,302 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:09,328 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/refs%2Fpr%2F10 HTTP/1.1\" 200 4064\n",
      "2025-04-17 11:41:09,337 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:09,408 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors.index.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:09,438 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:09,442 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors HTTP/1.1\" 302 0\n",
      "2025-04-17 11:41:09,475 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:09,506 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.jinja HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:09,593 - 8454604864 - clip.py-clip:100 - WARNING: Gpu not available, use cpu\n",
      "2025-04-17 11:41:09,628 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:09,667 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:09,699 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:09,799 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16 HTTP/1.1\" 200 3499\n",
      "2025-04-17 11:41:09,799 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:09,869 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/main HTTP/1.1\" 200 3099\n",
      "2025-04-17 11:41:09,889 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:09,918 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/discussions?p=0 HTTP/1.1\" 200 6380\n",
      "2025-04-17 11:41:09,937 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:10,044 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:10,077 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:10,463 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.jinja HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:10,464 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/refs%2Fpr%2F10 HTTP/1.1\" 200 4064\n",
      "2025-04-17 11:41:10,577 - 8454604864 - clip.py-clip:100 - WARNING: Gpu not available, use cpu\n",
      "2025-04-17 11:41:10,608 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors.index.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:10,610 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:10,639 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors HTTP/1.1\" 302 0\n",
      "2025-04-17 11:41:10,640 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:10,678 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:10,717 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16 HTTP/1.1\" 200 3499\n",
      "2025-04-17 11:41:10,774 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:10,775 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/main HTTP/1.1\" 200 3099\n",
      "2025-04-17 11:41:10,846 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:10,848 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/discussions?p=0 HTTP/1.1\" 200 6380\n",
      "2025-04-17 11:41:10,881 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:10,901 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/refs%2Fpr%2F10 HTTP/1.1\" 200 4064\n",
      "2025-04-17 11:41:10,997 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors.index.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:11,097 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:11,131 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:11,182 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.jinja HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:11,284 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors HTTP/1.1\" 302 0\n",
      "2025-04-17 11:41:11,286 - 8454604864 - clip.py-clip:100 - WARNING: Gpu not available, use cpu\n",
      "2025-04-17 11:41:11,319 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:11,354 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:11,396 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:11,431 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16 HTTP/1.1\" 200 3499\n",
      "2025-04-17 11:41:11,485 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/main HTTP/1.1\" 200 3099\n",
      "2025-04-17 11:41:11,495 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:11,543 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/discussions?p=0 HTTP/1.1\" 200 6380\n",
      "2025-04-17 11:41:11,571 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:11,590 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/refs%2Fpr%2F10 HTTP/1.1\" 200 4064\n",
      "2025-04-17 11:41:11,606 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:11,675 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors.index.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:11,707 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors HTTP/1.1\" 302 0\n",
      "2025-04-17 11:41:11,708 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:11,753 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:11,801 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.jinja HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:11,888 - 8454604864 - clip.py-clip:100 - WARNING: Gpu not available, use cpu\n",
      "2025-04-17 11:41:11,988 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:12,018 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:12,051 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:12,127 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16 HTTP/1.1\" 200 3499\n",
      "2025-04-17 11:41:12,142 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:12,181 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/main HTTP/1.1\" 200 3099\n",
      "2025-04-17 11:41:12,213 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:12,242 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:41:12,354 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:12,386 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:12,431 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.jinja HTTP/1.1\" 404 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 11:41:12,915 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/discussions?p=0 HTTP/1.1\" 200 6380\n",
      "2025-04-17 11:41:12,971 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/refs%2Fpr%2F10 HTTP/1.1\" 200 4064\n",
      "2025-04-17 11:41:13,010 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors.index.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:41:13,041 - 14630809600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors HTTP/1.1\" 302 0\n"
     ]
    }
   ],
   "source": [
    "def read_frame_loader_csv(csv_path, encoding='utf-8-sig'):\n",
    "    with open(csv_path, 'r', encoding=encoding) as f:\n",
    "        data = csv.DictReader(f)\n",
    "        for line in data:\n",
    "            raw_id = line['frame_id']\n",
    "            cleaned_id = raw_id[len('video'):]\n",
    "            # print(\"yeilding\", cleaned_id, line['frame_path_1'], line['frame_path_2'], line['frame_path_3'], line['frame_path_4'],\n",
    "            #       line['frame_path_5'], line['frame_path_6'], line['frame_path_7'], line['frame_path_8'])\n",
    "            values_to_yield = []\n",
    "            values_to_yield.append(int(cleaned_id))\n",
    "            for i in range(NUM_FRAMES):\n",
    "                values_to_yield.append(line[f'frame_path_{i+1}'])\n",
    "            \n",
    "            yield values_to_yield\n",
    "            # yield int(cleaned_id), line['frame_path_1'], line['frame_path_2'], line['frame_path_3'], line['frame_path_4'] \n",
    "\n",
    "\n",
    "frame_loader_pipeline = (\n",
    "    pipe.input('csv_file')\n",
    "    # .flat_map('csv_file', ('frame_id', 'f_path_1', 'f_path_2', 'f_path_3', 'f_path_4'), read_frame_loader_csv)\n",
    "    .flat_map('csv_file', ('frame_id', 'f_path_1', 'f_path_2', 'f_path_3', 'f_path_4', 'f_path_5', 'f_path_6', 'f_path_7', 'f_path_8'), read_frame_loader_csv)\n",
    "    # .map('frame_id', 'frame_id', lambda fid: print(fid))\n",
    "    .map('f_path_1', 'img1', ops.image_decode.cv2('rgb'))\n",
    "    .map('f_path_2', 'img2', ops.image_decode.cv2('rgb'))\n",
    "    .map('f_path_3', 'img3', ops.image_decode.cv2('rgb'))\n",
    "    .map('f_path_4', 'img4', ops.image_decode.cv2('rgb'))\n",
    "    .map('f_path_5', 'img5', ops.image_decode.cv2('rgb'))\n",
    "    .map('f_path_6', 'img6', ops.image_decode.cv2('rgb'))\n",
    "    .map('f_path_7', 'img7', ops.image_decode.cv2('rgb'))\n",
    "    .map('f_path_8', 'img8', ops.image_decode.cv2('rgb'))\n",
    "    \n",
    "    .map('img1', 'vec1', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='image', device='mps'))\n",
    "    .map('img2', 'vec2', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='image', device='mps'))\n",
    "    .map('img3', 'vec3', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='image', device='mps'))\n",
    "    .map('img4', 'vec4', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='image', device='mps'))\n",
    "    .map('img5', 'vec5', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='image', device='mps'))\n",
    "    .map('img6', 'vec6', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='image', device='mps'))\n",
    "    .map('img7', 'vec7', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='image', device='mps'))\n",
    "    .map('img8', 'vec8', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='image', device='mps'))\n",
    "    .map(('vec1', 'vec2', 'vec3', 'vec4', 'vec5', 'vec6', 'vec7', 'vec8'), 'vec', lambda v1, v2, v3, v4, v5, v6, v7, v8: np.mean([v1, v2, v3, v4, v5, v6, v7, v8], axis=0))\n",
    "    # .map(('vec1', 'vec2', 'vec3', 'vec4'), 'vec', lambda v1, v2, v3, v4: np.mean([v1, v2, v3, v4], axis=0))\n",
    "    .map('vec', 'vec', lambda x: x / np.linalg.norm(x))\n",
    "    .map(('frame_id', 'vec'), (), ops.ann_insert.milvus_client(collection_name=FRAME_RET_COLLECTION))\n",
    "    .output('frame_id')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d352597e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 11:41:16,308 - 14630809600 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2025-04-17 11:41:16,308 - 14647635968 - node.py-node:167 - INFO: Begin to run Node-read_frame_loader_csv-0\n",
      "2025-04-17 11:41:16,309 - 14664462336 - node.py-node:167 - INFO: Begin to run Node-image-decode/cv2-1\n",
      "2025-04-17 11:41:16,309 - 14681288704 - node.py-node:167 - INFO: Begin to run Node-image-decode/cv2-2\n",
      "2025-04-17 11:41:16,310 - 14698115072 - node.py-node:167 - INFO: Begin to run Node-image-decode/cv2-3\n",
      "2025-04-17 11:41:16,310 - 14630809600 - node.py-node:167 - INFO: Begin to run Node-image-decode/cv2-4\n",
      "2025-04-17 11:41:16,310 - 14714941440 - node.py-node:167 - INFO: Begin to run Node-image-decode/cv2-5\n",
      "2025-04-17 11:41:16,311 - 14731767808 - node.py-node:167 - INFO: Begin to run Node-image-decode/cv2-6\n",
      "2025-04-17 11:41:16,311 - 14748594176 - node.py-node:167 - INFO: Begin to run Node-image-decode/cv2-7\n",
      "2025-04-17 11:41:16,312 - 14765420544 - node.py-node:167 - INFO: Begin to run Node-image-decode/cv2-8\n",
      "2025-04-17 11:41:16,312 - 14782246912 - node.py-node:167 - INFO: Begin to run Node-image-text-embedding/clip-9\n",
      "2025-04-17 11:41:16,313 - 14799073280 - node.py-node:167 - INFO: Begin to run Node-image-text-embedding/clip-10\n",
      "2025-04-17 11:41:16,314 - 14815899648 - node.py-node:167 - INFO: Begin to run Node-image-text-embedding/clip-11\n",
      "2025-04-17 11:41:16,315 - 14832726016 - node.py-node:167 - INFO: Begin to run Node-image-text-embedding/clip-12\n",
      "2025-04-17 11:41:16,316 - 14849552384 - node.py-node:167 - INFO: Begin to run Node-image-text-embedding/clip-13\n",
      "2025-04-17 11:41:16,317 - 14866378752 - node.py-node:167 - INFO: Begin to run Node-image-text-embedding/clip-14\n",
      "2025-04-17 11:41:16,318 - 14883205120 - node.py-node:167 - INFO: Begin to run Node-image-text-embedding/clip-15\n",
      "2025-04-17 11:41:16,328 - 14647635968 - node.py-node:167 - INFO: Begin to run Node-image-text-embedding/clip-16\n",
      "2025-04-17 11:41:17,678 - 14664462336 - node.py-node:167 - INFO: Begin to run Node-lambda-17\n",
      "2025-04-17 11:41:17,682 - 14681288704 - node.py-node:167 - INFO: Begin to run Node-lambda-18\n",
      "2025-04-17 11:41:17,687 - 14698115072 - node.py-node:167 - INFO: Begin to run Node-ann-insert/milvus-client-19\n",
      "2025-04-17 11:41:17,689 - 14630809600 - node.py-node:167 - INFO: Begin to run Node-_output\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<towhee.runtime.data_queue.DataQueue at 0x32f007520>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_loader_pipeline(MSRVTT_SAMPLES_WITH_FRAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "641f13e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 11:48:50,217 - 8454604864 - clip.py-clip:100 - WARNING: Gpu not available, use cpu\n",
      "2025-04-17 11:48:50,225 - 8454604864 - connectionpool.py-connectionpool:289 - DEBUG: Resetting dropped connection: huggingface.co\n",
      "2025-04-17 11:48:50,404 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:48:50,479 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:48:50,513 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "2025-04-17 11:48:50,518 - 15049191424 - connectionpool.py-connectionpool:1049 - DEBUG: Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-17 11:48:50,588 - 15049191424 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16 HTTP/1.1\" 200 3499\n",
      "2025-04-17 11:48:50,635 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:48:50,660 - 15049191424 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/main HTTP/1.1\" 200 3099\n",
      "2025-04-17 11:48:50,737 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:48:50,737 - 15049191424 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/discussions?p=0 HTTP/1.1\" 200 6380\n",
      "2025-04-17 11:48:50,770 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 11:48:50,860 - 15049191424 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/refs%2Fpr%2F10 HTTP/1.1\" 200 4064\n",
      "2025-04-17 11:48:50,897 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:48:50,900 - 15049191424 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors.index.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:48:50,930 - 15049191424 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors HTTP/1.1\" 302 0\n",
      "2025-04-17 11:48:50,931 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.json HTTP/1.1\" 404 0\n",
      "2025-04-17 11:48:50,971 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.jinja HTTP/1.1\" 404 0\n"
     ]
    }
   ],
   "source": [
    "def read_frame_search_csv(csv_file):\n",
    "    with open(csv_file, 'r', encoding='utf-8-sig') as f:\n",
    "        data = csv.DictReader(f)\n",
    "        for line in data:\n",
    "            yield line['frame_id'], line['sentence']\n",
    "            \n",
    "frame_search_pipeline = (\n",
    "    pipe.input('csv_file')\n",
    "    .flat_map('csv_file', ('rel_frame_id', 'query'), read_frame_search_csv)\n",
    "    .map('query', 'vec', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='text', device='mps'))\n",
    "    .map('vec', 'vec', lambda x: x / np.linalg.norm(x))\n",
    "    .map('vec', 'top10_raw_res', ops.ann_search.milvus_client(collection_name=FRAME_RET_COLLECTION, limit=10))\n",
    "    # .map('vec', 'top10_raw_res', \n",
    "    #      ops.ann_search.milvus_client(collection_name=VIDEO_RET_COLLECTION, limit=10))\n",
    "    .map('top10_raw_res', ('top1', 'top5', 'top10'), lambda x: (x[:1], x[:5], x[:10]))\n",
    "    .output('rel_frame_id', 'query', 'top1', 'top5', 'top10')\n",
    "    # .output('vec')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "df641753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 11:50:21,987 - 15267295232 - node.py-node:167 - INFO: Begin to run Node-read_frame_search_csv-0\n"
     ]
    }
   ],
   "source": [
    "ret_dc = DataCollection(frame_search_pipeline(MSRVTT_SAMPLES_WITH_FRAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dab70054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border-collapse: collapse;\"><tr><th style=\"text-align: center; font-size: 130%; border: none;\">rel_frame_id</th> <th style=\"text-align: center; font-size: 130%; border: none;\">query</th> <th style=\"text-align: center; font-size: 130%; border: none;\">top1</th> <th style=\"text-align: center; font-size: 130%; border: none;\">top5</th> <th style=\"text-align: center; font-size: 130%; border: none;\">top10</th></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video7579</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">a girl wearing red top and black trouser is putting a sweater on a dog</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7579, 1.360194444656372]] len=1</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7579, 1.360194444656372],[9451, 1.4077376127243042],[7730, 1.4435832500457764],[9034, 1.4514113664627075],...] len=5</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7579, 1.360194444656372],[9451, 1.4077376127243042],[7730, 1.4435832500457764],[9034, 1.4514113664627075],...] len=10</td></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video7725</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">young people sit around the edges of a room clapping and raising their arms while others dance in the center during a party</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7725, 1.3989646434783936]] len=1</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7725, 1.3989646434783936],[7444, 1.4208428859710693],[8556, 1.4406566619873047],[8441, 1.4462244510650635],...] len=5</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7725, 1.3989646434783936],[7444, 1.4208428859710693],[8556, 1.4406566619873047],[8441, 1.4462244510650635],...] len=10</td></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video9258</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">a person is using a phone</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9257, 1.422074317932129]] len=1</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9257, 1.422074317932129],[9697, 1.4267330169677734],[9258, 1.4296905994415283],[8945, 1.4394712448120117],...] len=5</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9257, 1.422074317932129],[9697, 1.4267330169677734],[9258, 1.4296905994415283],[8945, 1.4394712448120117],...] len=10</td></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video7365</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">cartoon people are eating at a restaurant</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9777, 1.3951191902160645]] len=1</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9777, 1.3951191902160645],[9537, 1.4230724573135376],[7365, 1.4236586093902588],[7741, 1.4339861869812012],...] len=5</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9777, 1.3951191902160645],[9537, 1.4230724573135376],[7365, 1.4236586093902588],[7741, 1.4339861869812012],...] len=10</td></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video8068</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">a woman on a couch talks to a a man</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7724, 1.3635627031326294]] len=1</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7724, 1.3635627031326294],[7341, 1.4104743003845215],[9347, 1.4147610664367676],[7685, 1.4171432256698608],...] len=5</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7724, 1.3635627031326294],[7341, 1.4104743003845215],[9347, 1.4147610664367676],[7685, 1.4171432256698608],...] len=10</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ret_dc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9b7c4181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO remove this, import from helpers and rerun the whole notebook\n",
    "\n",
    "def twohee_data_col_to_df(twohee_data_collection):\n",
    "    res_list = twohee_data_collection.to_list()\n",
    "    res_obj_list = []\n",
    "    for r in res_list:\n",
    "        res_obj = vars(r)\n",
    "        res_obj_list.append(res_obj)\n",
    "    res_df = pd.DataFrame(res_obj_list)\n",
    "    \n",
    "    # Add ground truth column\n",
    "    if 'rel_video_id' in res_df.columns:\n",
    "        res_df['ground_truth'] = res_df['rel_video_id'].apply(\n",
    "            lambda x: int(x[len('video'):]))\n",
    "    if 'rel_frame_id' in res_df.columns:\n",
    "        res_df['ground_truth'] = res_df['rel_frame_id'].apply(\n",
    "            lambda x: int(x[len('video'):]))\n",
    "    else:\n",
    "        raise ValueError(\"No rel_video_id or rel_frame_id found in the DataCollection\")\n",
    "    return res_df.copy()\n",
    "\n",
    "\n",
    "def average_precision(ground_truth, predictions):\n",
    "    \"\"\"\n",
    "    Calculate the Average Precision (AP) for a single query.\n",
    "\n",
    "    Args:\n",
    "        ground_truth (int): The ground truth video ID.\n",
    "        predictions (list): List of predicted video IDs.\n",
    "\n",
    "    Returns:\n",
    "        float: The Average Precision (AP) score for the query.\n",
    "    \"\"\"\n",
    "    hits = 0\n",
    "    sum_precision = 0\n",
    "    for i, pred in enumerate(predictions):\n",
    "        if pred == ground_truth:\n",
    "            hits += 1\n",
    "            sum_precision += hits / (i + 1)\n",
    "    return sum_precision / hits if hits > 0 else 0\n",
    "\n",
    "\n",
    "def calculate_mean_average_precision(df):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Average Precision (MAP) for the given dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing columns 'query', 'ground_truth', 'top1', 'top5', 'top10'.\n",
    "\n",
    "    Returns:\n",
    "        float: The Mean Average Precision (MAP) score.\n",
    "    \"\"\"\n",
    "    # Calculate AP for each query\n",
    "    ap_scores = []\n",
    "    for _, row in df.iterrows():\n",
    "        ground_truth = row['ground_truth']\n",
    "        predictions_with_scores = row['top10']\n",
    "        predictions = [pred[0] for pred in predictions_with_scores]\n",
    "        ap_scores.append(average_precision(ground_truth, predictions))\n",
    "\n",
    "    # Calculate MAP\n",
    "    mean_ap = sum(ap_scores) / len(ap_scores) if ap_scores else 0\n",
    "    return mean_ap\n",
    "\n",
    "\n",
    "def calculate_recall(df):\n",
    "    \"\"\"\n",
    "    Calculate recall@1, recall@5, and recall@10 for the given dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing columns 'query', 'ground_truth', 'top1', 'top5', 'top10'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing recall@1, recall@5, and recall@10.\n",
    "    \"\"\"\n",
    "    recall_at_1 = 0\n",
    "    recall_at_5 = 0\n",
    "    recall_at_10 = 0\n",
    "    total_queries = len(df)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        ground_truth = row['ground_truth']\n",
    "        if ground_truth in [pred[0] for pred in row['top1']]:\n",
    "            recall_at_1 += 1\n",
    "        if ground_truth in [pred[0] for pred in row['top5']]:\n",
    "            recall_at_5 += 1\n",
    "        if ground_truth in [pred[0] for pred in row['top10']]:\n",
    "            recall_at_10 += 1\n",
    "\n",
    "    return {\n",
    "        'recall@1': recall_at_1 / total_queries,\n",
    "        'recall@5': recall_at_5 / total_queries,\n",
    "        'recall@10': recall_at_10 / total_queries\n",
    "    }\n",
    "\n",
    "\n",
    "def ndcg_score(ground_truth, predictions, k=10):\n",
    "    \"\"\"\n",
    "    Calculate the Normalized Discounted Cumulative Gain (NDCG) for a single query.\n",
    "\n",
    "    Args:\n",
    "        ground_truth (int): The ground truth video ID.\n",
    "        predictions (list): List of predicted video IDs with scores [(id, score), ...].\n",
    "        k (int): The number of top predictions to consider.\n",
    "\n",
    "    Returns:\n",
    "        float: The NDCG score for the query.\n",
    "    \"\"\"\n",
    "    def dcg(relevance_scores):\n",
    "        return sum(rel / np.log2(idx + 2) for idx, rel in enumerate(relevance_scores))\n",
    "\n",
    "    # Relevance scores: 1 if the prediction matches the ground truth, else 0\n",
    "    relevance_scores = [1 if pred[0] ==\n",
    "                        ground_truth else 0 for pred in predictions[:k]]\n",
    "\n",
    "    # Calculate DCG and IDCG\n",
    "    actual_dcg = dcg(relevance_scores)\n",
    "    ideal_dcg = dcg(sorted(relevance_scores, reverse=True))\n",
    "\n",
    "    # Return NDCG\n",
    "    return actual_dcg / ideal_dcg if ideal_dcg > 0 else 0\n",
    "\n",
    "# call this function to get the NDCG score for each query\n",
    "\n",
    "\n",
    "def calculate_ndcg(df, k=10):\n",
    "    \"\"\"\n",
    "    Calculate NDCG for the given dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing columns 'query', 'ground_truth', 'top1', 'top5', 'top10'.\n",
    "        k (int): The number of top predictions to consider.\n",
    "\n",
    "    Returns:\n",
    "        float: The mean NDCG score.\n",
    "    \"\"\"\n",
    "    ndcg_scores = []\n",
    "    for _, row in df.iterrows():\n",
    "        ground_truth = row['ground_truth']\n",
    "        predictions_with_scores = row['top10']\n",
    "        ndcg_scores.append(ndcg_score(\n",
    "            ground_truth, predictions_with_scores, k))\n",
    "\n",
    "    return sum(ndcg_scores) / len(ndcg_scores) if ndcg_scores else 0\n",
    "\n",
    "\n",
    "def get_all_eval_scores(df):\n",
    "    \"\"\"Return a dataframe with all evaluation scores: Recall@1, Recall@5, Recall@10, MAP, NDCG@1, NDCG@5, NDCG@10\"\"\"\n",
    "    recall_scores = calculate_recall(df)\n",
    "    map_score = calculate_mean_average_precision(df)\n",
    "    ndcg_score_1 = calculate_ndcg(df, k=1)\n",
    "    ndcg_score_5 = calculate_ndcg(df, k=5)\n",
    "    ndcg_score_10 = calculate_ndcg(df, k=10)\n",
    "\n",
    "    eval_scores = {\n",
    "        'recall@1': recall_scores['recall@1'],\n",
    "        'recall@5': recall_scores['recall@5'],\n",
    "        'recall@10': recall_scores['recall@10'],\n",
    "        'map': map_score,\n",
    "        'ndcg@1': ndcg_score_1,\n",
    "        'ndcg@5': ndcg_score_5,\n",
    "        'ndcg@10': ndcg_score_10\n",
    "    }\n",
    "\n",
    "    return eval_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2b8a22f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rel_frame_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "query",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "top1",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "top5",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "top10",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ground_truth",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e7bb423f-62cf-4cd5-a87f-8f4f404ec4e0",
       "rows": [
        [
         "0",
         "video7579",
         "a girl wearing red top and black trouser is putting a sweater on a dog",
         "[[7579, 1.360194444656372]]",
         "[[7579, 1.360194444656372], [9451, 1.4077376127243042], [7730, 1.4435832500457764], [9034, 1.4514113664627075], [7361, 1.4548304080963135]]",
         "[[7579, 1.360194444656372], [9451, 1.4077376127243042], [7730, 1.4435832500457764], [9034, 1.4514113664627075], [7361, 1.4548304080963135], [9405, 1.4561405181884766], [8825, 1.4576396942138672], [8837, 1.457802176475525], [9603, 1.46173894405365], [9969, 1.4722375869750977]]",
         "7579"
        ],
        [
         "1",
         "video7725",
         "young people sit around the edges of a room clapping and raising their arms while others dance in the center during a party",
         "[[7725, 1.3989646434783936]]",
         "[[7725, 1.3989646434783936], [7444, 1.4208428859710693], [8556, 1.4406566619873047], [8441, 1.4462244510650635], [8339, 1.456601619720459]]",
         "[[7725, 1.3989646434783936], [7444, 1.4208428859710693], [8556, 1.4406566619873047], [8441, 1.4462244510650635], [8339, 1.456601619720459], [8014, 1.4594473838806152], [9957, 1.4651188850402832], [9131, 1.4674513339996338], [9063, 1.4686394929885864], [7141, 1.4689221382141113]]",
         "7725"
        ],
        [
         "2",
         "video9258",
         "a person is using a phone",
         "[[9257, 1.422074317932129]]",
         "[[9257, 1.422074317932129], [9697, 1.4267330169677734], [9258, 1.4296905994415283], [8945, 1.4394712448120117], [9829, 1.4399117231369019]]",
         "[[9257, 1.422074317932129], [9697, 1.4267330169677734], [9258, 1.4296905994415283], [8945, 1.4394712448120117], [9829, 1.4399117231369019], [7418, 1.4420685768127441], [8804, 1.4465346336364746], [8681, 1.4465482234954834], [7354, 1.4485728740692139], [7687, 1.4489171504974365]]",
         "9258"
        ],
        [
         "3",
         "video7365",
         "cartoon people are eating at a restaurant",
         "[[9777, 1.3951191902160645]]",
         "[[9777, 1.3951191902160645], [9537, 1.4230724573135376], [7365, 1.4236586093902588], [7741, 1.4339861869812012], [8129, 1.4487584829330444]]",
         "[[9777, 1.3951191902160645], [9537, 1.4230724573135376], [7365, 1.4236586093902588], [7741, 1.4339861869812012], [8129, 1.4487584829330444], [9814, 1.4595956802368164], [8781, 1.460620403289795], [8911, 1.4645159244537354], [7835, 1.4648187160491943], [7968, 1.4700990915298462]]",
         "7365"
        ],
        [
         "4",
         "video8068",
         "a woman on a couch talks to a a man",
         "[[7724, 1.3635627031326294]]",
         "[[7724, 1.3635627031326294], [7341, 1.4104743003845215], [9347, 1.4147610664367676], [7685, 1.4171432256698608], [8783, 1.4174704551696777]]",
         "[[7724, 1.3635627031326294], [7341, 1.4104743003845215], [9347, 1.4147610664367676], [7685, 1.4171432256698608], [8783, 1.4174704551696777], [9023, 1.4179743528366089], [8068, 1.4184623956680298], [8254, 1.4226744174957275], [7832, 1.4292242527008057], [9517, 1.4299376010894775]]",
         "8068"
        ],
        [
         "5",
         "video7131",
         "athletes are getting ready and start running for an event",
         "[[8264, 1.4242017269134521]]",
         "[[8264, 1.4242017269134521], [7131, 1.4267456531524658], [8322, 1.4885741472244263], [8817, 1.4921003580093384], [8451, 1.4965126514434814]]",
         "[[8264, 1.4242017269134521], [7131, 1.4267456531524658], [8322, 1.4885741472244263], [8817, 1.4921003580093384], [8451, 1.4965126514434814], [7776, 1.4971873760223389], [9302, 1.5007150173187256], [8816, 1.5037944316864014], [8339, 1.5045162439346313], [7168, 1.5060158967971802]]",
         "7131"
        ],
        [
         "6",
         "video7213",
         "a woman is making lasagna",
         "[[7213, 1.3687245845794678]]",
         "[[7213, 1.3687245845794678], [7154, 1.3698673248291016], [7966, 1.387349009513855], [8910, 1.3916771411895752], [7968, 1.3977160453796387]]",
         "[[7213, 1.3687245845794678], [7154, 1.3698673248291016], [7966, 1.387349009513855], [8910, 1.3916771411895752], [7968, 1.3977160453796387], [8686, 1.4040558338165283], [8915, 1.40582275390625], [7799, 1.4082245826721191], [7744, 1.4111087322235107], [9693, 1.4122376441955566]]",
         "7213"
        ],
        [
         "7",
         "video7575",
         "a man speaking in a microphone",
         "[[7828, 1.364684820175171]]",
         "[[7828, 1.364684820175171], [9203, 1.3809665441513062], [7575, 1.3929505348205566], [9474, 1.3994146585464478], [7491, 1.4011871814727783]]",
         "[[7828, 1.364684820175171], [9203, 1.3809665441513062], [7575, 1.3929505348205566], [9474, 1.3994146585464478], [7491, 1.4011871814727783], [9885, 1.4013630151748657], [8072, 1.4123351573944092], [7418, 1.4152038097381592], [8269, 1.417567253112793], [9404, 1.4182287454605103]]",
         "7575"
        ],
        [
         "8",
         "video7978",
         "a team with blue uniforms are playing badmitten with a team in white",
         "[[9647, 1.453139305114746]]",
         "[[9647, 1.453139305114746], [9013, 1.4564461708068848], [7710, 1.4603581428527832], [7788, 1.4652950763702393], [7021, 1.466395616531372]]",
         "[[9647, 1.453139305114746], [9013, 1.4564461708068848], [7710, 1.4603581428527832], [7788, 1.4652950763702393], [7021, 1.466395616531372], [8817, 1.476462721824646], [9224, 1.4816417694091797], [7500, 1.4842991828918457], [7723, 1.4863321781158447], [9681, 1.4918086528778076]]",
         "7978"
        ],
        [
         "9",
         "video8123",
         "a woman is giving demo for baby trolley",
         "[[7230, 1.3555216789245605]]",
         "[[7230, 1.3555216789245605], [9755, 1.3671965599060059], [7217, 1.3729103803634644], [8258, 1.3755340576171875], [7827, 1.3770864009857178]]",
         "[[7230, 1.3555216789245605], [9755, 1.3671965599060059], [7217, 1.3729103803634644], [8258, 1.3755340576171875], [7827, 1.3770864009857178], [8018, 1.3985960483551025], [8123, 1.4019970893859863], [8899, 1.4271119832992554], [7364, 1.4432038068771362], [9696, 1.4518146514892578]]",
         "8123"
        ],
        [
         "10",
         "video9800",
         "a car is in a wreck",
         "[[9622, 1.3645062446594238]]",
         "[[9622, 1.3645062446594238], [7765, 1.4061617851257324], [9800, 1.4145509004592896], [7965, 1.4164247512817383], [8089, 1.4203362464904785]]",
         "[[9622, 1.3645062446594238], [7765, 1.4061617851257324], [9800, 1.4145509004592896], [7965, 1.4164247512817383], [8089, 1.4203362464904785], [8973, 1.4260053634643555], [9511, 1.428531289100647], [7354, 1.42897629737854], [9806, 1.4326753616333008], [8497, 1.4331560134887695]]",
         "9800"
        ],
        [
         "11",
         "video9205",
         "a woman interviewing about her part in a protest happening in brazil",
         "[[9205, 1.4102778434753418]]",
         "[[9205, 1.4102778434753418], [9028, 1.4347989559173584], [7364, 1.448054313659668], [7341, 1.4572813510894775], [8311, 1.4642090797424316]]",
         "[[9205, 1.4102778434753418], [9028, 1.4347989559173584], [7364, 1.448054313659668], [7341, 1.4572813510894775], [8311, 1.4642090797424316], [7822, 1.4670538902282715], [8022, 1.471035122871399], [7680, 1.47216796875], [8254, 1.4726080894470215], [7580, 1.4775995016098022]]",
         "9205"
        ],
        [
         "12",
         "video7590",
         "an emotional scene of two persons where they are crying on meeting",
         "[[7590, 1.4150629043579102]]",
         "[[7590, 1.4150629043579102], [9521, 1.4219805002212524], [7619, 1.4261687994003296], [7163, 1.4298243522644043], [8879, 1.430858850479126]]",
         "[[7590, 1.4150629043579102], [9521, 1.4219805002212524], [7619, 1.4261687994003296], [7163, 1.4298243522644043], [8879, 1.430858850479126], [8330, 1.4390268325805664], [8349, 1.4432077407836914], [7110, 1.4439359903335571], [8974, 1.4455170631408691], [8318, 1.4465126991271973]]",
         "7590"
        ],
        [
         "13",
         "video9017",
         "the man is driving his motorbike fast and having problems on the race",
         "[[8657, 1.3764333724975586]]",
         "[[8657, 1.3764333724975586], [7544, 1.3780450820922852], [8089, 1.3799407482147217], [7616, 1.3828401565551758], [9511, 1.3850352764129639]]",
         "[[8657, 1.3764333724975586], [7544, 1.3780450820922852], [8089, 1.3799407482147217], [7616, 1.3828401565551758], [9511, 1.3850352764129639], [8934, 1.3910493850708008], [7214, 1.3957018852233887], [9017, 1.3965098857879639], [9806, 1.3978595733642578], [8820, 1.4037936925888062]]",
         "9017"
        ],
        [
         "14",
         "video9241",
         "japanese people laughing and dancing",
         "[[9131, 1.3297301530838013]]",
         "[[9131, 1.3297301530838013], [9682, 1.4026682376861572], [8118, 1.4155192375183105], [8349, 1.419693946838379], [9241, 1.421635389328003]]",
         "[[9131, 1.3297301530838013], [9682, 1.4026682376861572], [8118, 1.4155192375183105], [8349, 1.419693946838379], [9241, 1.421635389328003], [8241, 1.4288599491119385], [8606, 1.4295796155929565], [7725, 1.432772159576416], [8306, 1.4363956451416016], [8899, 1.4364792108535767]]",
         "9241"
        ],
        [
         "15",
         "video7158",
         "fox news presidential debate recapping the gop debate with donald trump and ted cruz",
         "[[7158, 1.2895922660827637]]",
         "[[7158, 1.2895922660827637], [8464, 1.331559181213379], [7731, 1.3752323389053345], [9223, 1.3968212604522705], [8789, 1.4349762201309204]]",
         "[[7158, 1.2895922660827637], [8464, 1.331559181213379], [7731, 1.3752323389053345], [9223, 1.3968212604522705], [8789, 1.4349762201309204], [7234, 1.438897728919983], [7754, 1.442396640777588], [8824, 1.4648716449737549], [7231, 1.473816156387329], [8494, 1.4786052703857422]]",
         "7158"
        ],
        [
         "16",
         "video9233",
         "a man is giving a speech",
         "[[8416, 1.3901981115341187]]",
         "[[8416, 1.3901981115341187], [9233, 1.3903570175170898], [9404, 1.3980587720870972], [7828, 1.4033946990966797], [7418, 1.4062241315841675]]",
         "[[8416, 1.3901981115341187], [9233, 1.3903570175170898], [9404, 1.3980587720870972], [7828, 1.4033946990966797], [7418, 1.4062241315841675], [9203, 1.4114739894866943], [8346, 1.4136106967926025], [9350, 1.4152705669403076], [8804, 1.4171212911605835], [8445, 1.418581485748291]]",
         "9233"
        ],
        [
         "17",
         "video8687",
         "fast moving time is shown here",
         "[[8909, 1.3994320631027222]]",
         "[[8909, 1.3994320631027222], [8681, 1.4005186557769775], [9224, 1.4145855903625488], [8973, 1.4205141067504883], [9691, 1.4236668348312378]]",
         "[[8909, 1.3994320631027222], [8681, 1.4005186557769775], [9224, 1.4145855903625488], [8973, 1.4205141067504883], [9691, 1.4236668348312378], [9511, 1.426809549331665], [7418, 1.4269447326660156], [7616, 1.4284309148788452], [7765, 1.4310595989227295], [8622, 1.4311281442642212]]",
         "8687"
        ],
        [
         "18",
         "video9337",
         "some people are inside of a room",
         "[[9324, 1.4088647365570068]]",
         "[[9324, 1.4088647365570068], [7114, 1.426087737083435], [8076, 1.4264914989471436], [7780, 1.4321777820587158], [8486, 1.4327287673950195]]",
         "[[9324, 1.4088647365570068], [7114, 1.426087737083435], [8076, 1.4264914989471436], [7780, 1.4321777820587158], [8486, 1.4327287673950195], [9307, 1.4329274892807007], [7149, 1.4347960948944092], [9237, 1.440209150314331], [9878, 1.4404793977737427], [9322, 1.4414770603179932]]",
         "9337"
        ],
        [
         "19",
         "video9620",
         "outer space pictures that have parts of equipments in them with water droplets on it",
         "[[9620, 1.3663861751556396]]",
         "[[9620, 1.3663861751556396], [8674, 1.4335932731628418], [7562, 1.447702407836914], [8069, 1.4535737037658691], [7732, 1.458290934562683]]",
         "[[9620, 1.3663861751556396], [8674, 1.4335932731628418], [7562, 1.447702407836914], [8069, 1.4535737037658691], [7732, 1.458290934562683], [7431, 1.4591701030731201], [9609, 1.4690251350402832], [8246, 1.4720463752746582], [7027, 1.48012375831604], [7178, 1.4825210571289062]]",
         "9620"
        ],
        [
         "20",
         "video7411",
         "jolly good music troop delivering a program and the lady is in good spirit",
         "[[8919, 1.494800090789795]]",
         "[[8919, 1.494800090789795], [9357, 1.5064104795455933], [7843, 1.5191407203674316], [9352, 1.522047996520996], [9908, 1.5301480293273926]]",
         "[[8919, 1.494800090789795], [9357, 1.5064104795455933], [7843, 1.5191407203674316], [9352, 1.522047996520996], [9908, 1.5301480293273926], [7827, 1.5304268598556519], [7772, 1.5314029455184937], [8022, 1.5335828065872192], [9745, 1.5390390157699585], [8317, 1.5399816036224365]]",
         "7411"
        ],
        [
         "21",
         "video8514",
         "a person is putting the vegetable in to the water and boil it",
         "[[8514, 1.3199840784072876]]",
         "[[8514, 1.3199840784072876], [7968, 1.3534109592437744], [9625, 1.3617327213287354], [9639, 1.3719770908355713], [9335, 1.3785195350646973]]",
         "[[8514, 1.3199840784072876], [7968, 1.3534109592437744], [9625, 1.3617327213287354], [9639, 1.3719770908355713], [9335, 1.3785195350646973], [8300, 1.384836196899414], [7911, 1.384903073310852], [9693, 1.3953529596328735], [7154, 1.4001762866973877], [8751, 1.4005178213119507]]",
         "8514"
        ],
        [
         "22",
         "video8481",
         "a woman is reporting on keds commercials",
         "[[8481, 1.3050001859664917]]",
         "[[8481, 1.3050001859664917], [8494, 1.4104677438735962], [9600, 1.434720754623413], [7231, 1.436944842338562], [8826, 1.4388415813446045]]",
         "[[8481, 1.3050001859664917], [8494, 1.4104677438735962], [9600, 1.434720754623413], [7231, 1.436944842338562], [8826, 1.4388415813446045], [8488, 1.4453340768814087], [7724, 1.446473479270935], [8254, 1.446864366531372], [7577, 1.4489020109176636], [9575, 1.453249216079712]]",
         "8481"
        ],
        [
         "23",
         "video9224",
         "someone is playing a game",
         "[[7780, 1.4275999069213867]]",
         "[[7780, 1.4275999069213867], [9829, 1.4381603002548218], [8811, 1.4560742378234863], [7354, 1.457515001296997], [8123, 1.4606213569641113]]",
         "[[7780, 1.4275999069213867], [9829, 1.4381603002548218], [8811, 1.4560742378234863], [7354, 1.457515001296997], [8123, 1.4606213569641113], [7166, 1.4616601467132568], [9224, 1.4631907939910889], [8075, 1.4659576416015625], [8909, 1.4676320552825928], [9773, 1.4683095216751099]]",
         "9224"
        ],
        [
         "24",
         "video8426",
         "cabins on a sandy beach have walkways going up to their porches",
         "[[8426, 1.3310009241104126]]",
         "[[8426, 1.3310009241104126], [9332, 1.476109504699707], [9244, 1.4826526641845703], [8803, 1.4940145015716553], [9253, 1.495681643486023]]",
         "[[8426, 1.3310009241104126], [9332, 1.476109504699707], [9244, 1.4826526641845703], [8803, 1.4940145015716553], [9253, 1.495681643486023], [9338, 1.503388524055481], [9814, 1.5147243738174438], [7370, 1.514752745628357], [7588, 1.518836498260498], [8895, 1.518934965133667]]",
         "8426"
        ],
        [
         "25",
         "video9699",
         "a man explains how to do a experiment",
         "[[9699, 1.3441588878631592]]",
         "[[9699, 1.3441588878631592], [7546, 1.359521746635437], [8067, 1.3714537620544434], [8772, 1.372743010520935], [8257, 1.3797624111175537]]",
         "[[9699, 1.3441588878631592], [7546, 1.359521746635437], [8067, 1.3714537620544434], [8772, 1.372743010520935], [8257, 1.3797624111175537], [8774, 1.380042552947998], [9256, 1.380330204963684], [8834, 1.3837482929229736], [9335, 1.3848531246185303], [7418, 1.3851373195648193]]",
         "9699"
        ],
        [
         "26",
         "video9882",
         "a news reader is reading the news and asking question to some people",
         "[[9204, 1.3758230209350586]]",
         "[[9204, 1.3758230209350586], [9205, 1.381375789642334], [8311, 1.3885324001312256], [8333, 1.3899558782577515], [7469, 1.3998193740844727]]",
         "[[9204, 1.3758230209350586], [9205, 1.381375789642334], [8311, 1.3885324001312256], [8333, 1.3899558782577515], [7469, 1.3998193740844727], [8022, 1.4000272750854492], [7790, 1.4002532958984375], [7967, 1.4082486629486084], [8822, 1.4090075492858887], [8254, 1.4119230508804321]]",
         "9882"
        ],
        [
         "27",
         "video8300",
         "a woman pours water into her pot of meat then tomato sauce and stirs it all around while talking",
         "[[8300, 1.309309720993042]]",
         "[[8300, 1.309309720993042], [8910, 1.3431966304779053], [7744, 1.3470373153686523], [8772, 1.3604199886322021], [8479, 1.365689754486084]]",
         "[[8300, 1.309309720993042], [8910, 1.3431966304779053], [7744, 1.3470373153686523], [8772, 1.3604199886322021], [8479, 1.365689754486084], [8654, 1.368928074836731], [9335, 1.3744888305664062], [9693, 1.3764785528182983], [9689, 1.383622407913208], [9022, 1.3849060535430908]]",
         "8300"
        ],
        [
         "28",
         "video8863",
         "an animated girl talks to a baby and plays with it",
         "[[8676, 1.375429630279541]]",
         "[[8676, 1.375429630279541], [8123, 1.3770849704742432], [8863, 1.3829219341278076], [9777, 1.3894789218902588], [7020, 1.3988685607910156]]",
         "[[8676, 1.375429630279541], [8123, 1.3770849704742432], [8863, 1.3829219341278076], [9777, 1.3894789218902588], [7020, 1.3988685607910156], [7179, 1.4020097255706787], [9338, 1.4050370454788208], [8018, 1.405821442604065], [8672, 1.406315565109253], [9682, 1.4102535247802734]]",
         "8863"
        ],
        [
         "29",
         "video7147",
         "a man cooks burgers and bacon on a grill",
         "[[9333, 1.3220689296722412]]",
         "[[9333, 1.3220689296722412], [7147, 1.3264814615249634], [7154, 1.3773176670074463], [9694, 1.3795381784439087], [8834, 1.393604040145874]]",
         "[[9333, 1.3220689296722412], [7147, 1.3264814615249634], [7154, 1.3773176670074463], [9694, 1.3795381784439087], [8834, 1.393604040145874], [8078, 1.4136607646942139], [9335, 1.4144694805145264], [7820, 1.426265835762024], [8300, 1.4347002506256104], [8686, 1.436142086982727]]",
         "7147"
        ],
        [
         "30",
         "video7744",
         "a chef stirs up some ingredients inside of a pan",
         "[[9335, 1.2835357189178467]]",
         "[[9335, 1.2835357189178467], [7966, 1.3191606998443604], [8514, 1.3302453756332397], [8300, 1.3379318714141846], [9625, 1.3452807664871216]]",
         "[[9335, 1.2835357189178467], [7966, 1.3191606998443604], [8514, 1.3302453756332397], [8300, 1.3379318714141846], [9625, 1.3452807664871216], [7148, 1.3498520851135254], [7554, 1.352104902267456], [8865, 1.3555691242218018], [7360, 1.3574309349060059], [7799, 1.3580231666564941]]",
         "7744"
        ],
        [
         "31",
         "video7839",
         "this is a vine sports compilation",
         "[[8979, 1.279695749282837]]",
         "[[8979, 1.279695749282837], [9029, 1.3010227680206299], [7787, 1.306670904159546], [8253, 1.3104965686798096], [8913, 1.3124048709869385]]",
         "[[8979, 1.279695749282837], [9029, 1.3010227680206299], [7787, 1.306670904159546], [8253, 1.3104965686798096], [8913, 1.3124048709869385], [9605, 1.3202775716781616], [7839, 1.3276715278625488], [9018, 1.334777593612671], [7358, 1.3351337909698486], [9542, 1.3442684412002563]]",
         "7839"
        ],
        [
         "32",
         "video7214",
         "race cars of different colors lined up on a dark track",
         "[[7214, 1.4339113235473633]]",
         "[[7214, 1.4339113235473633], [7464, 1.4339215755462646], [8689, 1.4365336894989014], [9328, 1.4586873054504395], [8473, 1.460493564605713]]",
         "[[7214, 1.4339113235473633], [7464, 1.4339215755462646], [8689, 1.4365336894989014], [9328, 1.4586873054504395], [8473, 1.460493564605713], [9832, 1.4694325923919678], [7616, 1.4712269306182861], [9691, 1.4734892845153809], [7219, 1.4770662784576416], [9535, 1.4780242443084717]]",
         "7214"
        ],
        [
         "33",
         "video7771",
         "a golf player is trying to hit the ball into the pit",
         "[[7771, 1.3209941387176514]]",
         "[[7771, 1.3209941387176514], [7021, 1.4097967147827148], [8125, 1.4298264980316162], [8049, 1.4522924423217773], [7822, 1.4534566402435303]]",
         "[[7771, 1.3209941387176514], [7021, 1.4097967147827148], [8125, 1.4298264980316162], [8049, 1.4522924423217773], [7822, 1.4534566402435303], [7112, 1.4561809301376343], [7699, 1.4571073055267334], [7168, 1.4612065553665161], [8816, 1.461600661277771], [9832, 1.4646892547607422]]",
         "7771"
        ],
        [
         "34",
         "video8486",
         "a cartoon on a young guy cursing",
         "[[8486, 1.3750333786010742]]",
         "[[8486, 1.3750333786010742], [9777, 1.4089462757110596], [7741, 1.409935712814331], [7977, 1.418604850769043], [7160, 1.4318504333496094]]",
         "[[8486, 1.3750333786010742], [9777, 1.4089462757110596], [7741, 1.409935712814331], [7977, 1.418604850769043], [7160, 1.4318504333496094], [9242, 1.433635950088501], [7172, 1.4341390132904053], [8673, 1.4345061779022217], [9206, 1.4404555559158325], [7365, 1.4434764385223389]]",
         "8486"
        ],
        [
         "35",
         "video9909",
         "a crowd of people sitting next to each other as one man plays a video game",
         "[[8689, 1.3779256343841553]]",
         "[[8689, 1.3779256343841553], [9909, 1.393164873123169], [8472, 1.4103622436523438], [8313, 1.4261143207550049], [9224, 1.4302984476089478]]",
         "[[8689, 1.3779256343841553], [9909, 1.393164873123169], [8472, 1.4103622436523438], [8313, 1.4261143207550049], [9224, 1.4302984476089478], [7685, 1.4333863258361816], [8459, 1.4342341423034668], [7766, 1.4429917335510254], [7141, 1.4438167810440063], [8116, 1.4439585208892822]]",
         "9909"
        ],
        [
         "36",
         "video8922",
         "an old man shakes hands with another man and then they hug each other",
         "[[8922, 1.4179236888885498]]",
         "[[8922, 1.4179236888885498], [7200, 1.430182695388794], [8899, 1.445051908493042], [7110, 1.4464250802993774], [7158, 1.4552102088928223]]",
         "[[8922, 1.4179236888885498], [7200, 1.430182695388794], [8899, 1.445051908493042], [7110, 1.4464250802993774], [7158, 1.4552102088928223], [9681, 1.4552217721939087], [7362, 1.4558944702148438], [8815, 1.4569724798202515], [9520, 1.4579074382781982], [7590, 1.4586222171783447]]",
         "8922"
        ],
        [
         "37",
         "video9814",
         "a scene from spongebob squarepants where the townspeople are carrying torches and chasing a giant squidward",
         "[[9814, 1.3581178188323975]]",
         "[[9814, 1.3581178188323975], [7835, 1.37339448928833], [8128, 1.3851126432418823], [8916, 1.3904920816421509], [7111, 1.3949962854385376]]",
         "[[9814, 1.3581178188323975], [7835, 1.37339448928833], [8128, 1.3851126432418823], [8916, 1.3904920816421509], [7111, 1.3949962854385376], [7218, 1.399977445602417], [7235, 1.4047222137451172], [9300, 1.4151124954223633], [8673, 1.4195220470428467], [9014, 1.4202649593353271]]",
         "9814"
        ],
        [
         "38",
         "video9368",
         "someone demonstrates about the small motor uses to the video",
         "[[8626, 1.355933666229248]]",
         "[[8626, 1.355933666229248], [7688, 1.3614188432693481], [9696, 1.36846923828125], [7765, 1.3852827548980713], [7820, 1.387082576751709]]",
         "[[8626, 1.355933666229248], [7688, 1.3614188432693481], [9696, 1.36846923828125], [7765, 1.3852827548980713], [7820, 1.387082576751709], [9755, 1.3891630172729492], [8622, 1.389190912246704], [9368, 1.389275074005127], [7369, 1.3901052474975586], [9508, 1.395032525062561]]",
         "9368"
        ],
        [
         "39",
         "video8820",
         "a person comes up in the hill on a orange motor bike and falls down",
         "[[8820, 1.392780065536499]]",
         "[[8820, 1.392780065536499], [9511, 1.3939456939697266], [8125, 1.3942123651504517], [7616, 1.412494421005249], [7544, 1.4145182371139526]]",
         "[[8820, 1.392780065536499], [9511, 1.3939456939697266], [8125, 1.3942123651504517], [7616, 1.412494421005249], [7544, 1.4145182371139526], [9800, 1.417938232421875], [9489, 1.4220986366271973], [9622, 1.4224244356155396], [7649, 1.4225233793258667], [8934, 1.4259713888168335]]",
         "8820"
        ],
        [
         "40",
         "video9452",
         "an animated grey shark in the middle of a blue water simulation background rotating in a circle on the screen of a monitor",
         "[[9452, 1.2445812225341797]]",
         "[[9452, 1.2445812225341797], [8909, 1.3230962753295898], [8328, 1.3801560401916504], [8111, 1.3939447402954102], [7061, 1.4033973217010498]]",
         "[[9452, 1.2445812225341797], [8909, 1.3230962753295898], [8328, 1.3801560401916504], [8111, 1.3939447402954102], [7061, 1.4033973217010498], [8010, 1.431376576423645], [7027, 1.4361399412155151], [7900, 1.4474891424179077], [9820, 1.4502549171447754], [9620, 1.450631856918335]]",
         "9452"
        ],
        [
         "41",
         "video9344",
         "gameplay footage of someone playing a game",
         "[[7780, 1.3388729095458984]]",
         "[[7780, 1.3388729095458984], [9224, 1.3456008434295654], [8313, 1.3524413108825684], [9336, 1.354132890701294], [9795, 1.3543238639831543]]",
         "[[7780, 1.3388729095458984], [9224, 1.3456008434295654], [8313, 1.3524413108825684], [9336, 1.354132890701294], [9795, 1.3543238639831543], [7919, 1.354841947555542], [9452, 1.3550097942352295], [8027, 1.3595637083053589], [8116, 1.3634378910064697], [8689, 1.36542546749115]]",
         "9344"
        ],
        [
         "42",
         "video9032",
         "a hospital mortuary room and a doctor treat the special case",
         "[[9032, 1.393576979637146]]",
         "[[9032, 1.393576979637146], [8664, 1.4111671447753906], [8325, 1.4200739860534668], [7963, 1.4272494316101074], [8129, 1.4323883056640625]]",
         "[[9032, 1.393576979637146], [8664, 1.4111671447753906], [8325, 1.4200739860534668], [7963, 1.4272494316101074], [8129, 1.4323883056640625], [8606, 1.4397680759429932], [7829, 1.442253828048706], [7114, 1.4486138820648193], [9322, 1.45245361328125], [9579, 1.4538488388061523]]",
         "9032"
        ],
        [
         "43",
         "video9016",
         "all persons are wearing bikini dresses and playing in sea",
         "[[7117, 1.3964838981628418]]",
         "[[7117, 1.3964838981628418], [7681, 1.4269509315490723], [9359, 1.42836332321167], [8928, 1.4323508739471436], [9338, 1.4359803199768066]]",
         "[[7117, 1.3964838981628418], [7681, 1.4269509315490723], [9359, 1.42836332321167], [8928, 1.4323508739471436], [9338, 1.4359803199768066], [8999, 1.437074899673462], [7025, 1.4406285285949707], [8118, 1.4457851648330688], [9016, 1.4520138502120972], [9342, 1.4589543342590332]]",
         "9016"
        ],
        [
         "44",
         "video9353",
         "two women are outside and are discussing something in a foreign language",
         "[[7724, 1.4136474132537842]]",
         "[[7724, 1.4136474132537842], [9871, 1.434537649154663], [8306, 1.4359694719314575], [7116, 1.4472087621688843], [9341, 1.450223684310913]]",
         "[[7724, 1.4136474132537842], [9871, 1.434537649154663], [8306, 1.4359694719314575], [7116, 1.4472087621688843], [9341, 1.450223684310913], [7149, 1.4549376964569092], [8078, 1.458775520324707], [9039, 1.4601061344146729], [7780, 1.4609837532043457], [7370, 1.4635804891586304]]",
         "9353"
        ],
        [
         "45",
         "video9405",
         "red balloons float in the sky and have packages tied to them",
         "[[9405, 1.2989726066589355]]",
         "[[9405, 1.2989726066589355], [9680, 1.4573397636413574], [9030, 1.4758490324020386], [8945, 1.4805208444595337], [8075, 1.4809930324554443]]",
         "[[9405, 1.2989726066589355], [9680, 1.4573397636413574], [9030, 1.4758490324020386], [8945, 1.4805208444595337], [8075, 1.4809930324554443], [8110, 1.482123613357544], [8260, 1.4827752113342285], [8481, 1.4857338666915894], [9246, 1.4886568784713745], [9014, 1.4891756772994995]]",
         "9405"
        ],
        [
         "46",
         "video7559",
         "a man is trying some sushi",
         "[[7559, 1.3845603466033936]]",
         "[[7559, 1.3845603466033936], [9687, 1.4133687019348145], [7968, 1.4166603088378906], [8686, 1.428816795349121], [9537, 1.4343377351760864]]",
         "[[7559, 1.3845603466033936], [9687, 1.4133687019348145], [7968, 1.4166603088378906], [8686, 1.428816795349121], [9537, 1.4343377351760864], [9309, 1.4409068822860718], [8129, 1.4488664865493774], [8772, 1.4515093564987183], [8325, 1.459891438484192], [8300, 1.459998607635498]]",
         "7559"
        ],
        [
         "47",
         "video9063",
         "people on stage performing",
         "[[9063, 1.4032648801803589]]",
         "[[9063, 1.4032648801803589], [7558, 1.417301893234253], [7156, 1.4261060953140259], [8324, 1.4339599609375], [8441, 1.43422269821167]]",
         "[[9063, 1.4032648801803589], [7558, 1.417301893234253], [7156, 1.4261060953140259], [8324, 1.4339599609375], [8441, 1.43422269821167], [9131, 1.4370691776275635], [8926, 1.4415887594223022], [8445, 1.4431301355361938], [7772, 1.4437543153762817], [9304, 1.443985104560852]]",
         "9063"
        ],
        [
         "48",
         "video7352",
         "a movie scene starring morgan freeman and men in armor running",
         "[[8475, 1.3970510959625244]]",
         "[[8475, 1.3970510959625244], [8061, 1.3975272178649902], [8122, 1.4001202583312988], [7352, 1.4201266765594482], [8948, 1.4205992221832275]]",
         "[[8475, 1.3970510959625244], [8061, 1.3975272178649902], [8122, 1.4001202583312988], [7352, 1.4201266765594482], [8948, 1.4205992221832275], [9230, 1.4253015518188477], [9742, 1.4277565479278564], [8266, 1.4320285320281982], [8808, 1.4362895488739014], [8680, 1.4392499923706055]]",
         "7352"
        ],
        [
         "49",
         "video8447",
         "a woman singing on the voice",
         "[[9222, 1.304178237915039]]",
         "[[9222, 1.304178237915039], [8810, 1.3192046880722046], [8265, 1.3269178867340088], [7569, 1.3315062522888184], [8447, 1.3328766822814941]]",
         "[[9222, 1.304178237915039], [8810, 1.3192046880722046], [8265, 1.3269178867340088], [7569, 1.3315062522888184], [8447, 1.3328766822814941], [9351, 1.333519697189331], [9778, 1.334324598312378], [8818, 1.334850788116455], [9518, 1.3365559577941895], [9304, 1.345929503440857]]",
         "8447"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 1000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rel_frame_id</th>\n",
       "      <th>query</th>\n",
       "      <th>top1</th>\n",
       "      <th>top5</th>\n",
       "      <th>top10</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video7579</td>\n",
       "      <td>a girl wearing red top and black trouser is pu...</td>\n",
       "      <td>[[7579, 1.360194444656372]]</td>\n",
       "      <td>[[7579, 1.360194444656372], [9451, 1.407737612...</td>\n",
       "      <td>[[7579, 1.360194444656372], [9451, 1.407737612...</td>\n",
       "      <td>7579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video7725</td>\n",
       "      <td>young people sit around the edges of a room cl...</td>\n",
       "      <td>[[7725, 1.3989646434783936]]</td>\n",
       "      <td>[[7725, 1.3989646434783936], [7444, 1.42084288...</td>\n",
       "      <td>[[7725, 1.3989646434783936], [7444, 1.42084288...</td>\n",
       "      <td>7725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video9258</td>\n",
       "      <td>a person is using a phone</td>\n",
       "      <td>[[9257, 1.422074317932129]]</td>\n",
       "      <td>[[9257, 1.422074317932129], [9697, 1.426733016...</td>\n",
       "      <td>[[9257, 1.422074317932129], [9697, 1.426733016...</td>\n",
       "      <td>9258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video7365</td>\n",
       "      <td>cartoon people are eating at a restaurant</td>\n",
       "      <td>[[9777, 1.3951191902160645]]</td>\n",
       "      <td>[[9777, 1.3951191902160645], [9537, 1.42307245...</td>\n",
       "      <td>[[9777, 1.3951191902160645], [9537, 1.42307245...</td>\n",
       "      <td>7365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video8068</td>\n",
       "      <td>a woman on a couch talks to a a man</td>\n",
       "      <td>[[7724, 1.3635627031326294]]</td>\n",
       "      <td>[[7724, 1.3635627031326294], [7341, 1.41047430...</td>\n",
       "      <td>[[7724, 1.3635627031326294], [7341, 1.41047430...</td>\n",
       "      <td>8068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>video7034</td>\n",
       "      <td>man in black shirt is holding a baby upside do...</td>\n",
       "      <td>[[9522, 1.4664983749389648]]</td>\n",
       "      <td>[[9522, 1.4664983749389648], [9320, 1.47163987...</td>\n",
       "      <td>[[9522, 1.4664983749389648], [9320, 1.47163987...</td>\n",
       "      <td>7034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>video7568</td>\n",
       "      <td>the queen of england is seen walking with an e...</td>\n",
       "      <td>[[7568, 1.2713391780853271]]</td>\n",
       "      <td>[[7568, 1.2713391780853271], [7116, 1.43614828...</td>\n",
       "      <td>[[7568, 1.2713391780853271], [7116, 1.43614828...</td>\n",
       "      <td>7568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>video7979</td>\n",
       "      <td>people talking about a fight</td>\n",
       "      <td>[[7211, 1.4263927936553955]]</td>\n",
       "      <td>[[7211, 1.4263927936553955], [7835, 1.44549965...</td>\n",
       "      <td>[[7211, 1.4263927936553955], [7835, 1.44549965...</td>\n",
       "      <td>7979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>video7356</td>\n",
       "      <td>a vehicle with details on what comes with it b...</td>\n",
       "      <td>[[7356, 1.3739084005355835]]</td>\n",
       "      <td>[[7356, 1.3739084005355835], [9358, 1.39286637...</td>\n",
       "      <td>[[7356, 1.3739084005355835], [9358, 1.39286637...</td>\n",
       "      <td>7356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>video8578</td>\n",
       "      <td>a man is commentating while playing minecraft</td>\n",
       "      <td>[[8931, 1.3309963941574097]]</td>\n",
       "      <td>[[8931, 1.3309963941574097], [8313, 1.34997975...</td>\n",
       "      <td>[[8931, 1.3309963941574097], [8313, 1.34997975...</td>\n",
       "      <td>8578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    rel_frame_id                                              query  \\\n",
       "0      video7579  a girl wearing red top and black trouser is pu...   \n",
       "1      video7725  young people sit around the edges of a room cl...   \n",
       "2      video9258                          a person is using a phone   \n",
       "3      video7365          cartoon people are eating at a restaurant   \n",
       "4      video8068                a woman on a couch talks to a a man   \n",
       "..           ...                                                ...   \n",
       "995    video7034  man in black shirt is holding a baby upside do...   \n",
       "996    video7568  the queen of england is seen walking with an e...   \n",
       "997    video7979                       people talking about a fight   \n",
       "998    video7356  a vehicle with details on what comes with it b...   \n",
       "999    video8578      a man is commentating while playing minecraft   \n",
       "\n",
       "                             top1  \\\n",
       "0     [[7579, 1.360194444656372]]   \n",
       "1    [[7725, 1.3989646434783936]]   \n",
       "2     [[9257, 1.422074317932129]]   \n",
       "3    [[9777, 1.3951191902160645]]   \n",
       "4    [[7724, 1.3635627031326294]]   \n",
       "..                            ...   \n",
       "995  [[9522, 1.4664983749389648]]   \n",
       "996  [[7568, 1.2713391780853271]]   \n",
       "997  [[7211, 1.4263927936553955]]   \n",
       "998  [[7356, 1.3739084005355835]]   \n",
       "999  [[8931, 1.3309963941574097]]   \n",
       "\n",
       "                                                  top5  \\\n",
       "0    [[7579, 1.360194444656372], [9451, 1.407737612...   \n",
       "1    [[7725, 1.3989646434783936], [7444, 1.42084288...   \n",
       "2    [[9257, 1.422074317932129], [9697, 1.426733016...   \n",
       "3    [[9777, 1.3951191902160645], [9537, 1.42307245...   \n",
       "4    [[7724, 1.3635627031326294], [7341, 1.41047430...   \n",
       "..                                                 ...   \n",
       "995  [[9522, 1.4664983749389648], [9320, 1.47163987...   \n",
       "996  [[7568, 1.2713391780853271], [7116, 1.43614828...   \n",
       "997  [[7211, 1.4263927936553955], [7835, 1.44549965...   \n",
       "998  [[7356, 1.3739084005355835], [9358, 1.39286637...   \n",
       "999  [[8931, 1.3309963941574097], [8313, 1.34997975...   \n",
       "\n",
       "                                                 top10  ground_truth  \n",
       "0    [[7579, 1.360194444656372], [9451, 1.407737612...          7579  \n",
       "1    [[7725, 1.3989646434783936], [7444, 1.42084288...          7725  \n",
       "2    [[9257, 1.422074317932129], [9697, 1.426733016...          9258  \n",
       "3    [[9777, 1.3951191902160645], [9537, 1.42307245...          7365  \n",
       "4    [[7724, 1.3635627031326294], [7341, 1.41047430...          8068  \n",
       "..                                                 ...           ...  \n",
       "995  [[9522, 1.4664983749389648], [9320, 1.47163987...          7034  \n",
       "996  [[7568, 1.2713391780853271], [7116, 1.43614828...          7568  \n",
       "997  [[7211, 1.4263927936553955], [7835, 1.44549965...          7979  \n",
       "998  [[7356, 1.3739084005355835], [9358, 1.39286637...          7356  \n",
       "999  [[8931, 1.3309963941574097], [8313, 1.34997975...          8578  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twohee_data_col_to_df(ret_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "79ecce3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall@1': 0.332,\n",
       " 'recall@5': 0.551,\n",
       " 'recall@10': 0.656,\n",
       " 'map': 0.42762857142857114,\n",
       " 'ndcg@1': 0.332,\n",
       " 'ndcg@5': 0.44768332562758373,\n",
       " 'ndcg@10': 0.48185493150879904}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_eval_scores(twohee_data_col_to_df(ret_dc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b69532",
   "metadata": {},
   "source": [
    "# Try evaluation against queries from FIRE benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9ea2e1",
   "metadata": {},
   "source": [
    "We are working with a sample of MSR-VTT and our evaluation pipeline supports only one relevant query per video, hence we need to filter the full FIRE benchmark to only include videos we have sampled and ones with a single relevant result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31086197",
   "metadata": {},
   "source": [
    "FIRE_BENCHMARK_Q_JUDGEMENTS is created in the notebook `./clean_fire_judgements.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ca3c6413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 12:06:37,265 - 8454604864 - clip.py-clip:100 - WARNING: Gpu not available, use cpu\n",
      "2025-04-17 12:06:37,280 - 8454604864 - connectionpool.py-connectionpool:289 - DEBUG: Resetting dropped connection: huggingface.co\n",
      "2025-04-17 12:06:37,372 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 12:06:37,399 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 12:06:37,464 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "2025-04-17 12:06:37,467 - 15284121600 - connectionpool.py-connectionpool:289 - DEBUG: Resetting dropped connection: huggingface.co\n",
      "2025-04-17 12:06:37,770 - 15284121600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16 HTTP/1.1\" 200 3499\n",
      "2025-04-17 12:06:37,836 - 15284121600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/main HTTP/1.1\" 200 3099\n",
      "2025-04-17 12:06:37,837 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 12:06:37,889 - 15284121600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/discussions?p=0 HTTP/1.1\" 200 6380\n",
      "2025-04-17 12:06:37,968 - 15284121600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"GET /api/models/openai/clip-vit-base-patch16/commits/refs%2Fpr%2F10 HTTP/1.1\" 200 4064\n",
      "2025-04-17 12:06:38,061 - 15284121600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors.index.json HTTP/1.1\" 404 0\n",
      "2025-04-17 12:06:38,087 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 12:06:38,119 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-17 12:06:38,225 - 15284121600 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/refs%2Fpr%2F10/model.safetensors HTTP/1.1\" 302 0\n",
      "2025-04-17 12:06:38,258 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "2025-04-17 12:06:38,295 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.json HTTP/1.1\" 404 0\n",
      "2025-04-17 12:06:38,329 - 8454604864 - connectionpool.py-connectionpool:544 - DEBUG: https://huggingface.co:443 \"HEAD /openai/clip-vit-base-patch16/resolve/main/chat_template.jinja HTTP/1.1\" 404 0\n",
      "2025-04-17 12:06:38,460 - 16281268224 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2025-04-17 12:06:38,460 - 16314920960 - node.py-node:167 - INFO: Begin to run Node-read_frame_search_fire_csv-0\n",
      "2025-04-17 12:06:38,461 - 16492818432 - node.py-node:167 - INFO: Begin to run Node-image-text-embedding/clip-1\n",
      "2025-04-17 12:06:38,461 - 16281268224 - node.py-node:167 - INFO: Begin to run Node-lambda-2\n",
      "2025-04-17 12:06:38,461 - 16298094592 - node.py-node:167 - INFO: Begin to run Node-ann-search/milvus-client-3\n",
      "2025-04-17 12:06:38,461 - 16348573696 - node.py-node:167 - INFO: Begin to run Node-lambda-4\n",
      "2025-04-17 12:06:38,461 - 16459165696 - node.py-node:167 - INFO: Begin to run Node-_output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border-collapse: collapse;\"><tr><th style=\"text-align: center; font-size: 130%; border: none;\">rel_frame_id</th> <th style=\"text-align: center; font-size: 130%; border: none;\">query</th> <th style=\"text-align: center; font-size: 130%; border: none;\">top1</th> <th style=\"text-align: center; font-size: 130%; border: none;\">top5</th> <th style=\"text-align: center; font-size: 130%; border: none;\">top10</th></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video8469</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">two parrots in a bird cage one white chick and on green adult</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7546, 1.4175093173980713]] len=1</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7546, 1.4175093173980713],[8469, 1.4307200908660889],[7849, 1.4471447467803955],[8481, 1.4707032442092896],...] len=5</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7546, 1.4175093173980713],[8469, 1.4307200908660889],[7849, 1.4471447467803955],[8481, 1.4707032442092896],...] len=10</td></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video9687</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">a man chopping lobster and taking off the shell</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9687, 1.3523515462875366]] len=1</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9687, 1.3523515462875366],[9309, 1.3865060806274414],[8025, 1.3969764709472656],[8686, 1.4153034687042236],...] len=5</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9687, 1.3523515462875366],[9309, 1.3865060806274414],[8025, 1.3969764709472656],[8686, 1.4153034687042236],...] len=10</td></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video7698</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">two women are walking in a parking lot</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[8899, 1.390440583229065]] len=1</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[8899, 1.390440583229065],[7138, 1.4211058616638184],[7212, 1.42289137840271],[8016, 1.4232873916625977],...] len=5</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[8899, 1.390440583229065],[7138, 1.4211058616638184],[7212, 1.42289137840271],[8016, 1.4232873916625977],...] len=10</td></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video9503</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">a woman is talking about how jeans with patches or rips is trendy</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9503, 1.387997031211853]] len=1</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9503, 1.387997031211853],[8825, 1.424526572227478],[7724, 1.441739559173584],[8488, 1.4568039178848267],...] len=5</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9503, 1.387997031211853],[8825, 1.424526572227478],[7724, 1.441739559173584],[8488, 1.4568039178848267],...] len=10</td></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video8903</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">a naked child runs through a field</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[8125, 1.4102811813354492]] len=1</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[8125, 1.4102811813354492],[9240, 1.42606782913208],[8931, 1.4346017837524414],[9031, 1.4469490051269531],...] len=5</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[8125, 1.4102811813354492],[9240, 1.42606782913208],[8931, 1.4346017837524414],[9031, 1.4469490051269531],...] len=10</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run query pipeline using FIRE\n",
    "\n",
    "\n",
    "# CSV parser function and pipeline recreated since the FIRE csv uses `video_id` instead of `frame_id`\n",
    "def read_frame_search_fire_csv(csv_file):\n",
    "    with open(csv_file, 'r', encoding='utf-8-sig') as f:\n",
    "        data = csv.DictReader(f)\n",
    "        for line in data:\n",
    "            yield line['video_id'], line['sentence']\n",
    "            \n",
    "frame_search_fire_pipeline = (\n",
    "    pipe.input('csv_file')\n",
    "    .flat_map('csv_file', ('rel_frame_id', 'query'), read_frame_search_fire_csv)\n",
    "    .map('query', 'vec', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='text', device='mps'))\n",
    "    .map('vec', 'vec', lambda x: x / np.linalg.norm(x))\n",
    "    .map('vec', 'top10_raw_res', ops.ann_search.milvus_client(collection_name=FRAME_RET_COLLECTION, limit=10))\n",
    "    .map('top10_raw_res', ('top1', 'top5', 'top10'), lambda x: (x[:1], x[:5], x[:10]))\n",
    "    .output('rel_frame_id', 'query', 'top1', 'top5', 'top10')\n",
    ")\n",
    "            \n",
    "fire_query_results = DataCollection(frame_search_fire_pipeline(FIRE_BENCHMARK_Q_JUDGEMENTS))\n",
    "fire_query_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d379d6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall@1': 0.49044585987261147,\n",
       " 'recall@5': 0.6878980891719745,\n",
       " 'recall@10': 0.7484076433121019,\n",
       " 'map': 0.5742796481649985,\n",
       " 'ndcg@1': 0.49044585987261147,\n",
       " 'ndcg@5': 0.5961737289559949,\n",
       " 'ndcg@10': 0.616343918349418}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_eval_scores(twohee_data_col_to_df(fire_query_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info-ret-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
