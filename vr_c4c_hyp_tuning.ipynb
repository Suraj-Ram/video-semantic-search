{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70fea2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Milvus server at port 19530\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from towhee import ops, pipe, register\n",
    "from towhee.operator import PyOperator\n",
    "from towhee import DataCollection\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from helpers import milvus_utils\n",
    "from helpers import eval_utils as my_eval_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4590190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "\n",
    "# Files\n",
    "MSRVTT_SAMPLES = \"./MSRVTT_1K.csv\"\n",
    "\n",
    "# Database Collections\n",
    "VIDEO_RET_TUNING_COLLECTION_PREFIX = \"msrvtt_vid_hyp_tun_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d8cf2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "video_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "video_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentence",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d297f6e7-46b3-4273-8624-9e7feaa575fa",
       "rows": [
        [
         "0",
         "video7579",
         "./test_1k_compress/video7579.mp4",
         "a girl wearing red top and black trouser is putting a sweater on a dog"
        ],
        [
         "1",
         "video7725",
         "./test_1k_compress/video7725.mp4",
         "young people sit around the edges of a room clapping and raising their arms while others dance in the center during a party"
        ],
        [
         "2",
         "video9258",
         "./test_1k_compress/video9258.mp4",
         "a person is using a phone"
        ],
        [
         "3",
         "video7365",
         "./test_1k_compress/video7365.mp4",
         "cartoon people are eating at a restaurant"
        ],
        [
         "4",
         "video8068",
         "./test_1k_compress/video8068.mp4",
         "a woman on a couch talks to a a man"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_path</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video7579</td>\n",
       "      <td>./test_1k_compress/video7579.mp4</td>\n",
       "      <td>a girl wearing red top and black trouser is pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video7725</td>\n",
       "      <td>./test_1k_compress/video7725.mp4</td>\n",
       "      <td>young people sit around the edges of a room cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video9258</td>\n",
       "      <td>./test_1k_compress/video9258.mp4</td>\n",
       "      <td>a person is using a phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video7365</td>\n",
       "      <td>./test_1k_compress/video7365.mp4</td>\n",
       "      <td>cartoon people are eating at a restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video8068</td>\n",
       "      <td>./test_1k_compress/video8068.mp4</td>\n",
       "      <td>a woman on a couch talks to a a man</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    video_id                        video_path  \\\n",
       "0  video7579  ./test_1k_compress/video7579.mp4   \n",
       "1  video7725  ./test_1k_compress/video7725.mp4   \n",
       "2  video9258  ./test_1k_compress/video9258.mp4   \n",
       "3  video7365  ./test_1k_compress/video7365.mp4   \n",
       "4  video8068  ./test_1k_compress/video8068.mp4   \n",
       "\n",
       "                                            sentence  \n",
       "0  a girl wearing red top and black trouser is pu...  \n",
       "1  young people sit around the edges of a room cl...  \n",
       "2                          a person is using a phone  \n",
       "3          cartoon people are eating at a restaurant  \n",
       "4                a woman on a couch talks to a a man  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "raw_samples_df = pd.read_csv(MSRVTT_SAMPLES)\n",
    "raw_samples_df[['video_id', 'video_path', 'sentence']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b971683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loader_pipeline(uts_value, milvus_col_name):\n",
    "    print(f\"Creating loader pipeline for {uts_value} with collection {milvus_col_name}\")\n",
    "    def read_loader_csv(csv_file):\n",
    "        with open(csv_file, 'r', encoding='utf-8-sig') as f:\n",
    "            data = csv.DictReader(f)\n",
    "            for line in data:\n",
    "                yield int(line['video_id'][len('video'):]), line['video_path']\n",
    "\n",
    "    video_loader_pipeline = (\n",
    "        pipe.input('csv_file')\n",
    "        .flat_map('csv_file', ('video_id', 'video_path'), read_loader_csv)\n",
    "        # Create 12 evenly distributed frames per video\n",
    "        .map('video_path', 'frames', ops.video_decode.ffmpeg(sample_type='uniform_temporal_subsample', \n",
    "                                                             args={'num_samples': uts_value}))\n",
    "        # I have a M2 Max, so device is set to mps for better performance\n",
    "        .map('frames', 'vec', ops.video_text_embedding.clip4clip(model_name='clip_vit_b32', \n",
    "                                                                 modality='video', device='mps'))\n",
    "        .map(('video_id', 'vec'), (), ops.ann_insert.milvus_client(collection_name=milvus_col_name))\n",
    "        .output('video_id')\n",
    "    )\n",
    "    return video_loader_pipeline\n",
    "\n",
    "def create_searcher_pipeline(milvus_col_name):\n",
    "    print(f\"Creating searcher pipeline with collection {milvus_col_name}\")\n",
    "    def read_video_search_csv(csv_file):\n",
    "        with open(csv_file, 'r', encoding='utf-8-sig') as f:\n",
    "            data = csv.DictReader(f)\n",
    "            for line in data:\n",
    "                yield line['video_id'], line['sentence']\n",
    "\n",
    "    video_search_pipeline = (\n",
    "        pipe.input('csv_file')\n",
    "        .flat_map('csv_file', ('rel_video_id', 'query'), read_video_search_csv)\n",
    "        .map('query', 'vec', ops.video_text_embedding.clip4clip(model_name='clip_vit_b32', modality='text', device='mps'))\n",
    "        .map('vec', 'top10_raw_res', \n",
    "            ops.ann_search.milvus_client(collection_name=milvus_col_name, limit=10))\n",
    "        .map('top10_raw_res', ('top1', 'top5', 'top10'), lambda x: (x[:1], x[:5], x[:10]))\n",
    "        .output('rel_video_id', 'query', 'top1', 'top5', 'top10')\n",
    "    )\n",
    "    return video_search_pipeline\n",
    "        \n",
    "\n",
    "\n",
    "def load_and_query_c4c(uts_values):\n",
    "    # (1) Create a new collection for each experiment\n",
    "    milvus_cols = {uts_val: VIDEO_RET_TUNING_COLLECTION_PREFIX +\n",
    "                   str(uts_val) for uts_val in uts_values}\n",
    "    print(f\"Creating collections: {list(milvus_cols.values())}\")\n",
    "    for uv, m_col_name in milvus_cols.items():\n",
    "        milvus_utils.create_milvus_collection(m_col_name, 512)\n",
    "\n",
    "    # (2) Create different loader pipelines for each experiment\n",
    "    loader_pipelines = {}\n",
    "    searcher_pipelines = {}\n",
    "    search_dcs = {}\n",
    "    search_results_dfs = {}\n",
    "    for uv, m_col_name in milvus_cols.items():\n",
    "        print(f\"Creating loader pipeline for {uv}\")\n",
    "        loader_pipelines[uv] = create_loader_pipeline(uv, m_col_name)\n",
    "        searcher_pipelines[uv] = create_searcher_pipeline(m_col_name)\n",
    "    \n",
    "    # (3) Call each loader pipeline\n",
    "    for uv, m_col_name in milvus_cols.items():\n",
    "        print(f\"Loading data into {m_col_name}\")\n",
    "        pipe = loader_pipelines[uv]\n",
    "        pipe(MSRVTT_SAMPLES)\n",
    "        print(f\"Finished loading data into {m_col_name}\")\n",
    "    \n",
    "    # (4) Call each searcher pipeline\n",
    "    for uv, m_col_name in milvus_cols.items():\n",
    "        print(f\"Searching data in {m_col_name}\")\n",
    "        search_pipe = searcher_pipelines[uv]\n",
    "        search_dc = DataCollection(search_pipe(MSRVTT_SAMPLES))\n",
    "        search_dcs[uv] = search_dc\n",
    "        search_results_dfs[uv] = my_eval_utils.twohee_data_col_to_df(search_dc)\n",
    "        print(f\"Finished searching data in {m_col_name}\")\n",
    "\n",
    "    return search_results_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e13f2adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating collections: ['msrvtt_vid_hyp_tun_6', 'msrvtt_vid_hyp_tun_9', 'msrvtt_vid_hyp_tun_12']\n",
      "Creating loader pipeline for 6\n",
      "Creating loader pipeline for 6 with collection msrvtt_vid_hyp_tun_6\n",
      "Creating searcher pipeline with collection msrvtt_vid_hyp_tun_6\n",
      "Creating loader pipeline for 9\n",
      "Creating loader pipeline for 9 with collection msrvtt_vid_hyp_tun_9\n",
      "Creating searcher pipeline with collection msrvtt_vid_hyp_tun_9\n",
      "Creating loader pipeline for 12\n",
      "Creating loader pipeline for 12 with collection msrvtt_vid_hyp_tun_12\n",
      "Creating searcher pipeline with collection msrvtt_vid_hyp_tun_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 18:43:43,696 - 20599304192 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2025-04-16 18:43:43,696 - 25954381824 - node.py-node:167 - INFO: Begin to run Node-read_loader_csv-0\n",
      "2025-04-16 18:43:43,696 - 25971208192 - node.py-node:167 - INFO: Begin to run Node-video-decode/ffmpeg-1\n",
      "2025-04-16 18:43:43,696 - 20599304192 - node.py-node:167 - INFO: Begin to run Node-video-text-embedding/clip4clip-2\n",
      "2025-04-16 18:43:43,697 - 25988034560 - node.py-node:167 - INFO: Begin to run Node-ann-insert/milvus-client-3\n",
      "2025-04-16 18:43:43,697 - 26004860928 - node.py-node:167 - INFO: Begin to run Node-_output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data into msrvtt_vid_hyp_tun_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 18:44:37,545 - 26356314112 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2025-04-16 18:44:37,546 - 26373140480 - node.py-node:167 - INFO: Begin to run Node-read_loader_csv-0\n",
      "2025-04-16 18:44:37,546 - 26389966848 - node.py-node:167 - INFO: Begin to run Node-video-decode/ffmpeg-1\n",
      "2025-04-16 18:44:37,547 - 26406793216 - node.py-node:167 - INFO: Begin to run Node-video-text-embedding/clip4clip-2\n",
      "2025-04-16 18:44:37,547 - 26423619584 - node.py-node:167 - INFO: Begin to run Node-ann-insert/milvus-client-3\n",
      "2025-04-16 18:44:37,547 - 26356314112 - node.py-node:167 - INFO: Begin to run Node-_output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading data into msrvtt_vid_hyp_tun_6\n",
      "Loading data into msrvtt_vid_hyp_tun_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 18:45:39,864 - 27344547840 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2025-04-16 18:45:39,864 - 27361374208 - node.py-node:167 - INFO: Begin to run Node-read_loader_csv-0\n",
      "2025-04-16 18:45:39,865 - 27378200576 - node.py-node:167 - INFO: Begin to run Node-video-decode/ffmpeg-1\n",
      "2025-04-16 18:45:39,865 - 27344547840 - node.py-node:167 - INFO: Begin to run Node-video-text-embedding/clip4clip-2\n",
      "2025-04-16 18:45:39,866 - 27548266496 - node.py-node:167 - INFO: Begin to run Node-ann-insert/milvus-client-3\n",
      "2025-04-16 18:45:39,866 - 27531440128 - node.py-node:167 - INFO: Begin to run Node-_output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading data into msrvtt_vid_hyp_tun_9\n",
      "Loading data into msrvtt_vid_hyp_tun_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 18:46:33,961 - 18687864832 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2025-04-16 18:46:33,961 - 26088796160 - node.py-node:167 - INFO: Begin to run Node-read_video_search_csv-0\n",
      "2025-04-16 18:46:33,962 - 26105622528 - node.py-node:167 - INFO: Begin to run Node-video-text-embedding/clip4clip-1\n",
      "2025-04-16 18:46:33,962 - 18687864832 - node.py-node:167 - INFO: Begin to run Node-ann-search/milvus-client-2\n",
      "2025-04-16 18:46:33,963 - 26122448896 - node.py-node:167 - INFO: Begin to run Node-lambda-3\n",
      "2025-04-16 18:46:33,963 - 26139275264 - node.py-node:167 - INFO: Begin to run Node-_output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading data into msrvtt_vid_hyp_tun_12\n",
      "Searching data in msrvtt_vid_hyp_tun_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 18:47:40,700 - 26197651456 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2025-04-16 18:47:40,701 - 26214477824 - node.py-node:167 - INFO: Begin to run Node-read_video_search_csv-0\n",
      "2025-04-16 18:47:40,701 - 26231304192 - node.py-node:167 - INFO: Begin to run Node-video-text-embedding/clip4clip-1\n",
      "2025-04-16 18:47:40,702 - 26248130560 - node.py-node:167 - INFO: Begin to run Node-ann-search/milvus-client-2\n",
      "2025-04-16 18:47:40,702 - 26197651456 - node.py-node:167 - INFO: Begin to run Node-lambda-3\n",
      "2025-04-16 18:47:40,702 - 26264956928 - node.py-node:167 - INFO: Begin to run Node-_output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished searching data in msrvtt_vid_hyp_tun_6\n",
      "Searching data in msrvtt_vid_hyp_tun_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 18:48:54,391 - 26323890176 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2025-04-16 18:48:54,392 - 26440445952 - node.py-node:167 - INFO: Begin to run Node-read_video_search_csv-0\n",
      "2025-04-16 18:48:54,392 - 26457272320 - node.py-node:167 - INFO: Begin to run Node-video-text-embedding/clip4clip-1\n",
      "2025-04-16 18:48:54,393 - 26474098688 - node.py-node:167 - INFO: Begin to run Node-ann-search/milvus-client-2\n",
      "2025-04-16 18:48:54,393 - 26323890176 - node.py-node:167 - INFO: Begin to run Node-lambda-3\n",
      "2025-04-16 18:48:54,393 - 26490925056 - node.py-node:167 - INFO: Begin to run Node-_output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished searching data in msrvtt_vid_hyp_tun_9\n",
      "Searching data in msrvtt_vid_hyp_tun_12\n",
      "Finished searching data in msrvtt_vid_hyp_tun_12\n"
     ]
    }
   ],
   "source": [
    "experiment_query_results = load_and_query_c4c([6, 9, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53ee8351",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir hyperparam_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e18872",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type DataFrame is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save these raw experiment results to a json file\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhyperparam_tuning/c4c_uts_6_9_12\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_query_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/info-ret-proj/lib/python3.10/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m~/miniconda3/envs/info-ret-proj/lib/python3.10/json/encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 431\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/info-ret-proj/lib/python3.10/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/info-ret-proj/lib/python3.10/json/encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/info-ret-proj/lib/python3.10/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type DataFrame is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# TODO save these results to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708b9a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for uts value = 6\n",
      "{'recall@1': 0.411, 'recall@5': 0.708, 'recall@10': 0.795, 'map': 0.5326599206349206, 'ndcg@1': 0.411, 'ndcg@5': 0.5676151896815294, 'ndcg@10': 0.595778355143179}\n",
      "Results for uts value = 9\n",
      "{'recall@1': 0.417, 'recall@5': 0.705, 'recall@10': 0.805, 'map': 0.5381325396825392, 'ndcg@1': 0.417, 'ndcg@5': 0.5695032823417581, 'ndcg@10': 0.6021801975658738}\n",
      "Results for uts value = 12\n",
      "{'recall@1': 0.426, 'recall@5': 0.716, 'recall@10': 0.814, 'map': 0.5456543650793645, 'ndcg@1': 0.426, 'ndcg@5': 0.5780321865313451, 'ndcg@10': 0.6100154270801753}\n"
     ]
    }
   ],
   "source": [
    "for uv, res in experiment_query_results.items():\n",
    "    print(f\"Results for uts value = {uv}\")\n",
    "    print(get_all_eval_scores(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "772abf9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "recall@1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "recall@5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "recall@10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "map",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ndcg@1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ndcg@5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ndcg@10",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "49aa2444-3315-432e-9f7c-18965ffa3ae4",
       "rows": [
        [
         "6",
         "0.411",
         "0.708",
         "0.795",
         "0.5326599206349206",
         "0.411",
         "0.5676151896815294",
         "0.595778355143179"
        ],
        [
         "9",
         "0.417",
         "0.705",
         "0.805",
         "0.5381325396825392",
         "0.417",
         "0.5695032823417581",
         "0.6021801975658738"
        ],
        [
         "12",
         "0.426",
         "0.716",
         "0.814",
         "0.5456543650793645",
         "0.426",
         "0.5780321865313451",
         "0.6100154270801753"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall@1</th>\n",
       "      <th>recall@5</th>\n",
       "      <th>recall@10</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg@1</th>\n",
       "      <th>ndcg@5</th>\n",
       "      <th>ndcg@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.411</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.532660</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.567615</td>\n",
       "      <td>0.595778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.417</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.538133</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.569503</td>\n",
       "      <td>0.602180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.426</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.545654</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.578032</td>\n",
       "      <td>0.610015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    recall@1  recall@5  recall@10       map  ndcg@1    ndcg@5   ndcg@10\n",
       "6      0.411     0.708      0.795  0.532660   0.411  0.567615  0.595778\n",
       "9      0.417     0.705      0.805  0.538133   0.417  0.569503  0.602180\n",
       "12     0.426     0.716      0.814  0.545654   0.426  0.578032  0.610015"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Present results in a pandas dataframe table\n",
    "experiment_metrics = {uv: get_all_eval_scores(res) for uv, res in experiment_query_results.items()}\n",
    "experiment_metrics_df = pd.DataFrame(experiment_metrics)\n",
    "# flip rows and columns\n",
    "experiment_metrics_df = experiment_metrics_df.transpose()\n",
    "experiment_metrics_df = experiment_metrics_df.rename(columns={'uts_value': 'UTS Value'})\n",
    "experiment_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74b6ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def twohee_data_col_to_df(twohee_data_collection):\n",
    "    res_list = twohee_data_collection.to_list()\n",
    "    res_obj_list = []\n",
    "    for r in res_list:\n",
    "        res_obj = vars(r)\n",
    "        res_obj_list.append(res_obj)\n",
    "    res_df = pd.DataFrame(res_obj_list)\n",
    "    # Add ground truth column\n",
    "    res_df['ground_truth'] = res_df['rel_video_id'].apply(\n",
    "        lambda x: int(x[len('video'):]))\n",
    "\n",
    "    # TODO add conditional for frame_id here\n",
    "    return res_df.copy()\n",
    "\n",
    "\n",
    "def average_precision(ground_truth, predictions):\n",
    "    \"\"\"\n",
    "    Calculate the Average Precision (AP) for a single query.\n",
    "\n",
    "    Args:\n",
    "        ground_truth (int): The ground truth video ID.\n",
    "        predictions (list): List of predicted video IDs.\n",
    "\n",
    "    Returns:\n",
    "        float: The Average Precision (AP) score for the query.\n",
    "    \"\"\"\n",
    "    hits = 0\n",
    "    sum_precision = 0\n",
    "    for i, pred in enumerate(predictions):\n",
    "        if pred == ground_truth:\n",
    "            hits += 1\n",
    "            sum_precision += hits / (i + 1)\n",
    "    return sum_precision / hits if hits > 0 else 0\n",
    "\n",
    "\n",
    "def calculate_mean_average_precision(df):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Average Precision (MAP) for the given dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing columns 'query', 'ground_truth', 'top1', 'top5', 'top10'.\n",
    "\n",
    "    Returns:\n",
    "        float: The Mean Average Precision (MAP) score.\n",
    "    \"\"\"\n",
    "    # Calculate AP for each query\n",
    "    ap_scores = []\n",
    "    for _, row in df.iterrows():\n",
    "        ground_truth = row['ground_truth']\n",
    "        predictions_with_scores = row['top10']\n",
    "        predictions = [pred[0] for pred in predictions_with_scores]\n",
    "        ap_scores.append(average_precision(ground_truth, predictions))\n",
    "\n",
    "    # Calculate MAP\n",
    "    mean_ap = sum(ap_scores) / len(ap_scores) if ap_scores else 0\n",
    "    return mean_ap\n",
    "\n",
    "\n",
    "def calculate_recall(df):\n",
    "    \"\"\"\n",
    "    Calculate recall@1, recall@5, and recall@10 for the given dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing columns 'query', 'ground_truth', 'top1', 'top5', 'top10'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing recall@1, recall@5, and recall@10.\n",
    "    \"\"\"\n",
    "    recall_at_1 = 0\n",
    "    recall_at_5 = 0\n",
    "    recall_at_10 = 0\n",
    "    total_queries = len(df)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        ground_truth = row['ground_truth']\n",
    "        if ground_truth in [pred[0] for pred in row['top1']]:\n",
    "            recall_at_1 += 1\n",
    "        if ground_truth in [pred[0] for pred in row['top5']]:\n",
    "            recall_at_5 += 1\n",
    "        if ground_truth in [pred[0] for pred in row['top10']]:\n",
    "            recall_at_10 += 1\n",
    "\n",
    "    return {\n",
    "        'recall@1': recall_at_1 / total_queries,\n",
    "        'recall@5': recall_at_5 / total_queries,\n",
    "        'recall@10': recall_at_10 / total_queries\n",
    "    }\n",
    "\n",
    "\n",
    "def ndcg_score(ground_truth, predictions, k=10):\n",
    "    \"\"\"\n",
    "    Calculate the Normalized Discounted Cumulative Gain (NDCG) for a single query.\n",
    "\n",
    "    Args:\n",
    "        ground_truth (int): The ground truth video ID.\n",
    "        predictions (list): List of predicted video IDs with scores [(id, score), ...].\n",
    "        k (int): The number of top predictions to consider.\n",
    "\n",
    "    Returns:\n",
    "        float: The NDCG score for the query.\n",
    "    \"\"\"\n",
    "    def dcg(relevance_scores):\n",
    "        return sum(rel / np.log2(idx + 2) for idx, rel in enumerate(relevance_scores))\n",
    "\n",
    "    # Relevance scores: 1 if the prediction matches the ground truth, else 0\n",
    "    relevance_scores = [1 if pred[0] ==\n",
    "                        ground_truth else 0 for pred in predictions[:k]]\n",
    "\n",
    "    # Calculate DCG and IDCG\n",
    "    actual_dcg = dcg(relevance_scores)\n",
    "    ideal_dcg = dcg(sorted(relevance_scores, reverse=True))\n",
    "\n",
    "    # Return NDCG\n",
    "    return actual_dcg / ideal_dcg if ideal_dcg > 0 else 0\n",
    "\n",
    "# call this function to get the NDCG score for each query\n",
    "\n",
    "\n",
    "def calculate_ndcg(df, k=10):\n",
    "    \"\"\"\n",
    "    Calculate NDCG for the given dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing columns 'query', 'ground_truth', 'top1', 'top5', 'top10'.\n",
    "        k (int): The number of top predictions to consider.\n",
    "\n",
    "    Returns:\n",
    "        float: The mean NDCG score.\n",
    "    \"\"\"\n",
    "    ndcg_scores = []\n",
    "    for _, row in df.iterrows():\n",
    "        ground_truth = row['ground_truth']\n",
    "        predictions_with_scores = row['top10']\n",
    "        ndcg_scores.append(ndcg_score(\n",
    "            ground_truth, predictions_with_scores, k))\n",
    "\n",
    "    return sum(ndcg_scores) / len(ndcg_scores) if ndcg_scores else 0\n",
    "\n",
    "\n",
    "def get_all_eval_scores(df):\n",
    "    \"\"\"Return a dataframe with all evaluation scores: Recall@1, Recall@5, Recall@10, MAP, NDCG@1, NDCG@5, NDCG@10\"\"\"\n",
    "    recall_scores = calculate_recall(df)\n",
    "    map_score = calculate_mean_average_precision(df)\n",
    "    ndcg_score_1 = calculate_ndcg(df, k=1)\n",
    "    ndcg_score_5 = calculate_ndcg(df, k=5)\n",
    "    ndcg_score_10 = calculate_ndcg(df, k=10)\n",
    "\n",
    "    eval_scores = {\n",
    "        'recall@1': recall_scores['recall@1'],\n",
    "        'recall@5': recall_scores['recall@5'],\n",
    "        'recall@10': recall_scores['recall@10'],\n",
    "        'map': map_score,\n",
    "        'ndcg@1': ndcg_score_1,\n",
    "        'ndcg@5': ndcg_score_5,\n",
    "        'ndcg@10': ndcg_score_10\n",
    "    }\n",
    "\n",
    "    return eval_scores\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info-ret-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
